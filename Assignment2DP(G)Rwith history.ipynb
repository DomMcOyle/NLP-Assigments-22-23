{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/NLP-Assigments-22-23/blob/Assignment-2/Assignment2DP(G)Rwith%20history.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d23b6c",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3f451b",
      "metadata": {
        "id": "bd3f451b"
      },
      "source": [
        "## Deadlines\n",
        "\n",
        "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
        "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
        "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ada8c8",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c07553",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4907f8d",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: a question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3760b5",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cfee64",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "## The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996fa650",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3e7d0",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb6c37e",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa786e2",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26d68b7",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c7558c",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01cdad7",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "8aUY2EWyoS0x",
        "outputId": "ecac7a50-e275-498a-8d48-366082eafd11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8aUY2EWyoS0x",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.8.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import urllib.request\n",
        "import torch\n",
        "import pickle\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_from_disk\n",
        "from evaluate import load\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_error()"
      ],
      "metadata": {
        "id": "N6_2rsWowkPt"
      },
      "id": "N6_2rsWowkPt",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f6643e14",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xPPBaBkEa9N3",
        "outputId": "18926e21-2a41-474e-8c4e-d84cdd8c1654",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xPPBaBkEa9N3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "358bac70",
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5f6ab3ff",
      "metadata": {
        "id": "5f6ab3ff",
        "outputId": "4255137e-9d10-4dd5-b1f5-f0b00b566a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CoQA train data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-train-v1.0.json: 49.0MB [00:08, 5.87MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n",
            "Downloading CoQA test data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-dev-v1.0.json: 9.09MB [00:03, 2.87MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e42311",
      "metadata": {
        "id": "40e42311"
      },
      "source": [
        "#### Data Inspection\n",
        "\n",
        "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(SEED):\n",
        "  random.seed(SEED) # if you're using random\n",
        "  np.random.seed(SEED) # if you're using numpy\n",
        "  torch.manual_seed(SEED) # torch.cuda.manual_seed_all(SEED) is not required\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  tf.random.set_seed(SEED) # setting the seed for tensorflow too\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "def extract_data(split_dataset,add_history=False,sep_char=\"[SEP]\"):\n",
        "  \"\"\"\n",
        "  function extracting data from the list of dictionaries in the CoQA dataset\n",
        "  :params:\n",
        "    split_dataset: list of dictionaries from where to extract the pairs of question and passage and corresponding the answer\n",
        "  \"\"\"  \n",
        "  XQA = [] # list that will contain pairs (P,Q)\n",
        "  YQA = [] # list that will contain the Answers\n",
        "  story_source = [] #list that will contain the category/source for each example\n",
        "  for d in split_dataset: # scan each document\n",
        "    for i in range(len(d[\"questions\"])): # scan each question\n",
        "      if d[\"answers\"][i][\"span_end\"]!=-1: # discard unanswerable questions\n",
        "        single_example = [] # prepare the single example...\n",
        "        single_example.append(d[\"questions\"][i][\"input_text\"]) #... with the question ...\n",
        "        single_example.append(d[\"story\"]) # ...and the passage\n",
        "        if add_history:\n",
        "          for j in range(i-1,-1,-1):\n",
        "            if d[\"answers\"][j][\"span_end\"]!=-1:\n",
        "              single_example[1] = single_example[1] + sep_char + d[\"questions\"][j][\"input_text\"]+ sep_char + d[\"answers\"][j][\"input_text\"]\n",
        "              \n",
        "        XQA.append(single_example) # and append it\n",
        "        YQA.append(d[\"answers\"][i][\"input_text\"]) # add the answer\n",
        "        story_source.append(d[\"source\"]) # add the source\n",
        "  return XQA, YQA, story_source"
      ],
      "metadata": {
        "id": "h7_OLYpXkm56"
      },
      "id": "h7_OLYpXkm56",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f57334e0",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42 \n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "4Q6YfLkhyFXZ"
      },
      "id": "4Q6YfLkhyFXZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL NAME\n",
        "#model_name = 'distilroberta-base'\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "add_history=True\n",
        "\n",
        "with open('coqa/train.json') as f:\n",
        "  # loading the training json\n",
        "  train_json = json.load(f)\n",
        "\n",
        "with open('coqa/test.json') as f:\n",
        "  # loading the test json\n",
        "  test_json = json.load(f)\n",
        "\n",
        "# splitting training data\n",
        "train_data, val_data = train_test_split(train_json[\"data\"],\n",
        "                                        train_size=0.8,\n",
        "                                        shuffle=True,\n",
        "                                        random_state=seed)\n",
        "# extracting X as list of pairs [Question, Passage] and Y as a list of strings (Answers) \n",
        "XQA_train, YQA_train, source_train = extract_data(train_data, add_history)\n",
        "XQA_val, YQA_val, source_val = extract_data(val_data, add_history)\n",
        "XQA_test, YQA_test, source_test = extract_data(test_json[\"data\"], add_history)\n",
        "del(train_json)\n",
        "del(test_json)\n",
        "\n",
        "print(\"Fourth training example:\")\n",
        "print(XQA_train[3])\n",
        "print(YQA_train[3])\n",
        "print(source_train[3])\n",
        "print(\"Fourth validation example:\")\n",
        "print(XQA_val[3])\n",
        "print(YQA_val[3])\n",
        "print(source_val[3])\n",
        "print(\"Fourth test example:\")\n",
        "print(XQA_test[3])\n",
        "print(YQA_test[3])\n",
        "print(source_test[3])\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "id": "0s8Ux69Fq1j-",
        "outputId": "e19cf4a2-528d-48f5-a2a9-be3ad802479e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0s8Ux69Fq1j-",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fourth training example:\n",
            "['When was the last one held?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. [SEP]What day of the week did they vote?[SEP]Sunday[SEP]What is being voted on?[SEP]Representatives  are being chosen[SEP]Where is this taking place?[SEP]Tunisia']\n",
            "1956\n",
            "cnn\n",
            "Fourth validation example:\n",
            "['When was the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. [SEP]What was the score?[SEP]3-0[SEP]who was playing against them?[SEP]Manchester City[SEP]Who was playing in the game?[SEP]the team from Liverpool\"]\n",
            "Monday\n",
            "cnn\n",
            "Fourth test example:\n",
            "['Who did she live with?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "with her mommy and 5 sisters\n",
            "mctest\n",
            "Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## broken example fix:\n",
        "print(XQA_train[61])\n",
        "print(YQA_train[61])\n",
        "YQA_train[61] = 'October'\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mOxQbmUq0W",
        "outputId": "8d96a172-883d-4529-e35a-434968e68410"
      },
      "id": "o4mOxQbmUq0W",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what month?', 'Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features. \\n\\nIn 1981, Microsoft hired Charles Simonyi, the primary developer of Bravo, the first GUI word processor, which was developed at Xerox PARC. Simonyi started work on a word processor called \"Multi-Tool Word\" and soon hired Richard Brodie, a former Xerox intern, who became the primary software engineer. \\n\\nMicrosoft announced Multi-Tool Word for Xenix and MS-DOS in 1983. Its name was soon simplified to \"Microsoft Word\". Free demonstration copies of the application were bundled with the November 1983 issue of \"PC World\", making it the first to be distributed on-disk with a magazine. That year Microsoft demonstrated Word running on Windows.[SEP]when was it first released?[SEP]1983[SEP]Name a few other platforms that it was written for later.[SEP]IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985),[SEP]when?[SEP]November 1983[SEP]What magazine were distributed demo copies?[SEP]PC World[SEP]What is Microsoft word?[SEP]a word processor[SEP]what is that?[SEP]first GUI word processor[SEP]what did he develope?[SEP]Bravo[SEP]What did he do?[SEP]developer[SEP]Who did they hire in 1981?[SEP]Charles Simony']\n",
            "Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features.\n",
            "October\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_string(x):\n",
        "  return re.sub('[!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n]',\"\",x)\n",
        "  \n",
        "# this tokenizer doen't filter anything, so a word and the concatenation of the\n",
        "# same word with a punctuation will have different embeddings\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<UNK>')#, analyzer = custom_analyzer) # here we use a custom analyzer\n",
        "output_tokenizer.fit_on_texts([\"<start> \" + i + \" <end>\" for i in YQA_train])\n",
        "\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_output_length = max([len(i) for i in YQA_train])\n",
        "print(\"Max input output found: \" + str(max([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)])))\n",
        "#max_sequence_length = max(512, max_output_length)\n",
        "print(\"99° percentile of training set answer length:\" + str(np.quantile([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)], 0.99)))\n",
        "# actual percentile is 17, given that each string has the beginnning and ending token\n",
        "max_sequence_length = 20\n",
        "\n",
        "\n",
        "print(np.argmax([len(i) for i in YQA_train]))\n",
        "print(XQA_train[7529])\n",
        "print(YQA_train[7529])\n",
        "\n",
        "dataset_suffix = \"_hist\" if add_history else \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "7cfa8f5abb914b2491275b1351013f26",
            "3120530da629482abe0582f707f1f010",
            "f1c57d85542b47149257302059b68fc5",
            "ddd5221fea144ec0ad9a03799639d5cb",
            "ebdb9655a2c34932953a6a2cd3a2b205",
            "0bf54664aee84903a916352bb9485268",
            "f6ec9ad3273c4a3c848731a7510b1fc6",
            "8258ea0142de4e6bac76734a9b9610d2",
            "ab3f48841fcf4e2fb746bedf2597ec95",
            "5ff1ecc571ea4ba082dc0b263ff45b7d",
            "31d5327109ed4127b22c6ecc882c4e40"
          ]
        },
        "id": "bRzqq374GQOC",
        "outputId": "97ff39e5-83a4-4c01-cb83-8fca65ca4d4d"
      },
      "id": "bRzqq374GQOC",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cfa8f5abb914b2491275b1351013f26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input output found: 83\n",
            "99° percentile of training set answer length:13.0\n",
            "7529\n",
            "[\"What symptoms of addiction does Orzack's center list?\", 'Caught in the Web A few months ago, it wasn\\'t unusual for 47-year-old Carla Toebe to spend 15 hours per day online. She\\'d wake up early, turn on her laptop and chat on Internet dating sites and instant-messaging programs - leaving her bed for only brief intervals. Her household bills piled up, along with the dishes and dirty laundry, but it took near-constant complaints from her four daughters before she realized she had a problem. \"I was starting to feel like my whole world was falling apart - kind of slipping into a depression,\" said Carla. \"I knew that if I didn\\'t get off the dating sites, I\\'d just keep going,\" detaching herself further from the outside world. Toebe\\'s conclusion: She felt like she was \"addicted\" to the Internet. She\\'s not alone. Concern about excessive Internet use isn\\'t new. As far back as 1995, articles in medical journals and the establishment of a Pennsylvania treatment center for overusers generated interest in the subject. There\\'s still no consensus on how much time online constitutes too much or whether addiction is possible. But as reliance on the Web grows, there are signs that the question is getting more serious attention: Last month, a study published in CNS Spectrums claimed to be the first large-scale look at excessive Internet use. The American Psychiatric Association may consider listing Internet addiction in the next edition of its diagnostic manual. And scores of online discussion boards have popped up on which people discuss negative experiences tied to too much time on the Web. \"There\\'s no question that there\\'re people who\\'re seriously in trouble because they\\'re overdoing their Internet involvement,\" said psychiatrist Ivan Goldberg. Goldberg calls the problem a disorder rather than a true addiction. Jonathan Bishop, a researcher in Wales specializing in online communities, is more skeptical. \"The Internet is an environment,\" he said. \"You can\\'t be addicted to the environment.\" Bishop describes the problem as simply a matter of priorities, which can be solved by encouraging people to prioritize other life goals and plans in place of time spent online. The new CNS Spectrums study was based on results of a nationwide telephone survey of more than 2,500 adults. Like the 2005 survey, this one was conducted by Stanford University researchers.About 6% of respondents reported that \"their relationships suffered because of excessive Internet use.\" About 9% attempted to conceal \"nonessential Internet use,\" and nearly 4% reported feeling \"preoccupied by the Internet when offline.\" About 8% said they used the Internet as a way to escape problems, and almost 14% reported they \"found it hard to stay away from the Internet for several days at a time.\" \"The Internet problem is still in its infancy,\" said Elias Aboujaoude, a Stanford professor. No single online activity is to blame for excessive use, he said. \"They\\'re online in chat rooms, checking e-mail, or writing blogs. not limited to porn or gambling\" websites. Excessive Internet use should be defined not by the number of hours spent online but \"in terms of losses,\" said Maressa Orzack, a Harvard University professor. \"If it\\'s a loss you\\'re not getting to work, and family relationships are breaking down as a result, then it\\'s too much.\" Since the early 1990s, several clinics have been established in the U. S. to treat heavy Internet users. They include the Center for Internet Addiction Recovery and the Center for Internet Behavior. The website for Orzack\\'s center lists the following among the psychological symptoms of computer addiction: * Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders, Orzack said. When she discusses Internet habits with her patients, they often report that being online offers a \"sense of belonging, and escape, excitement fun,\" she said. \"Some people say relief...because they find themselves so relaxed.\" Some parts of the Internet seem to draw people in more than others. Internet gamers spend countless hours competing in games against people from all over the world. One such game, called World of Warcraft, is cited on many sites by posters complaining of a \"gaming addiction.\" Andrew Heidrich, an education network administrator from Sacramento, plays World of Warcraft for about two to four hours every other night, but that\\'s nothing compared with the 40 to 60 hours a week he spent playing online games when he was in college. He cut back only after a full-scale family intervention , in which s told him he\\'d gained weight. \"There\\'s this whole culture of competition that sucks people in\" with online gaming, said Heidrich, now a father of two. \"People do it at the expense of everything that was a constant in their lives.\" Heidrich now visits websites that discuss gaming addiction regularly \"to remind myself to keep my love for online games in check.\" Toebe also regularly visits a site where posters discuss Internet overuse. In August, when she first realized she had a problem, she posted a message on a Yahoo Internet addiction group with the subject line: \"I have an Internet Addiction.\" \"I\\'m self-employed and need the Internet for my work, but I\\'m failing to accomplish my work,to take care of my home, to give attention to my children,\" she wrote in a message sent to the group.\"I have no money or insurance to get professional help; I can\\'t even pay my mortgage and face losing everything.\" Since then, Toebe said, she has kept her promise to herself to cut back on her Internet use. \"I have a boyfriend now, and I\\'m not interested in online dating,\" she said by phone last week. \"It\\'s a lot better now.\"[SEP]What problems with addiction did Andrew have?[SEP]gained weight[SEP]What video game has been associated with addiction?[SEP]World of Warcraft[SEP]What problems did Carla have as a result of her addiction?[SEP]depression, bills piling up, household falling apart[SEP]How do you determine if someone is addicted to the internet?[SEP]There\\'s still no consensus[SEP]When did internet addiction first become known as a problem?[SEP]1995[SEP]Has the American Psychiatric Association listed Internet Addiction in its diagnostic manual?[SEP]No[SEP]Why was this a problem?[SEP]She was detached from daily life[SEP]What did Carla spend most of her day doing?[SEP]chat on Internet dating sites']\n",
            "Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dataset\n",
        "train_ds = Dataset.from_dict({\"xqa\": XQA_train, \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_train], \"source\":source_train})\n",
        "train_ds = train_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_token\": output_tokenizer.texts_to_sequences(x[\"yqa\"])}, batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_padded\": tf.keras.preprocessing.sequence.pad_sequences(x[\"y_token\"],\n",
        "                                                                     padding='post',\n",
        "                                                                     maxlen=max_sequence_length)}, batched=True\n",
        ")\n",
        "train_ds = train_ds.remove_columns([\"xqa\", \"yqa\", \"y_token\"])\n",
        "train_ds = train_ds.with_format(type=\"tensorflow\")\n",
        "if model_name == 'prajjwal1/bert-tiny':\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds\" + dataset_suffix)\n",
        "else:\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "nErpyDpLhRV8",
        "outputId": "48bdc51f-6c27-4370-c7dd-fc5c50d34853",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "e437ff16942240aabb8011ff85a22218",
            "96b9dfbe3ee04650acb502e3825afcc3",
            "fbf0703c9dae426e831dcac1409a5e11",
            "943f7c86832a442292db6c8db84e6ce7",
            "ed7d345b957a47edaed9d6005f380fb7",
            "be6f103e32b644feb1f42a7adef56e25",
            "5b2107d3e4234427a57f6d98d6615daa",
            "a71810eda1594a4c85c2ee810ee0598b",
            "1dc4a613bd5540c8b0541562c05d5734",
            "97ed3e36a9764744a773d0f5a6b33d77",
            "0faf46ae089243708093598b80e493d8",
            "1bd15d43f97849f5a7f5b2dab0ba338e",
            "0ad67389659744379cb2b5554c8226ca",
            "022d4b5b5f1945979bff59b61be92e1c",
            "a2fccbb7bcee4894ba2eec8cb6c5187f",
            "8dda9f1ea2e4465f96b7b8e56c6894e0",
            "7622f7174f574b848769d4721b80e306",
            "3e59e9e43bd043a5a8b258cba97efa13",
            "a3d968783bc64fcf94e76a59e6209545",
            "2f410c7410bd43a1a83ad04fe5ff4f9b",
            "c3e9e1bbd5a048f39076544d2c6030a6",
            "5ebc01f9f7014ed4a91b77cd70cd4a5c",
            "ae0cabb4b33b46c199abb38f65e3cae5",
            "dba0b8fe39ee41369ce187a361c53502",
            "5aa61ee49d0a4f289741ca236a09aa0d",
            "f9b0c1d828d2441d8a73f233a84bd869",
            "252d15399e0a4be8a16bf387808ed9a4",
            "8a599f3aea184edb8843b9ebed231b0e",
            "e06e62f0943744b8892ab5f03ee76958",
            "34c0e63c31b6412ab113929151e052b4",
            "0c40906c4ac544e9bc3e72d52460ac14",
            "b8b3a32fb2594d45a8ce7251b7228e96",
            "6f427381b6374ae49b74a8186fa60b5e",
            "9ae924f3033e45bf910380251be9679b",
            "33355dc2995f4df5918abd6b884f16b2",
            "daef163e7a14465188d15c7d8e326848",
            "e6d418edee314a909f2b149293ef5e21",
            "3b0cd951614c41c6b9b37d768b0bbc38",
            "5114a9d90c6c49d4ad9a6233b288617a",
            "6d6c0a4ea477413280e29843927462f1",
            "51413d2e51194a928f65e0717dab0dde",
            "3c47dd1cc0824a388836dada120decd8",
            "3917cb7b6ebb449e9e81f99ee30ec325",
            "d38d0760bd8745c0916707b95e46dafe"
          ]
        }
      },
      "id": "nErpyDpLhRV8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e437ff16942240aabb8011ff85a22218"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bd15d43f97849f5a7f5b2dab0ba338e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae0cabb4b33b46c199abb38f65e3cae5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/85807 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ae924f3033e45bf910380251be9679b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions are in lower case, so we consider the labels in lower case\n",
        "val_ds = Dataset.from_dict({\"xqa\": XQA_val,\n",
        "                            \"yqa\": [filter_string(i.lower()) for i in YQA_val],\n",
        "                            \"id_placeholder\": list(range(len(YQA_val))),\n",
        "                            \"source\":source_val})\n",
        "val_ds = val_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "val_ds = val_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "val_ds = val_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds\" + dataset_suffix)\n",
        "else:\n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "3338e914397b48558078e824b51f704a",
            "92d00fade76240078d50ff124ca739c0",
            "ffcdfc9b18ba4111840f7cb8a52a2a6f",
            "d20be3371c3a460b9a4d6d0a626a30bf",
            "fc5a0c7ed6a447c19034107ccf1092e2",
            "86c37bf7c4a542f6944b61023e4f5823",
            "18b4f2404e2d4fa7aa5e394081b8f2d0",
            "ca8c1905af06410da8e1017a46c0a7a3",
            "b161414258bc4c4fab9a04ea9e888328",
            "b985d1987b8b477f9b7a65c8f6efd15f",
            "c5f75518e18441e0981f6ed8cee4618a",
            "b9d7599dba594a7e8ec1a0bdc2a88c59",
            "c0432d06f05443b9888ae73ed0625760",
            "e1e570a3005f4d7dba8d444bee9abdbc",
            "cf515d848b9340ab9fc5b11e7008940d",
            "5d852d02afa3494db6d323d771baa41d",
            "9666fc914e024a67881d8a1828eebcce",
            "967164e5dd6c40c9bf701a3f451e92b1",
            "d6eb826f879a4e598029923699164cb4",
            "b8b2e2f7f8434d1fbffcd87be66217a6",
            "eacc919746994a3487060dd1d513087a",
            "3eccab7450aa48d9911b0f585e6241cf",
            "54ed691e396c4923928bd727b221446a",
            "30f6c06d35d44179aa2bed871d3e2847",
            "c3d569e1e2b64691ad136430ce38d8b1",
            "8ca93f427c2e4dd5b10302f147e9403b",
            "95efccc511c64c3cb54a47259099777c",
            "f8c71cb6f1fd41878e3e24a434b8bed3",
            "e1a475b832ac4d7594f81871fd07240c",
            "ec069d256829486a8c4d25110d2dad78",
            "9d5d0c27d92346d18f85d09a111d0650",
            "b83efebdd8f24ca89f4a85d6e6f0025e",
            "3f379f140fd946b0ab27e40c1b5713f2"
          ]
        },
        "id": "b9VyzKdnAuKz",
        "outputId": "36aa5136-fe80-4c04-9759-d7a37ff2c03d"
      },
      "id": "b9VyzKdnAuKz",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3338e914397b48558078e824b51f704a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/21479 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9d7599dba594a7e8ec1a0bdc2a88c59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/21479 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54ed691e396c4923928bd727b221446a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions are in lower case, so we consider the labels in lower case\n",
        "test_ds = Dataset.from_dict({\"xqa\": XQA_test,\n",
        "                             \"yqa\": [filter_string(i.lower()) for i in YQA_test],\n",
        "                             \"id_placeholder\": list(range(len(YQA_test))),\n",
        "                             \"source\":source_test})\n",
        "test_ds = test_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "test_ds = test_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "test_ds = test_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds\" + dataset_suffix)\n",
        "else:\n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "83_mH8gTRY5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "c0109beae5794bde9205e0472492247b",
            "e0c19cfae8ee413bbc609554c4f7b7fb",
            "eb5f2221c2c34e178bf63eb951c8b364",
            "c0a0a3ca88ee4e0a89ffc3d8764ab422",
            "a2df50f8ec134d68bc9eedbf72a82d07",
            "d16fd76e11a141eda802867957bbf1fd",
            "85b6c27036574928b2fbe3ca46fbe70b",
            "8eda94a2471f42a2a053c8056e733a51",
            "923afc43e2df4769926aab1a6538a455",
            "87f9076e747a48909bde7e0e06df4ea6",
            "fcbdbecd070045bb8ebb1ba74c74eeb9",
            "b78fe51459504e95a5ac26ba47d9a039",
            "bf54fcfd0cd247ffa81c36a13f10febb",
            "434ea6be2d994423bb5bb02e008e4b6f",
            "3c68ac9b84894bec974a218229655897",
            "0c805526d5094699b17bd178bd3e929b",
            "a64d0693afc64073bad450e686a3bf26",
            "25e739df9b9d45b7aac69761722f01af",
            "356c91e8155d4734a7a54cb84e4b520f",
            "8239b71822054c3285d9149edf198d29",
            "3ebb85ea66174a26a362e814978dcff8",
            "7c61fa7981ca432499623ef6ca9e89f3",
            "039c5405ee7644d5bdb7e7aa0daefa09",
            "9ff7d5d25a8a4fdbacb13849e475028b",
            "aa68da4d34b94755a8fb2e6d3db79aba",
            "c8b8aadea5624c70bf778d5392f54178",
            "518416137aba4b8c809b263d3fe659be",
            "94f48493b6464d8d9fbe34518325aee1",
            "8a3dea3833bc4e23b2296901d9500f45",
            "342c3e64589a4e41a8ca34a14b9c678a",
            "36d912985df846d49a5e4f6407b05346",
            "8db3efc9039246a3a424740e15c049eb",
            "5cd50e430ca54ec9a01157eed41d214e"
          ]
        },
        "outputId": "76a23be8-9f08-436a-e45b-300d3d5a52af"
      },
      "id": "83_mH8gTRY5z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0109beae5794bde9205e0472492247b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7918 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b78fe51459504e95a5ac26ba47d9a039"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/7918 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039c5405ee7644d5bdb7e7aa0daefa09"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230a21de",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS A SEPARATOR ##########################################################\n",
        "\n",
        "\"\"\"\n",
        "This was tested with:\n",
        "tensorflow==2.6\n",
        "tensorflow-gpu==2.6\n",
        "tensorflow-addons==0.16.1\n",
        "transformers==4.18.0\n",
        "Keras==2.6.0\n",
        "\n",
        "Note 1: Simple adaptation of tf_seq2seq_lstm.py script\n",
        "Note 2: make sure Keras and Tensorflow versions match!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# check if training can be performed on GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included) \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                                reduction='none') # from logits means that it returns values after a \n",
        "                                                                                  # softmax application, thus it is useless to\n",
        "                                                                                  # add a softmax activation layer if this parameter is set to \n",
        "                                                                                  # true (or even dangerous because it squashes the values)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)            # here it is possible to tweak the learning rate\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask # pointwise product\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # NOTABENE: it is necessary to add token_type_ids to see how it performs\n",
        "            if self.encoder.use_token_type_ids:\n",
        "              encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask'],\n",
        "                                                                  'token_type_ids': inputs['token_type_ids']})\n",
        "            else:\n",
        "              encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask']})\n",
        "            decoder_input = inputs['y_padded'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['y_padded'][:, 1:]  # ignore <start>\n",
        "\n",
        "            # encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs[0][0],\n",
        "            #                                                    'attention_mask': inputs[0][1]})\n",
        "            # decoder_input = inputs[1][:, :-1]\n",
        "            # real_target = inputs[1][:, 1:]\n",
        "\n",
        "            self.decoder.attention.setup_memory(encoder_output) # setup in order to perform attention queries over the \n",
        "                                                           # embedding space\n",
        "\n",
        "            # decoder initialization, check build_initial_state for additional insights\n",
        "            decoder_initial_state = self.decoder.build_initial_state(self.decoder.batch_size, [encoder_h, encoder_s])\n",
        "            # the input is then passed to the initialized decoder and we obtain predictions\n",
        "            # in rnn_output format because the model is BERT-emdedding-sequence-sequence, so the\n",
        "            # last layer is still a sequence of cells (a RNN)\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "            # we compute the losses over the computed predictions\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "        # gradients of the loss computed for this minibatch considering trainable\n",
        "        # parameters of encoder and decoder\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        # applies gradients to the trainable variables using Adam\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids, \n",
        "        })\n",
        "        if self.encoder.use_token_type_ids:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "        else:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        # samples the possible answer with greedy technique, we could possibly\n",
        "        # use a variant here such as beam search at inference time \n",
        "        # We could not do this at training time, since the Sampler used at training\n",
        "        # is not designed to project the token in an embedding space before computing\n",
        "        # the next one. The aforementioned embedding space\n",
        "        # is changing at each backpropagation step anyways, thus we stick with\n",
        "        # the computation of the argmax of the logits using TrainingSampler.\n",
        "        # NOTABENE: we can still change this sampler, find a way to penalize repetitions\n",
        "        # and perform the beam search\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler() \n",
        "        # we have a decoder for training and a decoder for test time, thus\n",
        "        # we need to re-define the training decoder each time we want to\n",
        "        # train a new batch\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # decoder_initial_state is still an output of the encoder, we pass it to\n",
        "        # the decoder_instance in order to get the outputs\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        \n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "    def beam_translate(self, results, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(results[0][:,0,:])\n",
        "\n",
        "    def beam_generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None, beam_width=3, length_penalty=0.5):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids, \n",
        "        })\n",
        "        if self.encoder.use_token_type_ids:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "        else:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "        \n",
        "        # From official documentation\n",
        "        # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "        # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "        # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "        # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "\n",
        "        encoder_output = tfa.seq2seq.tile_batch(encoder_output, multiplier=beam_width)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "        hidden_state = tfa.seq2seq.tile_batch([encoder_h, encoder_s], multiplier=beam_width)\n",
        "        decoder_initial_state = self.decoder.build_initial_state(beam_width*batch_size, hidden_state)\n",
        "\n",
        "        # Instantiate BeamSearchDecoder\n",
        "        decoder_instance = tfa.seq2seq.BeamSearchDecoder(self.decoder.wrapped_decoder_cell,\n",
        "                                                          beam_width=beam_width,\n",
        "                                                          output_layer=self.decoder.generation_dense,\n",
        "                                                          length_penalty_weight=length_penalty,\n",
        "                                                          maximum_iterations=self.max_length)\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "\n",
        "        # The BeamSearchDecoder object's call() function takes care of everything.\n",
        "        outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, \n",
        "                                                                  start_tokens=start_tokens,\n",
        "                                                                  end_token=end_token,\n",
        "                                                                  initial_state=decoder_initial_state)\n",
        "        # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
        "        # The final beam predictions are stored in outputs.predicted_id\n",
        "        # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
        "        # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
        "        # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
        "\n",
        "\n",
        "        # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "        # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "        # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
        "        final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
        "        beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
        "\n",
        "        return final_outputs.numpy(), beam_scores.numpy()\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True, trainable=False)\n",
        "        self.model.trainable=False\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "        self.reducer2 = tf.keras.layers.Dense(decoder_units)\n",
        "        self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size = 512)\n",
        "        self.use_token_type_ids = model_name=='prajjwal1/bert-tiny'\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        model_output = self.model(inputs)\n",
        "        \n",
        "        # all_outputs has shape (batch_size * 512 * 128)\n",
        "        all_outputs = model_output[0] # output of the last layer of the model\n",
        "        #pooled_output = model_output[1] # last layer but processed by a linear \n",
        "                                        # layer and a tanh\n",
        "        \n",
        "        # cls coding\n",
        "        hidden_pooled = all_outputs[:, 0, :]\n",
        "        cell_state = self.avg_pool(all_outputs)\n",
        "        cell_state = tf.reshape(cell_state, [all_outputs.shape[0], all_outputs.shape[2]])\n",
        "\n",
        "        # NOTABENE: it could be possible to add something to improve the encoding7\n",
        "        \n",
        "        # pooled output has shape (batch_size * 128)\n",
        "        hidden_state = self.reducer(hidden_pooled)\n",
        "        cell_state = self.reducer2(cell_state)\n",
        "        #return all_outputs, self.reducer(model_output[1]), self.reducer(model_output[1])\n",
        "        return all_outputs, hidden_state, cell_state\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        # NOTABENE: it is possible to change the embedding dimension and the number of LSTM cells\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        # NOTABENE: It could be possible to swap LSTMCell with GRUCell\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "        # NOTABENE: Just one type of attention, it could be changed to seek for different\n",
        "        # results\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units) # adds the attention mechanism after a single\n",
        "                                                                                # LSTM cell, because we pass a word at the time\n",
        "        # dense layer needed to generate the distribution values over \n",
        "        # the size of the vocabulary (probability for each word)\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        # Above we describe why this cannot be changed and why it resambles\n",
        "        # the greedysampler\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        # after initializing the tensors within the attention layer to 0 we add\n",
        "        # the designated initialization that allow us to query the embedding space,\n",
        "        # which is passed as encoder_state.\n",
        "        # We load the embedding of a single batch and we actually don't freeze \n",
        "        # the parameters related to BERT, that are modified and can possibly \n",
        "        # overfit. \n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state) \n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        # as shown in calls, inputs is a dictionary with entries: \n",
        "        # \"input_ids\" : _encoder_output_\n",
        "        # \"initial_state\" : _result_of_build_initial_state_\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n",
        "\n",
        "\n",
        "# THIS IS A SEPARATOR ##########################################################"
      ],
      "metadata": {
        "id": "tgypImQXgQhh"
      },
      "id": "tgypImQXgQhh",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(trainer, dataset, epochs, batch_size, ckpt_manager):\n",
        "  steps_per_epoch = len(dataset)//batch_size\n",
        "  \n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    batch_index = 0\n",
        "    cumulative_loss = 0\n",
        "\n",
        "    for batch_index in tqdm(range(steps_per_epoch), position=0, leave=True):\n",
        "      loss = trainer.batch_fit(dataset[batch_index*batch_size:batch_index*batch_size+batch_size])\n",
        "      cumulative_loss += loss\n",
        "\n",
        "    ckpt_manager.save()\n",
        "    mean_loss = cumulative_loss / batch_index\n",
        "    print(f\"Current mean {mean_loss}\")\n",
        "\n",
        "\n",
        "def predict_loop(trainer, dataset, inference_batch_size,model_name,output_tokenizer, beam_search=False):\n",
        "  ttids=None\n",
        "  if beam_search:\n",
        "    generation_func = trainer.beam_generate\n",
        "    translation_func = trainer.beam_translate\n",
        "  else:\n",
        "    generation_func = trainer.generate\n",
        "    translation_func = trainer.translate\n",
        "  \n",
        "  inference_step = len(dataset) // inference_batch_size\n",
        "  predictions = []\n",
        "  for step_index in tqdm(range(inference_step)):\n",
        "    starting_index = step_index*inference_batch_size\n",
        "    ending_index = step_index*inference_batch_size + inference_batch_size\n",
        "    if model_name == 'prajjwal1/bert-tiny':  \n",
        "      ttids = dataset[\"token_type_ids\"][starting_index : ending_index]\n",
        "    generated = generation_func(output_tokenizer=output_tokenizer, \n",
        "                                  input_ids=dataset[\"input_ids\"][starting_index : ending_index],\n",
        "                                  token_type_ids=ttids,\n",
        "                                  attention_mask=dataset[\"attention_mask\"][starting_index : ending_index])\n",
        "    translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "  # all this mess with indexes is needed in order to have coherent ids in the field \"id\"\n",
        "    list_to_add = [{'prediction_text': translated[i - starting_index].split(\"<end>\")[0], 'id':str(i)} for i in range(starting_index, ending_index)]\n",
        "    predictions.extend(list_to_add)\n",
        "  if model_name == 'prajjwal1/bert-tiny':  \n",
        "    ttids = dataset[\"token_type_ids\"][(inference_step)*inference_batch_size :]\n",
        "  \n",
        "  generated = generation_func(output_tokenizer = output_tokenizer, \n",
        "                             input_ids=dataset[\"input_ids\"][(inference_step)*inference_batch_size :],\n",
        "                             token_type_ids=ttids,\n",
        "                             attention_mask=dataset[\"attention_mask\"][(inference_step)*inference_batch_size :])\n",
        "  translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "\n",
        "  predictions.extend([{'prediction_text': translated[i - (inference_step)*inference_batch_size].split(\"<end>\")[0], \n",
        "                    'id':str(i)} for i in range((inference_step)*inference_batch_size, \n",
        "                                                len(dataset))])\n",
        "  return predictions\n",
        "  \n",
        "def save_prediction(prediction, filename):\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(prediction, f)"
      ],
      "metadata": {
        "id": "bIsHB5JGHGzE"
      },
      "id": "bIsHB5JGHGzE",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_metric = load(\"squad\")\n",
        "\n",
        "def train_and_val(model_name,train_ds, val_ds, epochs, batch_size, decoder_units, max_sequence_length, output_tokenizer, pred_file_name, checkpoint_dir):\n",
        "  INF_BS = 64 #Inference batch_size\n",
        "  results = []\n",
        "  results_beam = []\n",
        "  for train_seed in [42,1337,2022]:\n",
        "    set_seed(train_seed)\n",
        "\n",
        "    encoder = Encoder(model_name=model_name,\n",
        "                          decoder_units=decoder_units)\n",
        "      \n",
        "    # Testing the decoder\n",
        "    decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                          embedding_dim=100,\n",
        "                          decoder_units=decoder_units,\n",
        "                          batch_size=batch_size,\n",
        "                          max_sequence_length=max_sequence_length)\n",
        "    # Training\n",
        "    trainer = MyTrainer(encoder=encoder,\n",
        "                          decoder=decoder,\n",
        "                          max_length=max_sequence_length)\n",
        "    \n",
        "    checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                  encoder=encoder,\n",
        "                                  decoder=decoder)\n",
        "    manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir + f\"/{train_seed}\", max_to_keep=1)\n",
        "\n",
        "    train_loop(trainer, train_ds, epochs, batch_size, manager)\n",
        "\n",
        "    prediction = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer)\n",
        "    save_prediction(prediction, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + \"_pred.pickle\")\n",
        "\n",
        "    prediction_beam = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer, beam_search=True)\n",
        "    save_prediction(prediction_beam, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + \"_beampred.pickle\")\n",
        "\n",
        "    results.append(squad_metric.compute(predictions=prediction, references=val_ds['references']))\n",
        "    results_beam.append(squad_metric.compute(predictions=prediction_beam, references=val_ds['references']))\n",
        "\n",
        "    del(manager)\n",
        "    del(checkpoint)\n",
        "    del(trainer)\n",
        "    del(encoder)\n",
        "    del(decoder) \n",
        "\n",
        "  print(\"***VALIDATION RESULTS***\")\n",
        "  print(results)\n",
        "  print(results_beam)\n",
        "  print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "  print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "  print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "  print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )\n",
        "\n",
        "def test_model(model_name, test_ds, batch_size, decoder_units, max_sequence_length, output_tokenizer, pred_file_name, checkpoint_dir):\n",
        "  INF_BS = 64 #Inference batch_size\n",
        "  \n",
        "  \n",
        "  results = []\n",
        "  results_beam = []\n",
        "  for train_seed in [42,1337,2022]:\n",
        "    encoder = Encoder(model_name=model_name,\n",
        "                        decoder_units=decoder_units)\n",
        "      \n",
        "    # Testing the decoder\n",
        "    decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                          embedding_dim=100,\n",
        "                          decoder_units=decoder_units,\n",
        "                          batch_size=batch_size,\n",
        "                          max_sequence_length=max_sequence_length)\n",
        "  \n",
        "    # Training\n",
        "    trainer = MyTrainer(encoder=encoder,\n",
        "                          decoder=decoder,\n",
        "                          max_length=max_sequence_length)\n",
        "    \n",
        "    checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                  encoder=encoder,\n",
        "                                  decoder=decoder)\n",
        "    \n",
        "  \n",
        "    # required step in order to load correctly the decoder embedding matrix\n",
        "    decoder.embedding.build(input_shape=None)\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir+f\"/{train_seed}\")).expect_partial()\n",
        "\n",
        "    prediction = predict_loop(trainer, test_ds, INF_BS, model_name, output_tokenizer)\n",
        "    save_prediction(prediction, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + \"_testpred.pickle\")\n",
        "\n",
        "    prediction_beam = predict_loop(trainer, test_ds, INF_BS, model_name ,output_tokenizer, beam_search=True)\n",
        "    save_prediction(prediction_beam, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + \"_testbeampred.pickle\")\n",
        "\n",
        "    results.append(squad_metric.compute(predictions=prediction, references=test_ds['references']))\n",
        "    results_beam.append(squad_metric.compute(predictions=prediction_beam, references=test_ds['references']))\n",
        "\n",
        "  print(\"***TEST RESULTS***\")\n",
        "  print(results)\n",
        "  print(results_beam)\n",
        "  print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "  print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "  print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "  print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )"
      ],
      "metadata": {
        "id": "PQK8ldAw9SIs"
      },
      "id": "PQK8ldAw9SIs",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f1e83f28",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 14\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "TINY_DEC_UNITS = 128\n",
        "ROB_DEC_UNITS = 512"
      ],
      "metadata": {
        "id": "1yhop6aHPLr_"
      },
      "id": "1yhop6aHPLr_",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds\")\n",
        "\n",
        "train_and_val('prajjwal1/bert-tiny',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=TINY_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='tiny',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "1oNmAxBvSVuH",
        "outputId": "6987c73d-d37e-4e16-e8f9-46ee2a623c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1oNmAxBvSVuH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 6129/6129 [11:19<00:00,  9.02it/s]\n",
            " 33%|███▎      | 1/3 [11:19<22:39, 679.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.064605712890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:14<00:00,  9.08it/s]\n",
            " 67%|██████▋   | 2/3 [22:34<11:16, 676.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8742226958274841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:13<00:00,  9.10it/s]\n",
            "100%|██████████| 3/3 [33:48<00:00, 676.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7598474025726318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:32<00:00,  2.20it/s]\n",
            "100%|██████████| 335/335 [04:44<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}]\n",
            "[{'exact_match': 12.123469435262349, 'f1': 14.27187375444946}]\n",
            "greedy exact match:11.904651054518366\n",
            "greedy SQUAD-F1:14.289189542326932\n",
            "beam exact match:12.123469435262349\n",
            "beam SQUAD-F1:14.27187375444946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 6129/6129 [11:22<00:00,  8.98it/s]\n",
            " 33%|███▎      | 1/3 [11:23<22:46, 683.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0730599164962769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:11<00:00,  9.12it/s]\n",
            " 67%|██████▋   | 2/3 [22:35<11:16, 676.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8743070363998413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:12<00:00,  9.11it/s]\n",
            "100%|██████████| 3/3 [33:48<00:00, 676.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7575758695602417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:29<00:00,  2.24it/s]\n",
            "100%|██████████| 335/335 [04:39<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}, {'exact_match': 11.960519577261511, 'f1': 14.549653043162628}]\n",
            "[{'exact_match': 12.123469435262349, 'f1': 14.27187375444946}, {'exact_match': 12.197960798919874, 'f1': 14.561944356953724}]\n",
            "greedy exact match:11.932585315889938\n",
            "greedy SQUAD-F1:14.41942129274478\n",
            "beam exact match:12.160715117091112\n",
            "beam SQUAD-F1:14.416909055701591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 6129/6129 [11:16<00:00,  9.05it/s]\n",
            " 33%|███▎      | 1/3 [11:17<22:34, 677.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.065598726272583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:08<00:00,  9.17it/s]\n",
            " 67%|██████▋   | 2/3 [22:26<11:12, 672.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8747037649154663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:08<00:00,  9.16it/s]\n",
            "100%|██████████| 3/3 [33:35<00:00, 671.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7593579292297363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:27<00:00,  2.28it/s]\n",
            "100%|██████████| 335/335 [04:38<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}, {'exact_match': 11.960519577261511, 'f1': 14.549653043162628}, {'exact_match': 11.904651054518366, 'f1': 14.643605437027999}]\n",
            "[{'exact_match': 12.123469435262349, 'f1': 14.27187375444946}, {'exact_match': 12.197960798919874, 'f1': 14.561944356953724}, {'exact_match': 12.095535173890777, 'f1': 14.485326311156506}]\n",
            "greedy exact match:11.923273895432748\n",
            "greedy SQUAD-F1:14.494149340839186\n",
            "beam exact match:12.138988469357665\n",
            "beam SQUAD-F1:14.439714807519897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds_rob\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob\")\n",
        "\n",
        "train_and_val('distilroberta-base',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=ROB_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='rob',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "geZdYK00NgmK"
      },
      "id": "geZdYK00NgmK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7311ba86",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny/hist'\n",
        "\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds_hist\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_hist\")\n",
        "\n",
        "train_and_val('prajjwal1/bert-tiny',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=TINY_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='tiny_hist',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "66NLQ6G5OWRe",
        "outputId": "999567f6-e786-4b19-e2d2-515ac7245cc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        }
      },
      "id": "66NLQ6G5OWRe",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n",
            "100%|██████████| 6129/6129 [11:40<00:00,  8.75it/s]\n",
            " 33%|███▎      | 1/3 [11:40<23:21, 700.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0670831203460693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:24<00:00,  8.95it/s]\n",
            " 67%|██████▋   | 2/3 [23:06<11:31, 691.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8746263980865479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:24<00:00,  8.95it/s]\n",
            "100%|██████████| 3/3 [34:31<00:00, 690.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.759445309638977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:36<00:00,  2.14it/s]\n",
            "100%|██████████| 335/335 [04:51<00:00,  1.15it/s]\n",
            "100%|██████████| 6129/6129 [11:28<00:00,  8.90it/s]\n",
            " 33%|███▎      | 1/3 [11:29<22:58, 689.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0788750648498535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:23<00:00,  8.97it/s]\n",
            " 67%|██████▋   | 2/3 [22:53<11:26, 686.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8751189112663269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:23<00:00,  8.97it/s]\n",
            "100%|██████████| 3/3 [34:17<00:00, 685.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7595735192298889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:33<00:00,  2.19it/s]\n",
            "100%|██████████| 335/335 [04:47<00:00,  1.16it/s]\n",
            "100%|██████████| 6129/6129 [11:25<00:00,  8.94it/s]\n",
            " 33%|███▎      | 1/3 [11:25<22:51, 685.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0686047077178955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:22<00:00,  8.99it/s]\n",
            " 67%|██████▋   | 2/3 [22:48<11:23, 683.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8764885663986206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:21<00:00,  8.99it/s]\n",
            "100%|██████████| 3/3 [34:10<00:00, 683.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7604389190673828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:32<00:00,  2.20it/s]\n",
            "100%|██████████| 335/335 [04:49<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.913962474975557, 'f1': 14.435647357982468}, {'exact_match': 12.00242096931887, 'f1': 14.831662593488241}, {'exact_match': 11.81153684994646, 'f1': 14.194647495643768}]\n",
            "[{'exact_match': 12.216583639834257, 'f1': 14.615724631732936}, {'exact_match': 12.309697844406164, 'f1': 14.890212870467654}, {'exact_match': 12.104846594347968, 'f1': 14.181929087624674}]\n",
            "greedy exact match:11.909306764746963\n",
            "greedy SQUAD-F1:14.487319149038157\n",
            "beam exact match:12.21037602619613\n",
            "beam SQUAD-F1:14.562622196608421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob/hist'\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds_rob_hist\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob_hist\")\n",
        "\n",
        "train_and_val('distilroberta-base',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=ROB_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='rob_hist',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "nsQa40OkOWka"
      },
      "id": "nsQa40OkOWka",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b5ac768c",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds\")\n",
        "\n",
        "test_model('prajjwal1/bert-tiny',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=TINY_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='tiny',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "Nnr1YfanbSIs",
        "outputId": "ce9e021c-0493-44cb-ce7c-e44ee05905a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Nnr1YfanbSIs",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n",
            "100%|██████████| 123/123 [00:40<00:00,  3.04it/s]\n",
            "100%|██████████| 123/123 [01:29<00:00,  1.37it/s]\n",
            "100%|██████████| 123/123 [00:39<00:00,  3.09it/s]\n",
            "100%|██████████| 123/123 [01:27<00:00,  1.41it/s]\n",
            "100%|██████████| 123/123 [00:39<00:00,  3.10it/s]\n",
            "100%|██████████| 123/123 [01:29<00:00,  1.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 12.086385450871433, 'f1': 14.29309767458751}, {'exact_match': 12.136903258398586, 'f1': 14.5009777728258}, {'exact_match': 12.225309421571104, 'f1': 14.74764799280808}]\n",
            "[{'exact_match': 12.250568325334681, 'f1': 14.126559362075886}, {'exact_match': 12.32634503662541, 'f1': 14.498713003437578}, {'exact_match': 12.32634503662541, 'f1': 14.599285738107293}]\n",
            "greedy exact match:12.149532710280374\n",
            "greedy SQUAD-F1:14.51390781340713\n",
            "beam exact match:12.301086132861833\n",
            "beam SQUAD-F1:14.408186034540252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_rob\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "UR90KwNPPebI"
      },
      "id": "UR90KwNPPebI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny/hist'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_hist\")\n",
        "\n",
        "test_model('prajjwal1/bert-tiny',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=TINY_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='tiny_hist',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "7kH75XdyPvFy",
        "outputId": "82ee0d75-2c20-4d4c-eaaa-bae5d67bb2eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7kH75XdyPvFy",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:41<00:00,  2.98it/s]\n",
            "100%|██████████| 123/123 [01:31<00:00,  1.35it/s]\n",
            "100%|██████████| 123/123 [00:39<00:00,  3.10it/s]\n",
            "100%|██████████| 123/123 [01:29<00:00,  1.38it/s]\n",
            "100%|██████████| 123/123 [00:40<00:00,  3.01it/s]\n",
            "100%|██████████| 123/123 [01:30<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 12.124273806516797, 'f1': 14.392046008515898}, {'exact_match': 12.086385450871433, 'f1': 14.668835115967326}, {'exact_match': 12.073755998989643, 'f1': 14.23343061197177}]\n",
            "[{'exact_match': 12.47789845920687, 'f1': 14.779871710239322}, {'exact_match': 12.452639555443294, 'f1': 14.840252331149317}, {'exact_match': 12.250568325334681, 'f1': 14.217070933285694}]\n",
            "greedy exact match:12.09480508545929\n",
            "greedy SQUAD-F1:14.431437245484998\n",
            "beam exact match:12.393702113328281\n",
            "beam SQUAD-F1:14.612398324891444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob/hist'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_rob_hist\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob_hist',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "4-4EXMxEPz6x"
      },
      "id": "4-4EXMxEPz6x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = [{'prediction_text': translated[i - 128].split(\"<end>\")[0], 'id':str(i)} for i in range(128, 256)]\n",
        "print(type(prediction[0]))\n",
        "for i in prediction[0:10]:\n",
        "  print(i[\"prediction_text\"])\n",
        "  print(YQA_val[int(i[\"id\"])])\n",
        "  print(XQA_val[int(i[\"id\"])])"
      ],
      "metadata": {
        "id": "g_Q4mJbLSuPm"
      },
      "id": "g_Q4mJbLSuPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "92c7e98f",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_worst_errors(prediction_prefix, prediction_suffix, ref_dataset):\n",
        "  squad = load(\"squad\")\n",
        "  predictions = []\n",
        "  for seed in [42,1337,2022]:\n",
        "    with open(prediction_prefix + str(seed) + prediction_suffix, \"rb\") as f:\n",
        "      new_list = pickle.load(f)\n",
        "      new_list.sort(key=lambda x: int(x[\"id\"]))\n",
        "      predictions.append(new_list)\n",
        "      \n",
        "  categories = np.unique(ref_dataset[\"source\"])\n",
        "\n",
        "  source_dict = {cat:[] for cat in categories}\n",
        "  refd = ref_dataset[\"references\"]\n",
        "  for pred in tqdm(range(len(predictions[0]))):\n",
        "    #ATTENTION: the following instructions is based on the assumption that\n",
        "    # the id of each example is the row of the id itself, as it follows\n",
        "    #from our dataset construciton\n",
        "    ref = refd[int(predictions[0][pred][\"id\"])]\n",
        "    if ref[\"id\"] != predictions[0][pred][\"id\"] or ref[\"id\"] != predictions[1][pred][\"id\"] or ref[\"id\"] != predictions[2][pred][\"id\"]:\n",
        "      print(\"error with ids: example\" + ref[\"id\"])\n",
        "    \n",
        "    f1 = squad.compute(predictions=[predictions[0][pred]],\n",
        "                       references=[ref])[\"f1\"]\n",
        "\n",
        "    f1 += squad.compute(predictions=[predictions[1][pred]],\n",
        "                                     references = [ref])[\"f1\"]\n",
        "\n",
        "    f1 += squad.compute(predictions=[predictions[2][pred]],\n",
        "                        references = [ref])[\"f1\"]\n",
        "    \n",
        "    f1 = f1/3\n",
        "    source_dict[ref_dataset[\"source\"][int(predictions[0][pred][\"id\"])]].append((predictions[0][pred][\"id\"] , f1))\n",
        "\n",
        "\n",
        "  return source_dict\n",
        "\n",
        "def print_orderered_predictions(source_dict, prediction_prefix, prediction_suffix, ref_dataset, question_dataset, kind=\"worst\", qty=5, skip_yn=False):\n",
        "  predictions = []\n",
        "  refd = ref_dataset[\"references\"]\n",
        "  for seed in [42,1337,2022]:\n",
        "    with open(prediction_prefix + str(seed) + prediction_suffix, \"rb\") as f:\n",
        "      new_list = pickle.load(f)\n",
        "      new_list.sort(key=lambda x: int(x[\"id\"]))\n",
        "      predictions.append(new_list)\n",
        "  \n",
        "  for key in source_dict.keys():\n",
        "    source_dict[key].sort(key=lambda x : x[1], reverse=True if kind==\"best\" else False)\n",
        "    print(\"-------------\" + key + \"-------------\")\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i<qty and j<len(source_dict(key)):\n",
        "      id = source_dict[key][j][0]\n",
        "      if skip_yn and refd[int(id)][\"answers\"][\"text\"] in [\"yes\", \"no\"]:\n",
        "        j = j + 1\n",
        "        continue\n",
        "      print(\"question + passage: \" + str(XQA_test[int(id)]))\n",
        "      print(\"true answer: \" + str(refd[int(id)][\"answers\"][\"text\"]))\n",
        "      print(\"answer with seed 42: \" + predictions[0][int(id)][\"prediction_text\"])\n",
        "      print(\"answer with seed 1337: \" + predictions[1][int(id)][\"prediction_text\"])\n",
        "      print(\"answer with seed 2022: \" + predictions[2][int(id)][\"prediction_text\"])\n",
        "      print(\"f1: \" + str(source_dict[key][j][1]))\n",
        "      i = i + 1\n",
        "      j = j + 1\n",
        "\n",
        "    for i in range(qty):\n",
        "      id = source_dict[key][i][0]\n",
        "      print(\"question + passage: \" + str(XQA_test[int(id)]))\n",
        "      print(\"true answer: \" + str(refd[int(id)][\"answers\"][\"text\"]))\n",
        "      print(\"answer with seed 42: \" + predictions[0][int(id)][\"prediction_text\"])\n",
        "      print(\"answer with seed 1337: \" + predictions[1][int(id)][\"prediction_text\"])\n",
        "      print(\"answer with seed 2022: \" + predictions[2][int(id)][\"prediction_text\"])\n",
        "      print(\"f1: \" + str(source_dict[key][i][1]))\n",
        "    "
      ],
      "metadata": {
        "id": "v1tVCI94ne7w"
      },
      "id": "v1tVCI94ne7w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/tinytiny_\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "qQ4P1Rz3whvV"
      },
      "id": "qQ4P1Rz3whvV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tinytiny_\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "CFGqqJyS8dkB"
      },
      "id": "CFGqqJyS8dkB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tinytiny_\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "lyxBZF07vk5B",
        "outputId": "599a54f3-6076-425b-ff2a-59f342bc45bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lyxBZF07vk5B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------cnn-------------\n",
            "question + passage: ['Is someone in showbiz?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Was he in movies?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Did the resort follow procedure?', 'NEW YORK (CNN) -- Natasha Richardson, a film star, Tony-winning stage actress and member of the famed Redgrave acting family, died Wednesday after suffering injuries in a ski accident, according to a family statement. She was 45. \\n\\nNatasha Richardson fell on a beginners\\' slope in Canada. \\n\\nRichardson, wife of actor Liam Neeson, was injured Monday in a fall on a ski slope at a Quebec resort about 80 miles northwest of Montreal. \\n\\nRichardson\\'s family released a statement saying, \"Liam Neeson, his sons, and the entire family are shocked and devastated by the tragic death of their beloved Natasha. They are profoundly grateful for the support, love and prayers of everyone, and ask for privacy during this very difficult time.\" \\n\\nAccording to a statement from Mont Tremblant Ski Resort, Richardson fell during a lesson on a beginners\\' trail. Watch a report on Richardson\\'s life » \\n\\n\"She did not show any visible sign of injury, but the ski patrol followed strict procedures and brought her back to the bottom of the slope and insisted she should see a doctor,\" the statement said. \\n\\nRichardson, accompanied by her instructor, returned to her hotel, but about an hour after the fall was \"not feeling good,\" the statement said. An ambulance was called, and Richardson was taken to a local hospital before being transferred to Hopital du Sacre-Coeur in Montreal. From there she was transferred to Lenox Hill Hospital in New York City. \\n\\nFriends and colleagues were saddened by her death. \\n\\n\"Natasha was brilliant, beautiful, funny, talented beyond measure, as emotionally raw as she was razor sharp,\" said Jodie Foster, who worked with Richardson in \"Nell,\" in a statement. \"Tasha loved fiercely and that love continues in all of us who knew her. May Liam, her beautiful boys and her loving family hold her close as they move through this tragic moment.\" ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Did her husband share the same profession?', 'NEW YORK (CNN) -- Natasha Richardson, a film star, Tony-winning stage actress and member of the famed Redgrave acting family, died Wednesday after suffering injuries in a ski accident, according to a family statement. She was 45. \\n\\nNatasha Richardson fell on a beginners\\' slope in Canada. \\n\\nRichardson, wife of actor Liam Neeson, was injured Monday in a fall on a ski slope at a Quebec resort about 80 miles northwest of Montreal. \\n\\nRichardson\\'s family released a statement saying, \"Liam Neeson, his sons, and the entire family are shocked and devastated by the tragic death of their beloved Natasha. They are profoundly grateful for the support, love and prayers of everyone, and ask for privacy during this very difficult time.\" \\n\\nAccording to a statement from Mont Tremblant Ski Resort, Richardson fell during a lesson on a beginners\\' trail. Watch a report on Richardson\\'s life » \\n\\n\"She did not show any visible sign of injury, but the ski patrol followed strict procedures and brought her back to the bottom of the slope and insisted she should see a doctor,\" the statement said. \\n\\nRichardson, accompanied by her instructor, returned to her hotel, but about an hour after the fall was \"not feeling good,\" the statement said. An ambulance was called, and Richardson was taken to a local hospital before being transferred to Hopital du Sacre-Coeur in Montreal. From there she was transferred to Lenox Hill Hospital in New York City. \\n\\nFriends and colleagues were saddened by her death. \\n\\n\"Natasha was brilliant, beautiful, funny, talented beyond measure, as emotionally raw as she was razor sharp,\" said Jodie Foster, who worked with Richardson in \"Nell,\" in a statement. \"Tasha loved fiercely and that love continues in all of us who knew her. May Liam, her beautiful boys and her loving family hold her close as they move through this tragic moment.\" ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Did they have children?', 'NEW YORK (CNN) -- Natasha Richardson, a film star, Tony-winning stage actress and member of the famed Redgrave acting family, died Wednesday after suffering injuries in a ski accident, according to a family statement. She was 45. \\n\\nNatasha Richardson fell on a beginners\\' slope in Canada. \\n\\nRichardson, wife of actor Liam Neeson, was injured Monday in a fall on a ski slope at a Quebec resort about 80 miles northwest of Montreal. \\n\\nRichardson\\'s family released a statement saying, \"Liam Neeson, his sons, and the entire family are shocked and devastated by the tragic death of their beloved Natasha. They are profoundly grateful for the support, love and prayers of everyone, and ask for privacy during this very difficult time.\" \\n\\nAccording to a statement from Mont Tremblant Ski Resort, Richardson fell during a lesson on a beginners\\' trail. Watch a report on Richardson\\'s life » \\n\\n\"She did not show any visible sign of injury, but the ski patrol followed strict procedures and brought her back to the bottom of the slope and insisted she should see a doctor,\" the statement said. \\n\\nRichardson, accompanied by her instructor, returned to her hotel, but about an hour after the fall was \"not feeling good,\" the statement said. An ambulance was called, and Richardson was taken to a local hospital before being transferred to Hopital du Sacre-Coeur in Montreal. From there she was transferred to Lenox Hill Hospital in New York City. \\n\\nFriends and colleagues were saddened by her death. \\n\\n\"Natasha was brilliant, beautiful, funny, talented beyond measure, as emotionally raw as she was razor sharp,\" said Jodie Foster, who worked with Richardson in \"Nell,\" in a statement. \"Tasha loved fiercely and that love continues in all of us who knew her. May Liam, her beautiful boys and her loving family hold her close as they move through this tragic moment.\" ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "-------------gutenberg-------------\n",
            "question + passage: ['Was there a lot of coral in the lagoon?', 'CHAPTER XXII \\n\\nNorthward, along the leeward coast of Malaita, the _Ariel_ worked her leisurely way, threading the colour-riotous lagoon that lay between the shore-reefs and outer-reefs, daring passages so narrow and coral-patched that Captain Winters averred each day added a thousand grey hairs to his head, and dropping anchor off every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life. For Harley and Villa Kennan were in no hurry. So long as the way was interesting, they dared not how long it proved from anywhere to anywhere. \\n\\nDuring this time Jerry learned a new name for himself--or, rather, an entire series of names for himself. This was because of an aversion on Harley Kennan\\'s part against renaming a named thing. \\n\\n\"A name he must have had,\" he argued to Villa. \"Haggin must have named him before he sailed on the _Arangi_. Therefore, nameless he must be until we get back to Tulagi and find out his real name.\" \\n\\n\"What\\'s in a name?\" Villa had begun to tease. \\n\\n\"Everything,\" her husband retorted. \"Think of yourself, shipwrecked, called by your rescuers \\'Mrs. Riggs,\\' or \\'Mademoiselle de Maupin,\\' or just plain \\'Topsy.\\' And think of me being called \\'Benedict Arnold,\\' or \\' Judas,\\' or . . . or . . . \\'Haman.\\' No, keep him nameless, until we find out his original name.\" \\n\\n\"Must call him something,\" she objected. \"Can\\'t think of him without thinking something.\" \\n\\n\"Then call him many names, but never the same name twice. Call him \\'Dog\\' to-day, and \\'Mister Dog\\' to-morrow, and the next day something else.\" ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Was he a heretic?', 'CHAPTER FIFTY FIVE. \\n\\nWAITING. \\n\\nThe lengthening sunny days went on without bringing either what Romola most desired or what she most dreaded. They brought no sign from Baldassarre, and, in spite of special watch on the part of the Government, no revelation of the suspected conspiracy. But they brought other things which touched her closely, and bridged the phantom-crowded space of anxiety with active sympathy in immediate trial. They brought the spreading Plague and the Excommunication of Savonarola. \\n\\nBoth these events tended to arrest her incipient alienation from the Frate, and to rivet again her attachment to the man who had opened to her the new life of duty, and who seemed now to be worsted in the fight for principle against profligacy. For Romola could not carry from day to day into the abodes of pestilence and misery the sublime excitement of a gladness that, since such anguish existed, she too existed to make some of the anguish less bitter, without remembering that she owed this transcendent moral life to Fra Girolamo. She could not witness the silencing and excommunication of a man whose distinction from the great mass of the clergy lay, not in any heretical belief, not in his superstitions, but in the energy with which he sought to make the Christian life a reality, without feeling herself drawn strongly to his side. \\n\\nFar on in the hot days of June the Excommunication, for some weeks arrived from Rome, was solemnly published in the Duomo. Romola went to witness the scene, that the resistance it inspired might invigorate that sympathy with Savonarola which was one source of her strength. It was in memorable contrast with the scene she had been accustomed to witness there. ']\n",
            "true answer: ['no']\n",
            "answer with seed 42: no \n",
            "answer with seed 1337: no \n",
            "answer with seed 2022: no \n",
            "f1: 100.0\n",
            "question + passage: ['Was he superstitious?', 'CHAPTER FIFTY FIVE. \\n\\nWAITING. \\n\\nThe lengthening sunny days went on without bringing either what Romola most desired or what she most dreaded. They brought no sign from Baldassarre, and, in spite of special watch on the part of the Government, no revelation of the suspected conspiracy. But they brought other things which touched her closely, and bridged the phantom-crowded space of anxiety with active sympathy in immediate trial. They brought the spreading Plague and the Excommunication of Savonarola. \\n\\nBoth these events tended to arrest her incipient alienation from the Frate, and to rivet again her attachment to the man who had opened to her the new life of duty, and who seemed now to be worsted in the fight for principle against profligacy. For Romola could not carry from day to day into the abodes of pestilence and misery the sublime excitement of a gladness that, since such anguish existed, she too existed to make some of the anguish less bitter, without remembering that she owed this transcendent moral life to Fra Girolamo. She could not witness the silencing and excommunication of a man whose distinction from the great mass of the clergy lay, not in any heretical belief, not in his superstitions, but in the energy with which he sought to make the Christian life a reality, without feeling herself drawn strongly to his side. \\n\\nFar on in the hot days of June the Excommunication, for some weeks arrived from Rome, was solemnly published in the Duomo. Romola went to witness the scene, that the resistance it inspired might invigorate that sympathy with Savonarola which was one source of her strength. It was in memorable contrast with the scene she had been accustomed to witness there. ']\n",
            "true answer: ['no']\n",
            "answer with seed 42: no \n",
            "answer with seed 1337: no \n",
            "answer with seed 2022: no \n",
            "f1: 100.0\n",
            "question + passage: ['Is Archie having a bit of trouble keeping him in check?', 'Chapter XVIII \\n\\nThe Hound Restored \\n\\nOn the third day after his arrival at the camp Archie received orders to prepare to start with the hound, with the earl and a large party of men-at-arms, in search of Bruce. A traitor had just come in and told them where Bruce had slept the night before. Reluctantly Archie unfastened the chain from the pole, and holding the end in his hand went round with Hector to the front of the pavilion. He was resolved that if under the dog\\'s guidance the party came close up with Bruce, he would kill the dog and then try to escape by fleetness of foot, though of this, as there were so many mounted men in the party, he had but slight hope. Led by the peasant they proceeded to the hut, which was five miles away in the hills. On reaching it Hector at once became greatly excited. He sniffed here and there, eagerly hunted up and down the cottage, then made a circuit round it, and at last, with a loud deep bay he started off with his nose to the ground, pulling so hard at the chain that Archie had difficulty in keeping up with him. Pembroke and his knights rode a little behind, followed by their men-at-arms. \\n\\n\"I pray you, Sir Earl,\" Archie said, \"keep not too close to my traces, for the sound of the horse\\'s hoofs and the jingling of the equipments make him all the more impatient to get forward, and even now it taxes all my strength to hold him in.\" ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Did Pierre leave him?', 'Chapter 17: The Battle Of Moncontor. \\n\\nWhen Pierre left him in order to look after the horses, Philip continued his meal. There could be no hurry, for Nevers was twelve miles away; and it would be four hours, at least, before a party could arrive. \\n\\nThe landlady herself brought in the next course. After placing the dish upon the table, she stood looking earnestly at him for a minute, and then said: \\n\\n\"You spoke of stopping here tonight, sir. The accommodation is very poor and, if you will take my advice, you will ride farther. There have been some men along here this afternoon, inquiring for a party like yours; and offering a reward to any who would carry the news to them, should you pass through. Methinks their intentions were not friendly.\" \\n\\n\"I thank you very much for your counsel,\" Philip said, \"and will take it. I know that there are some who would gladly hinder me, in my journey; and if there is, as you say, a risk of their coming here for me, it were as well that I rode farther, although I would gladly have given my horses a night\\'s rest. I thank you warmly for having warned me.\" \\n\\n\"Do not let my husband know that I have spoken to you,\" she said. \"He is an honest man, but timid; and in these days \\'tis safest not to meddle with what does not concern one.\" \\n\\nPhilip waited for two hours, and then told Pierre to saddle the horses, and tell the landlord that he wished to speak to him. ']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "-------------mctest-------------\n",
            "question + passage: ['Was Cotton happy that she looked different than the rest of her family?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".']\n",
            "true answer: ['no']\n",
            "answer with seed 42: no \n",
            "answer with seed 1337: no \n",
            "answer with seed 2022: no \n",
            "f1: 100.0\n",
            "question + passage: ['Was Sharkie a friend?', 'Once there was a beautiful fish named Asta. Asta lived in the ocean. There were lots of other fish in the ocean where Asta lived. They played all day long. \\n\\nOne day, a bottle floated by over the heads of Asta and his friends. They looked up and saw the bottle. \"What is it?\" said Asta\\'s friend Sharkie. \"It looks like a bird\\'s belly,\" said Asta. But when they swam closer, it was not a bird\\'s belly. It was hard and clear, and there was something inside it. \\n\\nThe bottle floated above them. They wanted to open it. They wanted to see what was inside. So they caught the bottle and carried it down to the bottom of the ocean. They cracked it open on a rock. When they got it open, they found what was inside. It was a note. The note was written in orange crayon on white paper. Asta could not read the note. Sharkie could not read the note. They took the note to Asta\\'s papa. \"What does it say?\" they asked. \\n\\nAsta\\'s papa read the note. He told Asta and Sharkie, \"This note is from a little girl. She wants to be your friend. If you want to be her friend, we can write a note to her. But you have to find another bottle so we can send it to her.\" And that is what they did.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['did they get the bottle?', 'Once there was a beautiful fish named Asta. Asta lived in the ocean. There were lots of other fish in the ocean where Asta lived. They played all day long. \\n\\nOne day, a bottle floated by over the heads of Asta and his friends. They looked up and saw the bottle. \"What is it?\" said Asta\\'s friend Sharkie. \"It looks like a bird\\'s belly,\" said Asta. But when they swam closer, it was not a bird\\'s belly. It was hard and clear, and there was something inside it. \\n\\nThe bottle floated above them. They wanted to open it. They wanted to see what was inside. So they caught the bottle and carried it down to the bottom of the ocean. They cracked it open on a rock. When they got it open, they found what was inside. It was a note. The note was written in orange crayon on white paper. Asta could not read the note. Sharkie could not read the note. They took the note to Asta\\'s papa. \"What does it say?\" they asked. \\n\\nAsta\\'s papa read the note. He told Asta and Sharkie, \"This note is from a little girl. She wants to be your friend. If you want to be her friend, we can write a note to her. But you have to find another bottle so we can send it to her.\" And that is what they did.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['did they write back', 'Once there was a beautiful fish named Asta. Asta lived in the ocean. There were lots of other fish in the ocean where Asta lived. They played all day long. \\n\\nOne day, a bottle floated by over the heads of Asta and his friends. They looked up and saw the bottle. \"What is it?\" said Asta\\'s friend Sharkie. \"It looks like a bird\\'s belly,\" said Asta. But when they swam closer, it was not a bird\\'s belly. It was hard and clear, and there was something inside it. \\n\\nThe bottle floated above them. They wanted to open it. They wanted to see what was inside. So they caught the bottle and carried it down to the bottom of the ocean. They cracked it open on a rock. When they got it open, they found what was inside. It was a note. The note was written in orange crayon on white paper. Asta could not read the note. Sharkie could not read the note. They took the note to Asta\\'s papa. \"What does it say?\" they asked. \\n\\nAsta\\'s papa read the note. He told Asta and Sharkie, \"This note is from a little girl. She wants to be your friend. If you want to be her friend, we can write a note to her. But you have to find another bottle so we can send it to her.\" And that is what they did.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Did Kendra tell him why?', \"Kendra and Quinton travel to and from school every day. Kendra lives further from the bus stop than Quinton does, stops every morning at Quinton's house to join him to walk to the bus stop. Every afternoon, after school, when walking home from the bus stop they go in for cookies and milk that Quinton's mother has ready and waiting for them. Quinton can't eat cheese or cake so they had the same snack every day. They both work together on their homework and when they are done they play together. Kendra always makes sure to leave in time to get home for dinner. She doesn't want to miss story time which was right before bedtime. \\n\\nOne morning Kendra walked up to Quinton's house, she thought something might be wrong because normally Quinton was waiting outside for her and on this morning he was not to be found. Kendra went up to the door and knocked. She waited and waited and yet no one answered. She saw that Quinton's mother's car wasn't in their driveway which was weird. She waited for a few bit looking up and down the block and getting worried when Quinton was nowhere to be found. \\n\\nKendra didn't want to miss the bus to school and hurried off to make it in time. The bus driver saw that she was upset and that Quinton was not with her that morning. She told him what happened and he said that he was sure that everything would be okay. \\n\\nKendra got to school, ran to her teacher and told him what happened that morning. The teacher smiled and told her not to worry, Quinton's mother had called and he was going to the dentist and would be at school after lunch and that she would see him at the bus stop like normal tomorrow.\"]\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "-------------race-------------\n",
            "question + passage: ['Do I know her?', 'My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag. \\n\\nI know this lady. It is not her first visit. She is the boy\\'s grandmother, and her daughter bought the house next door last October. \\n\\nHer daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients. \\n\\nI know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice. \\n\\nCommunication between us is somewhat affected by the fact that she doesn\\'t speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother\\'s cooking and salt intake. Instantly, tears welled in my eyes. \\n\\n\"Your mother just can\\'t be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\" \\n\\n\"Oh, no, Lucy.\" Nicole said. \"Mum doesn\\'t like western food. Don\\'t worry about it; she has to cook for the three of them anyway, and she wants to do it.\" \\n\\nThe doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me. \\n\\nI am now working on some more Chinese words--it\\'s the least I can do after such display of kindness. \\n\\n\"Thank you\" is, of course, the first one. Somehow, it seems inadequate.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Did the house lights go out?', 'Thunder was coming when Reginald Eppes woke up at five in the morning. He checked the weather forecast. A violent storm was coming ,but it sounded like his small town wouldn\\'t be hit too hard. But Eppes, a firefighter, had clearly known the power of these huge storms from experiences. \"Do you know where the flashlights are?\" he asked his wife. Danielle. Just then, thunder was all-around them. The moment he turned the flashlight on. The house lights went off. A second later, the kitchen windows were broken. Eppes and Danielle ran to their boys who were still sleeping in their bedroom. \\n\\n\"Get up, get up, R.J.! \" Eppes shouted, waving his flashlight. The sleepy boy moved to the edge of the bed. Eppes held out his arms and ordered his son to jump. He was too late. The roof was torn down. R.J. was buried ,under the pieces. \\n\\n\"I\\'ve lost him,\" Eppes thought. Quickly, he hurried to Joel to shield him. Glass, wood, and plaster ( ) hit them. Then something huge, heavy-maybe the washing machine-knocked into him. He hurt his arms, but he still held the flashlight in one hand. \\n\\nAfter a long period, the wind began to die down. Eppes found himself standing in the ruins of his home. Darkness lay all about him. Then he thought he saw a shape moving straight toward him. It was R.J., guided home by the light of his father\\'s flashlight. \\n\\nAt the hospital later, R.J. described what had happened to him. \"I rushed out when the wall started moving I was scared. My mom and dad were gone. Pieces of glass hit my back, and something hit my neck really hard. \" \\n\\nR.J. had been raised up into the air by the wind and dropped back to the ground. Amazingly, R.J. was not hurt badly. Of all his family, Eppes was hurt most seriously.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Was it a real set?', \"John: Here's a good shop. Shall we buy mother's birthday present here? Mary: Yes, that's a good idea. Shall we go inside? Tom: No. Let's look in the window. Shall we buy her a sweater? Anne: Er, no. It'll soon be summer. Let's buy her a blouse to wear. There's a nice one in the window. John: No, she has two blouses. Let's buy a ring. Mary: Oh, no! They're diamond rings. Look at the price. The cheapest is $15. John: A real diamond ring is at least $500.They only look like diamonds. Tom: Shall we buy a table? It's only $15. Anne: It doesn't look good, just like a big box. Mum likes chairs. Tom: But they haven't any here. Mary: What about a pen? So cheap! Only $10. John: She has a lot of pens and pencils. All of them are new. Tom: Oh, look here. These flowers are beautiful. Mary: They aren't real and will never die. John: And they're the cheapest of all these things. Yes, let's buy them. Anne: All right.\"]\n",
            "true answer: ['no']\n",
            "answer with seed 42: no \n",
            "answer with seed 1337: no \n",
            "answer with seed 2022: no \n",
            "f1: 100.0\n",
            "question + passage: ['Was he with his unit at the time?', \"A German taxi-driver, Franz Bussman, recently found his brother who was thought to have been killed twenty years ago. \\n\\nWhile on a walking tour with his wife, he stopped to talk to a workman. After they had gone on, Mrs. Bussman said that the workman was closely like her husband and even suggested that he might be his brother. Franz laughed at the idea, pointing out that his brother had been killed in action during the war. Though Mrs. Busman knew this story quite well, she thought there was a chance in a million that she might be right. \\n\\nA few days later, she sent a boy to the workman to ask him if his name was Hans Bussman. Needless to say, the man's name was Hans Bussman. And he really was Franz's long-lost brother. \\n\\nWhen the brothers were reunited, Hans explained how it was that he was still alive. \\n\\nAfter having been wondered towards the end of the war, he had been sent to hospital and was separated from his unit . The hospital had been bombed and Hans had made his way back into Western Germany on foot. Meanwhile, his unit was lost and all records of him had been destroyed. Hans returned to his home, but the house had been bombed up. Guessing that his family had all been killed during an air-raid , Hans settled down in a village fifty miles away where he had remained ever since.\"]\n",
            "true answer: ['no']\n",
            "answer with seed 42: no \n",
            "answer with seed 1337: no \n",
            "answer with seed 2022: no \n",
            "f1: 100.0\n",
            "question + passage: ['Was his house still standing?', \"A German taxi-driver, Franz Bussman, recently found his brother who was thought to have been killed twenty years ago. \\n\\nWhile on a walking tour with his wife, he stopped to talk to a workman. After they had gone on, Mrs. Bussman said that the workman was closely like her husband and even suggested that he might be his brother. Franz laughed at the idea, pointing out that his brother had been killed in action during the war. Though Mrs. Busman knew this story quite well, she thought there was a chance in a million that she might be right. \\n\\nA few days later, she sent a boy to the workman to ask him if his name was Hans Bussman. Needless to say, the man's name was Hans Bussman. And he really was Franz's long-lost brother. \\n\\nWhen the brothers were reunited, Hans explained how it was that he was still alive. \\n\\nAfter having been wondered towards the end of the war, he had been sent to hospital and was separated from his unit . The hospital had been bombed and Hans had made his way back into Western Germany on foot. Meanwhile, his unit was lost and all records of him had been destroyed. Hans returned to his home, but the house had been bombed up. Guessing that his family had all been killed during an air-raid , Hans settled down in a village fifty miles away where he had remained ever since.\"]\n",
            "true answer: ['no']\n",
            "answer with seed 42: no \n",
            "answer with seed 1337: no \n",
            "answer with seed 2022: no \n",
            "f1: 100.0\n",
            "-------------wikipedia-------------\n",
            "question + passage: ['Is staten island one?', 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n\\nThe North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul\\'s Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Was it founded the same year?', 'OCLC, currently incorporated as OCLC Online Computer Library Center, Incorporated, is an American nonprofit cooperative organization \"dedicated to the public purposes of furthering access to the world\\'s information and reducing information costs\". It was founded in 1967 as the Ohio College Library Center. OCLC and its member libraries cooperatively produce and maintain WorldCat, the largest online public access catalog (OPAC) in the world. OCLC is funded mainly by the fees that libraries have to pay for its services (around $200\\xa0million annually ). \\n\\nOCLC began in 1967, as the Ohio College Library Center, through a collaboration of Ohio university presidents, vice presidents, and library directors who wanted to create a cooperative, computerized network for Ohio libraries. The group first met on July 5, 1967 on the campus of the Ohio State University to sign the articles of incorporation for the nonprofit organization. The group hired Frederick G. Kilgour, a former Yale University medical school librarian, to design the shared cataloging system. Kilgour wished to merge the latest information storage and retrieval system of the time, the computer, with the oldest, the library. The plan was to merge the catalogs of Ohio libraries electronically through a computer network and database to streamline operations, control costs, and increase efficiency in library management. The goal of this network and database was to bring libraries together to cooperatively keep track of the world\\'s information to best serve researchers and scholars. The first library to do online cataloging through OCLC was the Alden Library at Ohio University on August 26, 1971. This was the first occurrence of online cataloging by any library worldwide.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['does this make the county densely populated in some areas', 'Buckinghamshire ( or ), abbreviated Bucks, is a county in South East England which borders Greater London to the south east, Berkshire to the south, Oxfordshire to the west, Northamptonshire to the north, Bedfordshire to the north east and Hertfordshire to the east. \\n\\nBuckinghamshire is one of the home counties and towns such as High Wycombe, Amersham, Chesham and the Chalfonts in the east and southeast of the county are parts of the London commuter belt, forming some of the most densely-populated parts of the county. Development in this region is restricted by the Metropolitan Green Belt. Other large settlements include the county town of Aylesbury, Marlow in the south near the Thames and Princes Risborough in the west near Oxford. Some areas without direct rail links to London, such as around the old county town of Buckingham and near Olney in the northeast, are much less populous. The largest town is Milton Keynes in the northeast, which with the surrounding area is administered as a unitary authority separately to the rest of Buckinghamshire. The remainder of the county is administered by Buckinghamshire County Council as a non-metropolitan county, and four district councils. In national elections, Buckinghamshire is considered a reliable supporter of the Conservative Party.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['are areas without link to London less populous', 'Buckinghamshire ( or ), abbreviated Bucks, is a county in South East England which borders Greater London to the south east, Berkshire to the south, Oxfordshire to the west, Northamptonshire to the north, Bedfordshire to the north east and Hertfordshire to the east. \\n\\nBuckinghamshire is one of the home counties and towns such as High Wycombe, Amersham, Chesham and the Chalfonts in the east and southeast of the county are parts of the London commuter belt, forming some of the most densely-populated parts of the county. Development in this region is restricted by the Metropolitan Green Belt. Other large settlements include the county town of Aylesbury, Marlow in the south near the Thames and Princes Risborough in the west near Oxford. Some areas without direct rail links to London, such as around the old county town of Buckingham and near Olney in the northeast, are much less populous. The largest town is Milton Keynes in the northeast, which with the surrounding area is administered as a unitary authority separately to the rest of Buckinghamshire. The remainder of the county is administered by Buckinghamshire County Council as a non-metropolitan county, and four district councils. In national elections, Buckinghamshire is considered a reliable supporter of the Conservative Party.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n",
            "question + passage: ['Is it landlocked?', 'Wiltshire ( or ) is a county in South West England with an area of . It is landlocked and borders the counties of Dorset, Somerset, Hampshire, Gloucestershire, Oxfordshire and Berkshire. The county town was originally Wilton, after which the county is named, but Wiltshire Council is now based in the county town of Trowbridge. \\n\\nWiltshire is characterised by its high downland and wide valleys. Salisbury Plain is noted for being the location of the Stonehenge and Avebury stone circles and other ancient landmarks, and as a training area for the British Army. The city of Salisbury is notable for its mediaeval cathedral. Important country houses open to the public include Longleat, near Warminster, and the National Trust\\'s Stourhead, near Mere. \\n\\nThe county, in the 9th century written as \"Wiltunscir\", later \"Wiltonshire\", is named after the former county town of Wilton. \\n\\nWiltshire is notable for its pre-Roman archaeology. The Mesolithic, Neolithic and Bronze Age people that occupied southern Britain built settlements on the hills and downland that cover Wiltshire. Stonehenge and Avebury are perhaps the most famous Neolithic sites in the UK. \\n\\nIn the 6th and 7th centuries Wiltshire was at the western edge of Saxon Britain, as Cranborne Chase and the Somerset Levels prevented the advance to the west. The Battle of Bedwyn was fought in 675 between Escuin, a West Saxon nobleman who had seized the throne of Queen Saxburga, and King Wulfhere of Mercia. In 878 the Danes invaded the county. Following the Norman Conquest, large areas of the country came into the possession of the crown and the church.']\n",
            "true answer: ['yes']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA NO HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_rob\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/robrob_\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "Y4FxyBRY8wAi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y4FxyBRY8wAi"
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/robrob_\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "SUCp5EzY8wAo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "SUCp5EzY8wAo"
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/robrob_\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "t8_TsoNL8wAo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "t8_TsoNL8wAo"
    },
    {
      "cell_type": "code",
      "source": [
        "# TINYBERT WITH HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_hist\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/tiny/histtiny_hist\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "16FwFlx79Jku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "16FwFlx79Jku"
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tiny/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "d4xmsKk79Jku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "d4xmsKk79Jku"
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tiny/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "4m2oC28H9Jku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4m2oC28H9Jku"
    },
    {
      "cell_type": "code",
      "source": [
        "# TINYBERT WITH HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_hist\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/rob/histtiny_hist\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "hRT7aauu_och"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hRT7aauu_och"
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/rob/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "F80JZKNT_och"
      },
      "execution_count": null,
      "outputs": [],
      "id": "F80JZKNT_och"
    },
    {
      "cell_type": "code",
      "source": [
        "print_errors(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/rob/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "XY9_ajeA_och"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XY9_ajeA_och"
    },
    {
      "cell_type": "markdown",
      "id": "f1814004",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a1b2b9",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0967c209",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23929660",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c56a612",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bac4b9",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e437ff16942240aabb8011ff85a22218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96b9dfbe3ee04650acb502e3825afcc3",
              "IPY_MODEL_fbf0703c9dae426e831dcac1409a5e11",
              "IPY_MODEL_943f7c86832a442292db6c8db84e6ce7"
            ],
            "layout": "IPY_MODEL_ed7d345b957a47edaed9d6005f380fb7"
          }
        },
        "96b9dfbe3ee04650acb502e3825afcc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6f103e32b644feb1f42a7adef56e25",
            "placeholder": "​",
            "style": "IPY_MODEL_5b2107d3e4234427a57f6d98d6615daa",
            "value": "100%"
          }
        },
        "fbf0703c9dae426e831dcac1409a5e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71810eda1594a4c85c2ee810ee0598b",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dc4a613bd5540c8b0541562c05d5734",
            "value": 86
          }
        },
        "943f7c86832a442292db6c8db84e6ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97ed3e36a9764744a773d0f5a6b33d77",
            "placeholder": "​",
            "style": "IPY_MODEL_0faf46ae089243708093598b80e493d8",
            "value": " 86/86 [01:18&lt;00:00,  1.23ba/s]"
          }
        },
        "ed7d345b957a47edaed9d6005f380fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be6f103e32b644feb1f42a7adef56e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2107d3e4234427a57f6d98d6615daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a71810eda1594a4c85c2ee810ee0598b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dc4a613bd5540c8b0541562c05d5734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97ed3e36a9764744a773d0f5a6b33d77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0faf46ae089243708093598b80e493d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd15d43f97849f5a7f5b2dab0ba338e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ad67389659744379cb2b5554c8226ca",
              "IPY_MODEL_022d4b5b5f1945979bff59b61be92e1c",
              "IPY_MODEL_a2fccbb7bcee4894ba2eec8cb6c5187f"
            ],
            "layout": "IPY_MODEL_8dda9f1ea2e4465f96b7b8e56c6894e0"
          }
        },
        "0ad67389659744379cb2b5554c8226ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7622f7174f574b848769d4721b80e306",
            "placeholder": "​",
            "style": "IPY_MODEL_3e59e9e43bd043a5a8b258cba97efa13",
            "value": "100%"
          }
        },
        "022d4b5b5f1945979bff59b61be92e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3d968783bc64fcf94e76a59e6209545",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f410c7410bd43a1a83ad04fe5ff4f9b",
            "value": 86
          }
        },
        "a2fccbb7bcee4894ba2eec8cb6c5187f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e9e1bbd5a048f39076544d2c6030a6",
            "placeholder": "​",
            "style": "IPY_MODEL_5ebc01f9f7014ed4a91b77cd70cd4a5c",
            "value": " 86/86 [00:01&lt;00:00, 60.65ba/s]"
          }
        },
        "8dda9f1ea2e4465f96b7b8e56c6894e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7622f7174f574b848769d4721b80e306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e59e9e43bd043a5a8b258cba97efa13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3d968783bc64fcf94e76a59e6209545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f410c7410bd43a1a83ad04fe5ff4f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3e9e1bbd5a048f39076544d2c6030a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebc01f9f7014ed4a91b77cd70cd4a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae0cabb4b33b46c199abb38f65e3cae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dba0b8fe39ee41369ce187a361c53502",
              "IPY_MODEL_5aa61ee49d0a4f289741ca236a09aa0d",
              "IPY_MODEL_f9b0c1d828d2441d8a73f233a84bd869"
            ],
            "layout": "IPY_MODEL_252d15399e0a4be8a16bf387808ed9a4"
          }
        },
        "dba0b8fe39ee41369ce187a361c53502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a599f3aea184edb8843b9ebed231b0e",
            "placeholder": "​",
            "style": "IPY_MODEL_e06e62f0943744b8892ab5f03ee76958",
            "value": "100%"
          }
        },
        "5aa61ee49d0a4f289741ca236a09aa0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34c0e63c31b6412ab113929151e052b4",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c40906c4ac544e9bc3e72d52460ac14",
            "value": 86
          }
        },
        "f9b0c1d828d2441d8a73f233a84bd869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b3a32fb2594d45a8ce7251b7228e96",
            "placeholder": "​",
            "style": "IPY_MODEL_6f427381b6374ae49b74a8186fa60b5e",
            "value": " 86/86 [00:01&lt;00:00, 74.07ba/s]"
          }
        },
        "252d15399e0a4be8a16bf387808ed9a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a599f3aea184edb8843b9ebed231b0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06e62f0943744b8892ab5f03ee76958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34c0e63c31b6412ab113929151e052b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c40906c4ac544e9bc3e72d52460ac14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8b3a32fb2594d45a8ce7251b7228e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f427381b6374ae49b74a8186fa60b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ae924f3033e45bf910380251be9679b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33355dc2995f4df5918abd6b884f16b2",
              "IPY_MODEL_daef163e7a14465188d15c7d8e326848",
              "IPY_MODEL_e6d418edee314a909f2b149293ef5e21"
            ],
            "layout": "IPY_MODEL_3b0cd951614c41c6b9b37d768b0bbc38"
          }
        },
        "33355dc2995f4df5918abd6b884f16b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5114a9d90c6c49d4ad9a6233b288617a",
            "placeholder": "​",
            "style": "IPY_MODEL_6d6c0a4ea477413280e29843927462f1",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "daef163e7a14465188d15c7d8e326848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51413d2e51194a928f65e0717dab0dde",
            "max": 85807,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c47dd1cc0824a388836dada120decd8",
            "value": 85807
          }
        },
        "e6d418edee314a909f2b149293ef5e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3917cb7b6ebb449e9e81f99ee30ec325",
            "placeholder": "​",
            "style": "IPY_MODEL_d38d0760bd8745c0916707b95e46dafe",
            "value": " 85807/85807 [00:15&lt;00:00, 45946.37 examples/s]"
          }
        },
        "3b0cd951614c41c6b9b37d768b0bbc38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5114a9d90c6c49d4ad9a6233b288617a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d6c0a4ea477413280e29843927462f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51413d2e51194a928f65e0717dab0dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c47dd1cc0824a388836dada120decd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3917cb7b6ebb449e9e81f99ee30ec325": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d38d0760bd8745c0916707b95e46dafe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0109beae5794bde9205e0472492247b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c19cfae8ee413bbc609554c4f7b7fb",
              "IPY_MODEL_eb5f2221c2c34e178bf63eb951c8b364",
              "IPY_MODEL_c0a0a3ca88ee4e0a89ffc3d8764ab422"
            ],
            "layout": "IPY_MODEL_a2df50f8ec134d68bc9eedbf72a82d07"
          }
        },
        "e0c19cfae8ee413bbc609554c4f7b7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16fd76e11a141eda802867957bbf1fd",
            "placeholder": "​",
            "style": "IPY_MODEL_85b6c27036574928b2fbe3ca46fbe70b",
            "value": "100%"
          }
        },
        "eb5f2221c2c34e178bf63eb951c8b364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eda94a2471f42a2a053c8056e733a51",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_923afc43e2df4769926aab1a6538a455",
            "value": 8
          }
        },
        "c0a0a3ca88ee4e0a89ffc3d8764ab422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87f9076e747a48909bde7e0e06df4ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_fcbdbecd070045bb8ebb1ba74c74eeb9",
            "value": " 8/8 [00:09&lt;00:00,  1.35s/ba]"
          }
        },
        "a2df50f8ec134d68bc9eedbf72a82d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d16fd76e11a141eda802867957bbf1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b6c27036574928b2fbe3ca46fbe70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eda94a2471f42a2a053c8056e733a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923afc43e2df4769926aab1a6538a455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87f9076e747a48909bde7e0e06df4ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcbdbecd070045bb8ebb1ba74c74eeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78fe51459504e95a5ac26ba47d9a039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf54fcfd0cd247ffa81c36a13f10febb",
              "IPY_MODEL_434ea6be2d994423bb5bb02e008e4b6f",
              "IPY_MODEL_3c68ac9b84894bec974a218229655897"
            ],
            "layout": "IPY_MODEL_0c805526d5094699b17bd178bd3e929b"
          }
        },
        "bf54fcfd0cd247ffa81c36a13f10febb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64d0693afc64073bad450e686a3bf26",
            "placeholder": "​",
            "style": "IPY_MODEL_25e739df9b9d45b7aac69761722f01af",
            "value": "100%"
          }
        },
        "434ea6be2d994423bb5bb02e008e4b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356c91e8155d4734a7a54cb84e4b520f",
            "max": 7918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8239b71822054c3285d9149edf198d29",
            "value": 7918
          }
        },
        "3c68ac9b84894bec974a218229655897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ebb85ea66174a26a362e814978dcff8",
            "placeholder": "​",
            "style": "IPY_MODEL_7c61fa7981ca432499623ef6ca9e89f3",
            "value": " 7918/7918 [00:00&lt;00:00, 9405.91ex/s]"
          }
        },
        "0c805526d5094699b17bd178bd3e929b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64d0693afc64073bad450e686a3bf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e739df9b9d45b7aac69761722f01af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "356c91e8155d4734a7a54cb84e4b520f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8239b71822054c3285d9149edf198d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ebb85ea66174a26a362e814978dcff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c61fa7981ca432499623ef6ca9e89f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "039c5405ee7644d5bdb7e7aa0daefa09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ff7d5d25a8a4fdbacb13849e475028b",
              "IPY_MODEL_aa68da4d34b94755a8fb2e6d3db79aba",
              "IPY_MODEL_c8b8aadea5624c70bf778d5392f54178"
            ],
            "layout": "IPY_MODEL_518416137aba4b8c809b263d3fe659be"
          }
        },
        "9ff7d5d25a8a4fdbacb13849e475028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f48493b6464d8d9fbe34518325aee1",
            "placeholder": "​",
            "style": "IPY_MODEL_8a3dea3833bc4e23b2296901d9500f45",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "aa68da4d34b94755a8fb2e6d3db79aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342c3e64589a4e41a8ca34a14b9c678a",
            "max": 7918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36d912985df846d49a5e4f6407b05346",
            "value": 7918
          }
        },
        "c8b8aadea5624c70bf778d5392f54178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db3efc9039246a3a424740e15c049eb",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd50e430ca54ec9a01157eed41d214e",
            "value": " 7918/7918 [00:14&lt;00:00, 8215.74 examples/s]"
          }
        },
        "518416137aba4b8c809b263d3fe659be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "94f48493b6464d8d9fbe34518325aee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3dea3833bc4e23b2296901d9500f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "342c3e64589a4e41a8ca34a14b9c678a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d912985df846d49a5e4f6407b05346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8db3efc9039246a3a424740e15c049eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd50e430ca54ec9a01157eed41d214e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cfa8f5abb914b2491275b1351013f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3120530da629482abe0582f707f1f010",
              "IPY_MODEL_f1c57d85542b47149257302059b68fc5",
              "IPY_MODEL_ddd5221fea144ec0ad9a03799639d5cb"
            ],
            "layout": "IPY_MODEL_ebdb9655a2c34932953a6a2cd3a2b205"
          }
        },
        "3120530da629482abe0582f707f1f010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bf54664aee84903a916352bb9485268",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ec9ad3273c4a3c848731a7510b1fc6",
            "value": "Downloading: 100%"
          }
        },
        "f1c57d85542b47149257302059b68fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8258ea0142de4e6bac76734a9b9610d2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab3f48841fcf4e2fb746bedf2597ec95",
            "value": 231508
          }
        },
        "ddd5221fea144ec0ad9a03799639d5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ff1ecc571ea4ba082dc0b263ff45b7d",
            "placeholder": "​",
            "style": "IPY_MODEL_31d5327109ed4127b22c6ecc882c4e40",
            "value": " 232k/232k [00:00&lt;00:00, 214kB/s]"
          }
        },
        "ebdb9655a2c34932953a6a2cd3a2b205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bf54664aee84903a916352bb9485268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ec9ad3273c4a3c848731a7510b1fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8258ea0142de4e6bac76734a9b9610d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab3f48841fcf4e2fb746bedf2597ec95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ff1ecc571ea4ba082dc0b263ff45b7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d5327109ed4127b22c6ecc882c4e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3338e914397b48558078e824b51f704a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_92d00fade76240078d50ff124ca739c0",
              "IPY_MODEL_ffcdfc9b18ba4111840f7cb8a52a2a6f",
              "IPY_MODEL_d20be3371c3a460b9a4d6d0a626a30bf"
            ],
            "layout": "IPY_MODEL_fc5a0c7ed6a447c19034107ccf1092e2"
          }
        },
        "92d00fade76240078d50ff124ca739c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c37bf7c4a542f6944b61023e4f5823",
            "placeholder": "​",
            "style": "IPY_MODEL_18b4f2404e2d4fa7aa5e394081b8f2d0",
            "value": "100%"
          }
        },
        "ffcdfc9b18ba4111840f7cb8a52a2a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8c1905af06410da8e1017a46c0a7a3",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b161414258bc4c4fab9a04ea9e888328",
            "value": 22
          }
        },
        "d20be3371c3a460b9a4d6d0a626a30bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b985d1987b8b477f9b7a65c8f6efd15f",
            "placeholder": "​",
            "style": "IPY_MODEL_c5f75518e18441e0981f6ed8cee4618a",
            "value": " 22/22 [00:20&lt;00:00,  1.24ba/s]"
          }
        },
        "fc5a0c7ed6a447c19034107ccf1092e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c37bf7c4a542f6944b61023e4f5823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18b4f2404e2d4fa7aa5e394081b8f2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8c1905af06410da8e1017a46c0a7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b161414258bc4c4fab9a04ea9e888328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b985d1987b8b477f9b7a65c8f6efd15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f75518e18441e0981f6ed8cee4618a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9d7599dba594a7e8ec1a0bdc2a88c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0432d06f05443b9888ae73ed0625760",
              "IPY_MODEL_e1e570a3005f4d7dba8d444bee9abdbc",
              "IPY_MODEL_cf515d848b9340ab9fc5b11e7008940d"
            ],
            "layout": "IPY_MODEL_5d852d02afa3494db6d323d771baa41d"
          }
        },
        "c0432d06f05443b9888ae73ed0625760": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9666fc914e024a67881d8a1828eebcce",
            "placeholder": "​",
            "style": "IPY_MODEL_967164e5dd6c40c9bf701a3f451e92b1",
            "value": "100%"
          }
        },
        "e1e570a3005f4d7dba8d444bee9abdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6eb826f879a4e598029923699164cb4",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8b2e2f7f8434d1fbffcd87be66217a6",
            "value": 21479
          }
        },
        "cf515d848b9340ab9fc5b11e7008940d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eacc919746994a3487060dd1d513087a",
            "placeholder": "​",
            "style": "IPY_MODEL_3eccab7450aa48d9911b0f585e6241cf",
            "value": " 21479/21479 [00:02&lt;00:00, 8014.74ex/s]"
          }
        },
        "5d852d02afa3494db6d323d771baa41d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9666fc914e024a67881d8a1828eebcce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967164e5dd6c40c9bf701a3f451e92b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6eb826f879a4e598029923699164cb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b2e2f7f8434d1fbffcd87be66217a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eacc919746994a3487060dd1d513087a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eccab7450aa48d9911b0f585e6241cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54ed691e396c4923928bd727b221446a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30f6c06d35d44179aa2bed871d3e2847",
              "IPY_MODEL_c3d569e1e2b64691ad136430ce38d8b1",
              "IPY_MODEL_8ca93f427c2e4dd5b10302f147e9403b"
            ],
            "layout": "IPY_MODEL_95efccc511c64c3cb54a47259099777c"
          }
        },
        "30f6c06d35d44179aa2bed871d3e2847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8c71cb6f1fd41878e3e24a434b8bed3",
            "placeholder": "​",
            "style": "IPY_MODEL_e1a475b832ac4d7594f81871fd07240c",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "c3d569e1e2b64691ad136430ce38d8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec069d256829486a8c4d25110d2dad78",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d5d0c27d92346d18f85d09a111d0650",
            "value": 21479
          }
        },
        "8ca93f427c2e4dd5b10302f147e9403b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b83efebdd8f24ca89f4a85d6e6f0025e",
            "placeholder": "​",
            "style": "IPY_MODEL_3f379f140fd946b0ab27e40c1b5713f2",
            "value": " 21479/21479 [00:15&lt;00:00, 61806.19 examples/s]"
          }
        },
        "95efccc511c64c3cb54a47259099777c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f8c71cb6f1fd41878e3e24a434b8bed3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1a475b832ac4d7594f81871fd07240c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec069d256829486a8c4d25110d2dad78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d5d0c27d92346d18f85d09a111d0650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b83efebdd8f24ca89f4a85d6e6f0025e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f379f140fd946b0ab27e40c1b5713f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}