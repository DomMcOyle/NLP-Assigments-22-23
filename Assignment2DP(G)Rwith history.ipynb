{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/NLP-Assigments-22-23/blob/Assignment-2/Assignment2DP(G)Rwith%20history.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d23b6c",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Team Members**: Domenico Dell'Olio, Giovanni Pio Delvecchio, Raffaele Disabato\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ada8c8",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c07553",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4907f8d",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: a question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3760b5",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cfee64",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "## The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996fa650",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3e7d0",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb6c37e",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa786e2",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26d68b7",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c7558c",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "8aUY2EWyoS0x",
        "outputId": "8e15dc9c-546b-4471-cc36-ba6914d4bfd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8aUY2EWyoS0x",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01cdad7",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell contains all the needed import for the assignment"
      ],
      "metadata": {
        "id": "M-WnbUQV8vHG"
      },
      "id": "M-WnbUQV8vHG"
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import urllib.request\n",
        "import pickle\n",
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_from_disk\n",
        "from evaluate import load\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "from transformers import logging\n",
        "\n",
        "logging.set_verbosity_error() # removes warning related to transformers"
      ],
      "metadata": {
        "id": "N6_2rsWowkPt"
      },
      "id": "N6_2rsWowkPt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also make use of drive to save all the results and to cope with the colab time restrictions"
      ],
      "metadata": {
        "id": "OzVfGmsV85MO"
      },
      "id": "OzVfGmsV85MO"
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xPPBaBkEa9N3",
        "outputId": "07a918fc-f024-401a-abcd-151fe2dbfc83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xPPBaBkEa9N3",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6643e14",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n",
        "The following two cells contain already given helper functions for the download of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "358bac70",
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5f6ab3ff",
      "metadata": {
        "id": "5f6ab3ff",
        "outputId": "089d4659-9a1a-43c9-e742-e61431ae5af1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CoQA train data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-train-v1.0.json: 49.0MB [00:08, 5.78MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n",
            "Downloading CoQA test data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-dev-v1.0.json: 9.09MB [00:03, 2.85MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test') "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e42311",
      "metadata": {
        "id": "40e42311"
      },
      "source": [
        "#### Dataset extraction and cleaning\n",
        "in the follwing cell we define the function to set the seed for the environment, in order to allow reproducibility and the function to format the dataset in (Question + Passage[+History], Answer) pairs. The latter also automatically removes unanswerable QA pairs and can add the history of the previous turns in the dialogue to the passage. In particular the history in inverted order: $P_i$ [SEP] $Q_{i-1}$[SEP]$A_{i-1}$[SEP] $Q_{i-2}$[SEP]$A_{i-2}$...[SEP]$A_{1}$\n",
        "\n",
        "In this way, when the input is truncated, we have an higher probabilty of retaining information releated to the current question, as usually the questions referring back to history are linked to immediately previous turns. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(SEED):\n",
        "  \"\"\"\n",
        "  Function to set the random seed and ensure reproducibilty of results.\n",
        "  :params:\n",
        "    SEED: integer representing the seed for pseudorandom generation to be set\n",
        "  \"\"\"\n",
        "  random.seed(SEED) # if you're using random\n",
        "  np.random.seed(SEED) # if you're using numpy\n",
        "  tf.random.set_seed(SEED) # setting the seed for tensorflow too\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "def extract_data(split_dataset,add_history=False,sep_char=\"[SEP]\"):\n",
        "  \"\"\"\n",
        "  function extracting data from the list of dictionaries in the CoQA dataset. It\n",
        "  removes unanswerable pairs and eventually adds history in an inverted way:\n",
        "  Pi sep_char Qi-1 sep_char Ai-1 ... A1. It also returns the source for each input\n",
        "  :params:\n",
        "    split_dataset: list of dictionaries from where to extract the pairs of question and passage and corresponding the answer\n",
        "    add_history: boolean flag that allows adding the history to the XQA output (default=False)\n",
        "    sep_char: string or character used as separation token by the input tokenizer for the encoder.\n",
        "      It is used to separate the different parts of the input\n",
        "  :returns:\n",
        "    XQA: list containing sublists [question, passage(+history)]\n",
        "    YQA: list containing answers\n",
        "    story_source: list containing the story source for each pair\n",
        "  \"\"\"  \n",
        "  XQA = [] # list that will contain pairs (P,Q)\n",
        "  YQA = [] # list that will contain the Answers\n",
        "  story_source = [] #list that will contain the category/source for each example\n",
        "  for d in split_dataset: # scan each document\n",
        "    for i in range(len(d[\"questions\"])): # scan each question\n",
        "      if d[\"answers\"][i][\"span_end\"]!=-1: # discard unanswerable questions\n",
        "        single_example = [] # prepare the single example...\n",
        "        single_example.append(d[\"questions\"][i][\"input_text\"]) #... with the question ...\n",
        "        single_example.append(d[\"story\"]) # ...and the passage\n",
        "        if add_history:\n",
        "          for j in range(i-1,-1,-1): # add the history from the last pairs\n",
        "            if d[\"answers\"][j][\"span_end\"]!=-1: # excluding unanswerable questions\n",
        "              single_example[1] = single_example[1] + sep_char + d[\"questions\"][j][\"input_text\"]+ sep_char + d[\"answers\"][j][\"input_text\"]\n",
        "              \n",
        "        XQA.append(single_example) # and append it\n",
        "        YQA.append(d[\"answers\"][i][\"input_text\"]) # add the answer\n",
        "        story_source.append(d[\"source\"]) # add the source\n",
        "  return XQA, YQA, story_source"
      ],
      "metadata": {
        "id": "h7_OLYpXkm56"
      },
      "id": "h7_OLYpXkm56",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f57334e0",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set the seed before splitting with the function previously defined"
      ],
      "metadata": {
        "id": "HMRr7khYBY5h"
      },
      "id": "HMRr7khYBY5h"
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42 \n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "4Q6YfLkhyFXZ"
      },
      "id": "4Q6YfLkhyFXZ",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block data is splitted as required (80% train, 20% validation) and extracted with or without history. Some examples from each split are printed."
      ],
      "metadata": {
        "id": "rjJf6SNLBdWF"
      },
      "id": "rjJf6SNLBdWF"
    },
    {
      "cell_type": "code",
      "source": [
        "add_history=True\n",
        "\n",
        "with open('coqa/train.json') as f:\n",
        "  # loading the training json\n",
        "  train_json = json.load(f)\n",
        "\n",
        "with open('coqa/test.json') as f:\n",
        "  # loading the test json\n",
        "  test_json = json.load(f)\n",
        "\n",
        "# splitting training data\n",
        "train_data, val_data = train_test_split(train_json[\"data\"],\n",
        "                                        train_size=0.8,\n",
        "                                        shuffle=True,\n",
        "                                        random_state=seed)\n",
        "# extracting X as list of pairs [Question, Passage] and Y as a list of strings (Answers) \n",
        "XQA_train, YQA_train, source_train = extract_data(train_data, add_history)\n",
        "XQA_val, YQA_val, source_val = extract_data(val_data, add_history)\n",
        "XQA_test, YQA_test, source_test = extract_data(test_json[\"data\"], add_history)\n",
        "del(train_json)\n",
        "del(test_json)\n",
        "\n",
        "print(\"Fourth training example:\")\n",
        "print(XQA_train[3])\n",
        "print(YQA_train[3])\n",
        "print(source_train[3])\n",
        "print(\"Fourth validation example:\")\n",
        "print(XQA_val[3])\n",
        "print(YQA_val[3])\n",
        "print(source_val[3])\n",
        "print(\"Fourth test example:\")\n",
        "print(XQA_test[3])\n",
        "print(YQA_test[3])\n",
        "print(source_test[3])\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "id": "0s8Ux69Fq1j-",
        "outputId": "9867c39a-9027-4885-fde9-af58c6026253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0s8Ux69Fq1j-",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fourth training example:\n",
            "['When was the last one held?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. [SEP]What day of the week did they vote?[SEP]Sunday[SEP]What is being voted on?[SEP]Representatives  are being chosen[SEP]Where is this taking place?[SEP]Tunisia']\n",
            "1956\n",
            "cnn\n",
            "Fourth validation example:\n",
            "['When was the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. [SEP]What was the score?[SEP]3-0[SEP]who was playing against them?[SEP]Manchester City[SEP]Who was playing in the game?[SEP]the team from Liverpool\"]\n",
            "Monday\n",
            "cnn\n",
            "Fourth test example:\n",
            "['Who did she live with?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "with her mommy and 5 sisters\n",
            "mctest\n",
            "Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the data exploration phase, we noticed an extremely wrong example in the dataset due to its length. We decided to fix it before training the net."
      ],
      "metadata": {
        "id": "9C4nQSOwB6o1"
      },
      "id": "9C4nQSOwB6o1"
    },
    {
      "cell_type": "code",
      "source": [
        "## broken example fix:\n",
        "print(XQA_train[61])\n",
        "print(YQA_train[61])\n",
        "YQA_train[61] = 'October'\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mOxQbmUq0W",
        "outputId": "09d8b619-7283-4707-a215-e39d05a6466f"
      },
      "id": "o4mOxQbmUq0W",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what month?', 'Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features. \\n\\nIn 1981, Microsoft hired Charles Simonyi, the primary developer of Bravo, the first GUI word processor, which was developed at Xerox PARC. Simonyi started work on a word processor called \"Multi-Tool Word\" and soon hired Richard Brodie, a former Xerox intern, who became the primary software engineer. \\n\\nMicrosoft announced Multi-Tool Word for Xenix and MS-DOS in 1983. Its name was soon simplified to \"Microsoft Word\". Free demonstration copies of the application were bundled with the November 1983 issue of \"PC World\", making it the first to be distributed on-disk with a magazine. That year Microsoft demonstrated Word running on Windows.[SEP]when was it first released?[SEP]1983[SEP]Name a few other platforms that it was written for later.[SEP]IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985),[SEP]when?[SEP]November 1983[SEP]What magazine were distributed demo copies?[SEP]PC World[SEP]What is Microsoft word?[SEP]a word processor[SEP]what is that?[SEP]first GUI word processor[SEP]what did he develope?[SEP]Bravo[SEP]What did he do?[SEP]developer[SEP]Who did they hire in 1981?[SEP]Charles Simony']\n",
            "Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features.\n",
            "October\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block the two tokenizers (one for the encoder and one for the decoder) are created. The encoder tokenizer (<code>input_tokenizer</code>) is pre-trained, while the decoder tokenizer (<code>output_tokenizer</code>) is fit on the training set (with the addtion of the tokens <code>\\<start></code> and <code>\\<end></code>) alone. Moreover, to simplify generation, the tokenizer lowercases characters and filters everything but the <code>'</code>, <code>\\<</code> and <code>\\></code> tokens.\n",
        "\n",
        "\n",
        "In order to keep the computational complexity low and allow training under colab restrictions, we limited the input maximum dimension to 512 tokens (which is the maximum for the two bert variants considered) truncating on the passage string and the output maximum dimension to 20 tokens, which is a bit more than the $99^{th}$ percentile of the lenghts of the answers. Both inputs and outputs are padded."
      ],
      "metadata": {
        "id": "_JTAOJXPCH3b"
      },
      "id": "_JTAOJXPCH3b"
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL NAME\n",
        "model_name = 'distilroberta-base'\n",
        "#model_name = 'prajjwal1/bert-tiny'\n",
        "\n",
        "## FILTER\n",
        "filter = '!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "\n",
        "def filter_string(x):\n",
        "  \"\"\"\n",
        "  function required to apply filtering on a string in the same way it was applied by the tokenizer.\n",
        "  it is mainly used when storing the dataset splits.\n",
        "  \"\"\"\n",
        "  return re.sub('[' + filter + ']',\"\",x)\n",
        "  \n",
        "#create and fit the tokenizer\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filter, oov_token='<UNK>')\n",
        "output_tokenizer.fit_on_texts([\"<start> \" + i + \" <end>\" for i in YQA_train])\n",
        "\n",
        "# import the required tokenizer\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(\"Max input output found: \" + str(max([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)])))\n",
        "print(np.argmax([len(i) for i in YQA_train]))\n",
        "print(XQA_train[7529])\n",
        "print(YQA_train[7529])\n",
        "\n",
        "print(\"99° percentile of training set answer length:\" + str(np.quantile([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)], 0.99)))\n",
        "\n",
        "# actual percentile is 17, given that each string has the beginnning and ending token\n",
        "max_sequence_length = 20\n",
        "max_input_length = 512\n",
        "\n",
        "# this suffix is used when saving the pre-processed dataset split\n",
        "dataset_suffix = \"_hist\" if add_history else \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "44c92f70d51445aeba4a88634118cfa5",
            "8a69a5df68484a8abcbe921738b05733",
            "2d2005b4ae3b40f4b35f106b0fe2c821",
            "cc6a8aac265f4718b8618eb92f9fb18c",
            "4a95eda09682413f95c457f91780081a",
            "18e347a9cf0f449e899414cac02ead43",
            "37e624ff8f244f6e8afe8b6bdf36b0bc",
            "5e329caf173d4623a720f082a9acff29",
            "a7bf3beff83b4f328686cc9b81e04dd9",
            "29cff18d2f1c43018b006a6bc71ac3e5",
            "e8a693af87b246e39a002302aabfe739",
            "a6f51a016d264f1eb85071dc37b7b7a9",
            "351314f7e10346989a9a9eb8cd43c9f3",
            "1464be09ed2f44d49fa6762c6c66b237",
            "f8817ac5ab424f05bdbda261fa703603",
            "bee5328ba2174cea9a192ed29c507765",
            "52f52b2538f84e84a5cbebb06ef3c57e",
            "2d463d4fcc7c447ea37cb9a3b5d837ee",
            "3766b037385b4957abc32ee4e382bc6d",
            "a0bfbf9f713c49318a060502edbdeeff",
            "d77d211ee309472c8b4a4f5f234bf5ac",
            "39285a05bcf24321ad5411e04d45712d",
            "2b09311a71804a1ca1aa458be4a206cc",
            "106c6e88517c4a5c8cb56f91b1fb4cbe",
            "cf837f5ef6be468aa28e80651d4597ed",
            "9088e12eeb4a4608901d0fa52a1396b4",
            "9f53190325894c028e7b8a4c69d35d17",
            "95173ed6eeba4f8fa4c921f9716ae8e8",
            "8e27a4428b284a82831b5bc888052bc4",
            "c6cbc67139ea46dc891e0392ea78de4c",
            "82fd6d341c094ad5ab182c063148d86e",
            "2c7f96badcfd463ea7385ca3776ae3cd",
            "4c94483778564b46ac06ee64c707f9c4",
            "1bd41687be904c3fb9a7ad0289c0e6d0",
            "78bc5f6558294884847858240edc5d7b",
            "b2018aef547146aabab70f0e90db9646",
            "ddaf89e1320b44808d33f01f250f156e",
            "4950ee1d976346269fb0c5ce4c9e372d",
            "3ea9fb3b2aee4fe783d02e53d7b1974a",
            "5d8cd3d744b74828a793cd877b45d401",
            "eaf06a81affc47c49ea90cc942b10337",
            "4cdac443da464807acec14c3e5b57035",
            "e06390ea463f4757bb6f90f8a170d6ca",
            "1df3cf36c9a3457cae50d32cfc691c4a"
          ]
        },
        "id": "bRzqq374GQOC",
        "outputId": "3d110945-0efe-4c0f-b76d-79cfd2f356bf"
      },
      "id": "bRzqq374GQOC",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44c92f70d51445aeba4a88634118cfa5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6f51a016d264f1eb85071dc37b7b7a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b09311a71804a1ca1aa458be4a206cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bd41687be904c3fb9a7ad0289c0e6d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input output found: 83\n",
            "99° percentile of training set answer length:13.0\n",
            "7529\n",
            "[\"What symptoms of addiction does Orzack's center list?\", 'Caught in the Web A few months ago, it wasn\\'t unusual for 47-year-old Carla Toebe to spend 15 hours per day online. She\\'d wake up early, turn on her laptop and chat on Internet dating sites and instant-messaging programs - leaving her bed for only brief intervals. Her household bills piled up, along with the dishes and dirty laundry, but it took near-constant complaints from her four daughters before she realized she had a problem. \"I was starting to feel like my whole world was falling apart - kind of slipping into a depression,\" said Carla. \"I knew that if I didn\\'t get off the dating sites, I\\'d just keep going,\" detaching herself further from the outside world. Toebe\\'s conclusion: She felt like she was \"addicted\" to the Internet. She\\'s not alone. Concern about excessive Internet use isn\\'t new. As far back as 1995, articles in medical journals and the establishment of a Pennsylvania treatment center for overusers generated interest in the subject. There\\'s still no consensus on how much time online constitutes too much or whether addiction is possible. But as reliance on the Web grows, there are signs that the question is getting more serious attention: Last month, a study published in CNS Spectrums claimed to be the first large-scale look at excessive Internet use. The American Psychiatric Association may consider listing Internet addiction in the next edition of its diagnostic manual. And scores of online discussion boards have popped up on which people discuss negative experiences tied to too much time on the Web. \"There\\'s no question that there\\'re people who\\'re seriously in trouble because they\\'re overdoing their Internet involvement,\" said psychiatrist Ivan Goldberg. Goldberg calls the problem a disorder rather than a true addiction. Jonathan Bishop, a researcher in Wales specializing in online communities, is more skeptical. \"The Internet is an environment,\" he said. \"You can\\'t be addicted to the environment.\" Bishop describes the problem as simply a matter of priorities, which can be solved by encouraging people to prioritize other life goals and plans in place of time spent online. The new CNS Spectrums study was based on results of a nationwide telephone survey of more than 2,500 adults. Like the 2005 survey, this one was conducted by Stanford University researchers.About 6% of respondents reported that \"their relationships suffered because of excessive Internet use.\" About 9% attempted to conceal \"nonessential Internet use,\" and nearly 4% reported feeling \"preoccupied by the Internet when offline.\" About 8% said they used the Internet as a way to escape problems, and almost 14% reported they \"found it hard to stay away from the Internet for several days at a time.\" \"The Internet problem is still in its infancy,\" said Elias Aboujaoude, a Stanford professor. No single online activity is to blame for excessive use, he said. \"They\\'re online in chat rooms, checking e-mail, or writing blogs. not limited to porn or gambling\" websites. Excessive Internet use should be defined not by the number of hours spent online but \"in terms of losses,\" said Maressa Orzack, a Harvard University professor. \"If it\\'s a loss you\\'re not getting to work, and family relationships are breaking down as a result, then it\\'s too much.\" Since the early 1990s, several clinics have been established in the U. S. to treat heavy Internet users. They include the Center for Internet Addiction Recovery and the Center for Internet Behavior. The website for Orzack\\'s center lists the following among the psychological symptoms of computer addiction: * Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders, Orzack said. When she discusses Internet habits with her patients, they often report that being online offers a \"sense of belonging, and escape, excitement fun,\" she said. \"Some people say relief...because they find themselves so relaxed.\" Some parts of the Internet seem to draw people in more than others. Internet gamers spend countless hours competing in games against people from all over the world. One such game, called World of Warcraft, is cited on many sites by posters complaining of a \"gaming addiction.\" Andrew Heidrich, an education network administrator from Sacramento, plays World of Warcraft for about two to four hours every other night, but that\\'s nothing compared with the 40 to 60 hours a week he spent playing online games when he was in college. He cut back only after a full-scale family intervention , in which s told him he\\'d gained weight. \"There\\'s this whole culture of competition that sucks people in\" with online gaming, said Heidrich, now a father of two. \"People do it at the expense of everything that was a constant in their lives.\" Heidrich now visits websites that discuss gaming addiction regularly \"to remind myself to keep my love for online games in check.\" Toebe also regularly visits a site where posters discuss Internet overuse. In August, when she first realized she had a problem, she posted a message on a Yahoo Internet addiction group with the subject line: \"I have an Internet Addiction.\" \"I\\'m self-employed and need the Internet for my work, but I\\'m failing to accomplish my work,to take care of my home, to give attention to my children,\" she wrote in a message sent to the group.\"I have no money or insurance to get professional help; I can\\'t even pay my mortgage and face losing everything.\" Since then, Toebe said, she has kept her promise to herself to cut back on her Internet use. \"I have a boyfriend now, and I\\'m not interested in online dating,\" she said by phone last week. \"It\\'s a lot better now.\"[SEP]What problems with addiction did Andrew have?[SEP]gained weight[SEP]What video game has been associated with addiction?[SEP]World of Warcraft[SEP]What problems did Carla have as a result of her addiction?[SEP]depression, bills piling up, household falling apart[SEP]How do you determine if someone is addicted to the internet?[SEP]There\\'s still no consensus[SEP]When did internet addiction first become known as a problem?[SEP]1995[SEP]Has the American Psychiatric Association listed Internet Addiction in its diagnostic manual?[SEP]No[SEP]Why was this a problem?[SEP]She was detached from daily life[SEP]What did Carla spend most of her day doing?[SEP]chat on Internet dating sites']\n",
            "Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following three cells are used to create a HuggingFace <code>Dataset</code> for each split, after having chosen the model that will be used (tiny bert and distilroberta have different input tokenizer) and if it will contain also the history. The <code>Dataset</code> allows managing big datasets by reading only what's needed and when's needed from the disk.\n",
        "\n",
        "The test and validation split will have an additional column (\"references\") which will contain a dictionary containing the keys \"answer\" and \"id\". \"answer\" has as value another dictionary containing the text of the answer (lowercased and stripped from punctuation as done by the tokenizer) and a placeholder \"answer_start\". While the \"id\" has the index of the example cast into string as value, which identifies uniquely the answer in the split. This organization was needed to use the SQUAD-F1 implementation by the library <code>evaluate</code> of HuggingFace. "
      ],
      "metadata": {
        "id": "TgWkxgFQFGCV"
      },
      "id": "TgWkxgFQFGCV"
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate training split dataset\n",
        "# EXECUTE ONLY IF NEEDED\n",
        "\n",
        "# create dictionary\n",
        "train_ds = Dataset.from_dict({\"xqa\": XQA_train, \n",
        "                              \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_train],\n",
        "                              \"source\":source_train})\n",
        "# tokenize input\n",
        "train_ds = train_ds.map(lambda x: input_tokenizer(x[\"xqa\"], \n",
        "                                                  return_tensors=\"tf\", \n",
        "                                                  padding=\"max_length\", \n",
        "                                                  truncation=\"longest_first\", \n",
        "                                                  max_length=max_input_length), \n",
        "                        batched=True)\n",
        "# tokenize output\n",
        "train_ds = train_ds.map(lambda x: {\"y_token\": output_tokenizer.texts_to_sequences(x[\"yqa\"])}, \n",
        "                        batched=True)\n",
        "# pad output\n",
        "train_ds = train_ds.map(lambda x: {\"y_padded\": tf.keras.preprocessing.sequence.pad_sequences(x[\"y_token\"],\n",
        "                                                                     padding='post',\n",
        "                                                                     maxlen=max_sequence_length)},\n",
        "                         batched=True)\n",
        "# remove working columns\n",
        "train_ds = train_ds.remove_columns([\"xqa\", \"yqa\", \"y_token\"])\n",
        "# format tensors\n",
        "train_ds = train_ds.with_format(type=\"tensorflow\")\n",
        "\n",
        "# save on drive\n",
        "if model_name == 'prajjwal1/bert-tiny':\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds\" + dataset_suffix)\n",
        "else:\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "nErpyDpLhRV8",
        "outputId": "c5147e35-4aaf-41a0-ceed-daa011558ce5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "5bd1337bc16e431a945d91419f08b570",
            "624b7eaf24dd4ca9a2bab42e625e7b23",
            "4435751b55fe46b58ea6a571a8a28a98",
            "1c7578d1c0654a5882254ad544c82fd4",
            "46edd2b91c1e43859975368e59d5e46e",
            "0dfc7ad83e12402fb05843e5a2cfeb90",
            "c1c5f9fe435842108e28673da86b74eb",
            "17c6bd12ff95409b8c7ea10c2dec1b9c",
            "df3325bf87b24d9a9b87bb37df4900c9",
            "ff90be31268849ac8f391fc1fbe2931e",
            "f64c92fc7ab242b296df5df1ae565783",
            "a56b9400f24b4506b99112d9258f0bb2",
            "8f8a92a4e5c1406b94095b8ceff4ee99",
            "281598e24b7147e3ab9733b3c953fed2",
            "ed41b8d67962432b91dcb045bb7305af",
            "5fff8d4f4d474502a44c8ea6ffd50086",
            "e02079bb28434e12915633e51267047f",
            "5d88f575dc0e47e4ab5323b66ff71ec2",
            "f209fd6954994ab4948682cb90ac5cb0",
            "ad18e03447114e8a857836cf711160b3",
            "077a694007d24b18a140281edeab976b",
            "eadd5c9121b8460c998fc9a285c6506d",
            "2405da8484eb4b8e8247688d0e02dc82",
            "6b936e7581e644e98ef84cb3b7a3d840",
            "370deb64231a4ae1b42610bfa4665486",
            "afa3624556434dd596378f577ac1037c",
            "bf58fd99a15d4538a6e92768f9fa735c",
            "27843725e3b84b81aa5d9e465bfdc320",
            "c261e9123be046e1b04723cc097745be",
            "f0f7b209e8e344d1bc20f3881c9bfbed",
            "1f5365ee933c4bc3b8a0febe0290a0e8",
            "fce44261845642ceb7f0dfdfe453621c",
            "84d9854c7daf479da2f3322395866d17",
            "c76f5c7f4a4945a3893576388e4db546",
            "37b78047e5e941609bfcdab4565d3e34",
            "d84ca56e55714667a0dffc6296e9d3d2",
            "10a43dbe50d4489d9e413da54a03d1bb",
            "c49374eb6d044460950a0da7394bf7d1",
            "1fbe610571e34f808c3c73a6102275ca",
            "107c68c0a6ed4a1a8a68f3246342f9ff",
            "09af26594af34adab0e4253926553688",
            "b6d8bc02f4844ee9becd49046c8bed73",
            "3be9d52dde60465c94727836955d165d",
            "38a1dfa473f847f696b94fa0ad0013e8"
          ]
        }
      },
      "id": "nErpyDpLhRV8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bd1337bc16e431a945d91419f08b570"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a56b9400f24b4506b99112d9258f0bb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2405da8484eb4b8e8247688d0e02dc82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/85807 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c76f5c7f4a4945a3893576388e4db546"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate validaion split dataset\n",
        "# EXECUTE ONLY IF NEEDED\n",
        "\n",
        "# create dictionary\n",
        "val_ds = Dataset.from_dict({\"xqa\": XQA_val,\n",
        "                            \"yqa\": [filter_string(i.lower()) for i in YQA_val],\n",
        "                            \"id_placeholder\": list(range(len(YQA_val))),\n",
        "                            \"source\":source_val})\n",
        "# tokenize input\n",
        "val_ds = val_ds.map(lambda x: input_tokenizer(x[\"xqa\"],\n",
        "                                              return_tensors=\"tf\",\n",
        "                                              padding=\"max_length\",\n",
        "                                              truncation=\"longest_first\",\n",
        "                                              max_length=max_input_length),\n",
        "                     batched=True)\n",
        "# add references\n",
        "val_ds = val_ds.map(lambda x:{\"references\": \n",
        "                              {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "                                'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "# remove working columns\n",
        "val_ds = val_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "# save to drive\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds\" + dataset_suffix)\n",
        "else:\n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "776e8997f6d4457896027e25435bd136",
            "0413a3cc0ca449f3ba1872e618cd4a28",
            "8a0ee58f67d048a3bc490a15b80bc22c",
            "03822042f6a144fca4d30d7084c67647",
            "8285759e2dee4a139135e288aa4c09be",
            "e2d835f8d4eb40bb857612fa0f76cdde",
            "e97a9ef2f7cf4e41a873d403133ac667",
            "39d95039cb424cbf8cb1eec98d7ebf8c",
            "3a01b34f58c2427e9336d8e3b5d4e1e8",
            "953f56d7c6004e07b4fe7327b7a7e8ad",
            "61d0694679c74efcb3120210042d2853",
            "813ffbd42adf47bd866881800b623977",
            "ec7d4998ece34a6896d7aa63f598366b",
            "59226e51ddef4ac5805c6bb74711b543",
            "a31bb6c9cdce436d9134de11ef4f62ab",
            "a0c2e563ea9d466db751703148a884cd",
            "acb3522cf30b44b784c7f6616d24e6f7",
            "9824ecdc6bd3459ca32368349f0a03a5",
            "3f93cd99da4d47328b32eba2bf9282c7",
            "09b7b0d268a1448d991254eac5036f54",
            "d1aa7a38536049fda9a95f0b712fd563",
            "07d9d018ad314f389196ead6241ac251",
            "2ce5b1cabdf84977ad674347963410a7",
            "273ca89a769240a8aa8106c9b5cec519",
            "694c84af95fb4010974868438149cc60",
            "0beba010f657448d8151148006e51cc3",
            "2b7a739e9f4b488d884b1477ec1f344b",
            "38f9382be394422b9d7147fa10ec8017",
            "805706bcdc1d4dadb4a61bb08ed60f6b",
            "010f4a329db94ecdaabea6d3ecbc845f",
            "0b97adc55f6a4177bacf9d9b56bdb4af",
            "7cd64219b7ad40239d8dcfe1bb54385e",
            "5be6678c69f5431991601de29e9f21dc"
          ]
        },
        "id": "b9VyzKdnAuKz",
        "outputId": "848da777-cb2e-4ae1-828c-c32e65c47caa"
      },
      "id": "b9VyzKdnAuKz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "776e8997f6d4457896027e25435bd136"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/21479 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "813ffbd42adf47bd866881800b623977"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/21479 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ce5b1cabdf84977ad674347963410a7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate test split dataset\n",
        "# EXECUTE ONLY IF NEEDED\n",
        "\n",
        "# create dictionary\n",
        "test_ds = Dataset.from_dict({\"xqa\": XQA_test,\n",
        "                             \"yqa\": [filter_string(i.lower()) for i in YQA_test],\n",
        "                             \"id_placeholder\": list(range(len(YQA_test))),\n",
        "                             \"source\":source_test})\n",
        "# tokenize input\n",
        "test_ds = test_ds.map(lambda x: input_tokenizer(x[\"xqa\"],\n",
        "                                                return_tensors=\"tf\",\n",
        "                                                padding=\"max_length\",\n",
        "                                                truncation=\"longest_first\",\n",
        "                                                max_length=max_input_length),\n",
        "                       batched=True)\n",
        "# add references\n",
        "test_ds = test_ds.map(lambda x:{\"references\":\n",
        "                                {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "                                  'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "# remove working columns\n",
        "test_ds = test_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "# save to drive\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds\" + dataset_suffix)\n",
        "else:\n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "83_mH8gTRY5z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "c0109beae5794bde9205e0472492247b",
            "e0c19cfae8ee413bbc609554c4f7b7fb",
            "eb5f2221c2c34e178bf63eb951c8b364",
            "c0a0a3ca88ee4e0a89ffc3d8764ab422",
            "a2df50f8ec134d68bc9eedbf72a82d07",
            "d16fd76e11a141eda802867957bbf1fd",
            "85b6c27036574928b2fbe3ca46fbe70b",
            "8eda94a2471f42a2a053c8056e733a51",
            "923afc43e2df4769926aab1a6538a455",
            "87f9076e747a48909bde7e0e06df4ea6",
            "fcbdbecd070045bb8ebb1ba74c74eeb9",
            "b78fe51459504e95a5ac26ba47d9a039",
            "bf54fcfd0cd247ffa81c36a13f10febb",
            "434ea6be2d994423bb5bb02e008e4b6f",
            "3c68ac9b84894bec974a218229655897",
            "0c805526d5094699b17bd178bd3e929b",
            "a64d0693afc64073bad450e686a3bf26",
            "25e739df9b9d45b7aac69761722f01af",
            "356c91e8155d4734a7a54cb84e4b520f",
            "8239b71822054c3285d9149edf198d29",
            "3ebb85ea66174a26a362e814978dcff8",
            "7c61fa7981ca432499623ef6ca9e89f3",
            "039c5405ee7644d5bdb7e7aa0daefa09",
            "9ff7d5d25a8a4fdbacb13849e475028b",
            "aa68da4d34b94755a8fb2e6d3db79aba",
            "c8b8aadea5624c70bf778d5392f54178",
            "518416137aba4b8c809b263d3fe659be",
            "94f48493b6464d8d9fbe34518325aee1",
            "8a3dea3833bc4e23b2296901d9500f45",
            "342c3e64589a4e41a8ca34a14b9c678a",
            "36d912985df846d49a5e4f6407b05346",
            "8db3efc9039246a3a424740e15c049eb",
            "5cd50e430ca54ec9a01157eed41d214e"
          ]
        },
        "outputId": "76a23be8-9f08-436a-e45b-300d3d5a52af"
      },
      "id": "83_mH8gTRY5z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0109beae5794bde9205e0472492247b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7918 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b78fe51459504e95a5ac26ba47d9a039"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/7918 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "039c5405ee7644d5bdb7e7aa0daefa09"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230a21de",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following cell defines the model we are proposing for the task. It is a Bert2LSTM (or seq2seq) model with Attention, adapted from the tutorial [<code>tf_seq2seq_lstm.py</code>](https://www.tensorflow.org/addons/tutorials/networks_seq2seq_nmt). Differently from the tutorial, the input part is handled by a frozen Bert encoder model, which outputs the intermediate encoding of the input as well as a further elaborated encoding of the first token. The latter is discarded and substuted with two newly learned used as the first hidden and cell state for the following LSTM decoder. The first one is obtained starting from the embedding of the first token, the second one is obtained after applying a 1D average pooling on the whole output and then passed to a dense layer.\n",
        "\n",
        "Also, the numbers of decoding cells have been expanded to 128 for the tiny bert model and 256 for the distilroberta model (considering that tiny bert output tensors with 128 dimensions for each token and distilroberta output tensors with 768 dimensions).\n",
        "\n",
        "Finally the model can both generate answers with a greedy sampling strategy or with a beam search."
      ],
      "metadata": {
        "id": "QXB4KQ71JKmS"
      },
      "id": "QXB4KQ71JKmS"
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- #\n",
        "# MODEL DEFINITION #\n",
        "# ---------------- #\n",
        "\n",
        "\n",
        "# check if training can be performed on GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class to train the model\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included) \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "      \"\"\"\n",
        "      init function for the model. It requires the encoder and decoder distance, as well as\n",
        "      the maximum allowed length for the output to be generated. It also sets the loss function\n",
        "      and the optimizer\n",
        "      :params:\n",
        "        encoder: Encoder class instance\n",
        "        decoder: Decoder class instance\n",
        "        max_length: maximum allowed lenght for the output\n",
        "      \"\"\"\n",
        "      self.encoder = encoder\n",
        "      self.decoder = decoder\n",
        "      self.max_length = max_length\n",
        "      self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                                reduction='none') # from logits means that it returns values after a \n",
        "                                                                                  # softmax application, thus it is useless to\n",
        "                                                                                  # add a softmax activation layer if this parameter is set to \n",
        "                                                                                  # true (or even dangerous because it squashes the values)\n",
        "      self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "      \"\"\"\n",
        "      Function to compute the loss.\n",
        "      :params:\n",
        "        logits: values computed by the network\n",
        "        target: labels to compare with logits\n",
        "      \"\"\"\n",
        "      loss = self.ce(y_true=target, y_pred=logits)\n",
        "      mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "      mask = tf.cast(mask, dtype=loss.dtype)\n",
        "      loss *= mask # pointwise product\n",
        "      return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "      \"\"\"\n",
        "      Function executing a single step of training.\n",
        "      :param:\n",
        "        inputs: dictionary containing the tokenized inputs ('input_ids'), the \n",
        "          attention mask ('attention_mask') and the token type indexes ('token_type_ids')\n",
        "          if the model is tiny bert-based.\n",
        "      \"\"\"\n",
        "      with tf.GradientTape() as tape:\n",
        "            \n",
        "          if self.encoder.use_token_type_ids:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask'],\n",
        "                                                                  'token_type_ids': inputs['token_type_ids']})\n",
        "          else:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask']})\n",
        "          decoder_input = inputs['y_padded'][:, :-1]  # ignore <end>\n",
        "          real_target = inputs['y_padded'][:, 1:]  # ignore <start>\n",
        "\n",
        "          # setup in order to perform attention queries over the embedding space\n",
        "          self.decoder.attention.setup_memory(encoder_output) \n",
        "\n",
        "          # decoder initialization, check build_initial_state for additional insights\n",
        "          decoder_initial_state = self.decoder.build_initial_state(self.decoder.batch_size, [encoder_h, encoder_s])\n",
        "\n",
        "          # the input is then passed to the initialized decoder and we obtain predictions\n",
        "          # in rnn_output format because the model is BERT-emdedding-sequence-sequence, so the\n",
        "          # last layer is still a sequence of cells (a RNN)\n",
        "          predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "\n",
        "          # we compute the losses over the computed predictions\n",
        "          loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "      # gradients of the loss computed for this minibatch considering trainable\n",
        "      # parameters of encoder and decoder\n",
        "      grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "      return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "      \"\"\"\n",
        "      function executing a single step of training, updating the gradients.\n",
        "      :param:\n",
        "        inputs: dictionary containing the tokenized inputs ('input_ids'), the \n",
        "          attention mask ('attention_mask') and the token type indexes ('token_type_ids')\n",
        "          if the model is tiny bert-based.\n",
        "      \"\"\"\n",
        "      loss, grads = self.train_op(inputs=inputs)\n",
        "      # applies gradients to the trainable variables using Adam\n",
        "      self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "      return loss\n",
        "\n",
        "    def generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None):\n",
        "      \"\"\"\n",
        "      function to generate (a batch of) answers with a greedy sampling technquique\n",
        "      :params:\n",
        "        output_tokenizer: the tokenizer instance used to split and analyze output sequences\n",
        "        input_ids: indexes of the input tokens\n",
        "        token_type_ids: indexes indicating which part of the input a token belongs to (only tiny bert)\n",
        "        attention_mask: indexes indicating which part of the input is padding\n",
        "      \"\"\"\n",
        "      batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "\n",
        "      if self.encoder.use_token_type_ids:\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "      else:\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "      # padding the placeholders  \n",
        "      start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "      end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "\n",
        "      # We could not do this at training time, since the Sampler used at training\n",
        "      # is not designed to project the token in an embedding space before computing\n",
        "      # the next one. The aforementioned embedding space\n",
        "      # is changing at each backpropagation step anyways, thus we stick with\n",
        "      # the computation of the argmax of the logits using TrainingSampler.\n",
        "      greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler() \n",
        "\n",
        "      # we have a decoder for training and a decoder for test time, thus\n",
        "      # we need to re-define the training decoder each time we want to\n",
        "      # train a new batch\n",
        "      decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "      \n",
        "      self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "      # decoder_initial_state is still an output of the encoder, we pass it to\n",
        "      # the decoder_instance in order to get the outputs\n",
        "      decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        \n",
        "      decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "      outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "      return outputs\n",
        "\n",
        "    def translate(self, generated, output_tokenizer):\n",
        "      \"\"\"\n",
        "      function to translate the sequence of indexes produced by the greedy decoder\n",
        "      in sentences.\n",
        "      :params:\n",
        "        generated: generated sequences of token indexes\n",
        "        output_tokenizer: the tokenizer instance used to split and analyze output sequences\n",
        "      \"\"\"\n",
        "      return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "    def beam_translate(self, generated, output_tokenizer):\n",
        "      \"\"\"\n",
        "      function to translate the sequence of indexes produced by the beam search decoder\n",
        "      in sentences. it recovers only the best scoring sequence\n",
        "      :params:\n",
        "        generated: generated sequences of token indexes\n",
        "        output_tokenizer: the tokenizer instance used to split and analyze output sequences\n",
        "      \"\"\"\n",
        "      return output_tokenizer.sequences_to_texts(generated[0][:,0,:])\n",
        "\n",
        "    def beam_generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None, beam_width=3, length_penalty=1.5):\n",
        "      \"\"\"\n",
        "      function to generate (a batch of) answers with a beam search techinques, allowing to control the number\n",
        "      of beams and the penalty to be added to long sequences\n",
        "      :params:\n",
        "      output_tokenizer: the tokenizer instance used to split and analyze output sequences\n",
        "      input_ids: indexes of the input tokens\n",
        "      token_type_ids: indexes indicating which part of the input a token belongs to (only tiny bert)\n",
        "      attention_mask: indexes indicating which part of the input is padding\n",
        "      beam_width: number of sequences to consider at each step (default=3)\n",
        "      lenght_penalty: length penalty parameter to be added to reweight the different sequences generated (default=1.5)\n",
        "      \"\"\"\n",
        "      batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "\n",
        "      if self.encoder.use_token_type_ids:\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "      else:\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "      # padding the placeholders    \n",
        "      start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "      end_token = output_tokenizer.word_index['<end>']\n",
        "        \n",
        "      # From official documentation:\n",
        "      # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "      # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "      # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "      # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "\n",
        "      encoder_output = tfa.seq2seq.tile_batch(encoder_output, multiplier=beam_width)\n",
        "      self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "      # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "      hidden_state = tfa.seq2seq.tile_batch([encoder_h, encoder_s], multiplier=beam_width)\n",
        "      decoder_initial_state = self.decoder.build_initial_state(beam_width*batch_size, hidden_state)\n",
        "\n",
        "      # Instantiate BeamSearchDecoder\n",
        "      decoder_instance = tfa.seq2seq.BeamSearchDecoder(self.decoder.wrapped_decoder_cell,\n",
        "                                                          beam_width=beam_width,\n",
        "                                                          output_layer=self.decoder.generation_dense,\n",
        "                                                          length_penalty_weight=length_penalty,\n",
        "                                                          maximum_iterations=self.max_length)\n",
        "      decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "\n",
        "      # The BeamSearchDecoder object's call() function takes care of everything.\n",
        "      outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, \n",
        "                                                                  start_tokens=start_tokens,\n",
        "                                                                  end_token=end_token,\n",
        "                                                                  initial_state=decoder_initial_state)\n",
        "      # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
        "      # The final beam predictions are stored in outputs.predicted_id\n",
        "      # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
        "      # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
        "       # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
        "\n",
        "\n",
        "      # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "      # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "      # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
        "      final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
        "      beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
        "\n",
        "      return final_outputs.numpy(), beam_scores.numpy()\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Wrapper class for the Bert Encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "      \"\"\"\n",
        "      Constructor method for the encoder. It requires the string indicating the model\n",
        "      to be loaded and the number of decoder units used in the decoder, in order\n",
        "      to correctly resize its outputs.\n",
        "      :params:\n",
        "       model_name: string containg the name of the bert encoder to load\n",
        "        decoder_units: number of RNN decoder units used in the decoder\n",
        "      \"\"\"    \n",
        "      super(Encoder, self).__init__()\n",
        "      self.model = TFAutoModel.from_pretrained(model_name, from_pt=True, trainable=False)\n",
        "      self.model.trainable=False # the encoder model is frozen\n",
        "      self.reducer = tf.keras.layers.Dense(decoder_units) # reducer used to obtain the hidden state\n",
        "      self.reducer2 = tf.keras.layers.Dense(decoder_units) # reducer used to obtain the cell state\n",
        "      self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size = 512) # used to create the cell state\n",
        "      self.use_token_type_ids = model_name=='prajjwal1/bert-tiny' # flag used to see if token type ids must be considered.\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "      \"\"\"\n",
        "      call function of the encoder model. \n",
        "      It takes the input, passes them to the bert encoder, then it takes the input of the last layer.\n",
        "      From here, it takes the encoding of the first token and passes it to \"reducer\" layer \n",
        "      to obtain the hidden_state encoding and then\n",
        "      it takes everything, passes it through an average pooling and the \"reducer2\" layer to obtain \n",
        "      the cell state encoding.\n",
        "      :params:\n",
        "        inputs: inputs to the model\n",
        "        training: boolean flag required by the call function\n",
        "      \"\"\"\n",
        "      model_output = self.model(inputs)\n",
        "        \n",
        "      # all_outputs has shape (batch_size * 512 * 128/768)\n",
        "      all_outputs = model_output[0] # output of the last layer of the model\n",
        "        \n",
        "      # cls coding\n",
        "      hidden_pooled = all_outputs[:, 0, :]\n",
        "      cell_state = self.avg_pool(all_outputs)\n",
        "      cell_state = tf.reshape(cell_state, [all_outputs.shape[0], all_outputs.shape[2]])\n",
        "        \n",
        "      # pooled output has shape (batch_size * 128/256)\n",
        "      hidden_state = self.reducer(hidden_pooled)\n",
        "      cell_state = self.reducer2(cell_state)\n",
        "\n",
        "      return all_outputs, hidden_state, cell_state\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Wrapper class for the LSTM decoder\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "      \"\"\"\n",
        "      Constructor method for the decoder. It requires the vocabulary size to create the last\n",
        "      layer, the maximums lenght of a sequence to be generated, the dimension of the decoder\n",
        "      embeddings, the number of decoder units and the batch_size. It also set ups the attention mechanism, \n",
        "      a basic decoder and the training sampler.\n",
        "      :param:\n",
        "        vocab_size: number of different tokens in the output encoder\n",
        "        max_sequence_length: maximum length to be considered when generating an answer\n",
        "        embedding_dim: dimension of the embedding vectors in the encoder\n",
        "        decoder_units: number of RNN cells to be used for decoding\n",
        "        batch_size: dimension of the batch to be considered during training\n",
        "      \"\"\"\n",
        "      super(Decoder, self).__init__()\n",
        "      self.max_sequence_length = max_sequence_length\n",
        "      self.batch_size = batch_size\n",
        "      self.decoder_units = decoder_units\n",
        "      self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                 output_dim=embedding_dim)\n",
        "      self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "      self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "      self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                               self.attention,\n",
        "                                                               attention_layer_size=self.decoder_units) \n",
        "      # dense layer needed to generate the distribution values over \n",
        "      # the size of the vocabulary (probability for each word)\n",
        "      self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "      self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "      self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                              sampler=self.sampler,\n",
        "                                              output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "      \"\"\"\n",
        "      function used to build the initial state of the encoder.\n",
        "      after initializing the tensors within the attention layer to 0 we add\n",
        "      the designated initialization that allow us to query the embedding space,\n",
        "      which is passed as encoder_state.\n",
        "      :params:\n",
        "        batch_size: size of the batch of data that is being used\n",
        "        encoder_state: output of the last layer of the encoder\n",
        "      \"\"\"\n",
        "      initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "      initial_state = initial_state.clone(cell_state=encoder_state) \n",
        "      return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "      \"\"\"\n",
        "      call fucntion of the decoder. \n",
        "      :params:\n",
        "      inputs: it is a dictionary with entries: \n",
        "        - \"input_ids\" : _encoder_output_\n",
        "        - \"initial_state\" : _result_of_build_initial_state_\n",
        "      training: boolean flag required by the call function\n",
        "      \"\"\"\n",
        "      input_ids = inputs['input_ids']\n",
        "      input_emb = self.embedding(input_ids)\n",
        "      decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "      return decoder_output\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tgypImQXgQhh"
      },
      "id": "tgypImQXgQhh",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without considering tuning trials (changing the number of neurons, adjusting the beam search method, changing the decoder embedding dimension...), we experimented different variatons which however worsened the result or did not bring any remarkable improvement:\n",
        "- Trying the <code>GRUCell</code> instead of the <code>LSTMCell</code>.\n",
        "- Trying to augment the number of layers in the decoder with the <code>StackedRNN</code>\n",
        "- Trying the Luong attention instead of the Badhanau one.\n",
        "- Adding a time distributed layer over the encoder output.\n",
        "- Adding the POS tagging as an additional information.\n",
        "\n",
        "In the following cells, utility functions for testing and training the model are created."
      ],
      "metadata": {
        "id": "amzydmZdXvRb"
      },
      "id": "amzydmZdXvRb"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(trainer, dataset, epochs, batch_size, ckpt_manager):\n",
        "  \"\"\"\n",
        "  Function executing a full training loop with the model. It automatically manages\n",
        "  batches, but it discards the elements in the last batch if its dimension is different\n",
        "  from batch_size. At each epochs it saves a checkpoint of the model and prints\n",
        "  the current mean loss\n",
        "  :params:\n",
        "    trainer: MyTrainer class instance to use for training\n",
        "    dataset: split of the dataset to be used for training\n",
        "    epochs: number of epochs to execute during training\n",
        "    batch_size: dimension of the batches to be used\n",
        "    ckpt_manager: instance of CheckpointManager, to incrementally save a checkpoint at each epoch\n",
        "  \"\"\"\n",
        "  steps_per_epoch = len(dataset)//batch_size\n",
        "  \n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    cumulative_loss = 0\n",
        "\n",
        "    for batch_index in tqdm(range(steps_per_epoch), position=0, leave=True):\n",
        "      loss = trainer.batch_fit(dataset[batch_index*batch_size:batch_index*batch_size+batch_size])\n",
        "      cumulative_loss += loss\n",
        "\n",
        "    ckpt_manager.save()\n",
        "    mean_loss = cumulative_loss / batch_index\n",
        "    print(f\"Current mean {mean_loss}\")\n",
        "\n",
        "\n",
        "def predict_loop(trainer, dataset, inference_batch_size,model_name,output_tokenizer, beam_search=False):\n",
        "  \"\"\"\n",
        "  Function executing a prediction loop over a given dataset. It automatically\n",
        "  manages batches, without discarding the last batch. It also allows to choose between\n",
        "  beam search and greedy decoding. The output is formatted so that it can directly be used\n",
        "  to compute the SQUAD-F1 score with the evaluate package function.\n",
        "  :params:\n",
        "    trainer: MyTrainer class instance to use for prediction\n",
        "    dataset: split of the dataset to be used for prediction\n",
        "    inference_batch_size: dimension of the batch considered during inference\n",
        "    model_name: name of the model used for the encoder. It allows to use\n",
        "      token type ids when available\n",
        "    output_tokenizer: tokenizer used to tokenize the answers for the decoder\n",
        "    beam_search: boolean indicating whether to use (True) or not the beam_search\n",
        "      (default=False)\n",
        "  \"\"\"\n",
        "  ttids=None # ttids stands for \"token type ids\"\n",
        "  \n",
        "  if beam_search: # here we discriminate between the translate/generate function to use\n",
        "    generation_func = trainer.beam_generate\n",
        "    translation_func = trainer.beam_translate\n",
        "  else:\n",
        "    generation_func = trainer.generate\n",
        "    translation_func = trainer.translate\n",
        "  \n",
        "  inference_step = len(dataset) // inference_batch_size\n",
        "  predictions = []\n",
        "  for step_index in tqdm(range(inference_step)):\n",
        "    starting_index = step_index*inference_batch_size # for the batch\n",
        "    ending_index = step_index*inference_batch_size + inference_batch_size # for the batch\n",
        "\n",
        "    if model_name == 'prajjwal1/bert-tiny':  # if the ttids are available, they are set\n",
        "      ttids = dataset[\"token_type_ids\"][starting_index : ending_index]\n",
        "\n",
        "    generated = generation_func(output_tokenizer=output_tokenizer, \n",
        "                                  input_ids=dataset[\"input_ids\"][starting_index : ending_index],\n",
        "                                  token_type_ids=ttids,\n",
        "                                  attention_mask=dataset[\"attention_mask\"][starting_index : ending_index])\n",
        "    \n",
        "    translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "\n",
        "    #this transformation on indexes is needed in order to have coherent ids in the field \"id\"\n",
        "    list_to_add = [{'prediction_text': translated[i - starting_index].split(\"<end>\")[0],\n",
        "                    'id':str(i)} for i in range(starting_index, ending_index)]\n",
        "\n",
        "    predictions.extend(list_to_add)\n",
        "\n",
        "  # this part of the function replicates the previous part for the last batch  \n",
        "  if model_name == 'prajjwal1/bert-tiny':  \n",
        "    ttids = dataset[\"token_type_ids\"][(inference_step)*inference_batch_size :]\n",
        "  \n",
        "  generated = generation_func(output_tokenizer = output_tokenizer, \n",
        "                             input_ids=dataset[\"input_ids\"][(inference_step)*inference_batch_size :],\n",
        "                             token_type_ids=ttids,\n",
        "                             attention_mask=dataset[\"attention_mask\"][(inference_step)*inference_batch_size :])\n",
        "  translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "\n",
        "  predictions.extend([{'prediction_text': translated[i - (inference_step)*inference_batch_size].split(\"<end>\")[0], \n",
        "                    'id':str(i)} for i in range((inference_step)*inference_batch_size, \n",
        "                                                len(dataset))])\n",
        "  \n",
        "  return predictions\n",
        "  \n",
        "def save_prediction(prediction, filename):\n",
        "  \"\"\"\n",
        "  Function used to save the predictions as a pickle serialized file.\n",
        "  :params:\n",
        "    prediction: dictionary containing predictions to be serialized\n",
        "    filename: name of the file to be used when saving\n",
        "  \"\"\"\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(prediction, f)"
      ],
      "metadata": {
        "id": "bIsHB5JGHGzE"
      },
      "id": "bIsHB5JGHGzE",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the squad metric from the evaluate package\n",
        "squad_metric = load(\"squad\")\n",
        "\n",
        "def train_and_val(model_name,train_ds, val_ds, epochs, batch_size, decoder_units, max_sequence_length, output_tokenizer, pred_file_name, checkpoint_dir):\n",
        "  \"\"\"\n",
        "  Function replicating the training and validation loop for each of the three seed required.\n",
        "  At the end of the training for each seed it saves the predictions made both with greedy sampler and \n",
        "  beam search decoder. Moreover at the end of the whole training process it prints the results\n",
        "  for each seed and their mean, considering both type of answer generation.\n",
        "  :params:\n",
        "    model_name: name of the model to be used as encoder\n",
        "    train_ds: training split of the dataset\n",
        "    val_ds: validation split of the dataset\n",
        "    epochs: number of epochs to be done for each seed\n",
        "    batch_size: dimension of the batch during training\n",
        "    decoder_units: number of decoder units\n",
        "    max_sequence_length: maximum length for an output sequence\n",
        "    output_tokenizer: the tokenizer instance used to split and analyze output sequences\n",
        "    pred_file_name: prefix for the filename used when saving predictions\n",
        "    checkpoint_dir: directory where checkpoints and predictions will be saved\n",
        "\n",
        "  \"\"\"\n",
        "  INF_BS = 64 #Inference batch_size\n",
        "  results = []\n",
        "  results_beam = []\n",
        "  for train_seed in [42,1337,2022]:\n",
        "    set_seed(train_seed) # setting the seed\n",
        "\n",
        "    # creation of the model and util classes\n",
        "    encoder = Encoder(model_name=model_name,\n",
        "                          decoder_units=decoder_units)\n",
        "      \n",
        "    decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                          embedding_dim=100,\n",
        "                          decoder_units=decoder_units,\n",
        "                          batch_size=batch_size,\n",
        "                          max_sequence_length=max_sequence_length)\n",
        "    trainer = MyTrainer(encoder=encoder,\n",
        "                          decoder=decoder,\n",
        "                          max_length=max_sequence_length)\n",
        "    \n",
        "    checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                  encoder=encoder,\n",
        "                                  decoder=decoder)\n",
        "    manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir + f\"/{train_seed}\", max_to_keep=1)\n",
        "\n",
        "    # training\n",
        "    train_loop(trainer, train_ds, epochs, batch_size, manager)\n",
        "\n",
        "    # prediction\n",
        "    prediction = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer)\n",
        "    save_prediction(prediction, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + \"_pred.pickle\")\n",
        "\n",
        "    prediction_beam = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer, beam_search=True)\n",
        "    save_prediction(prediction_beam, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + \"_beampred.pickle\")\n",
        "\n",
        "    results.append(squad_metric.compute(predictions=prediction, references=val_ds['references']))\n",
        "    results_beam.append(squad_metric.compute(predictions=prediction_beam, references=val_ds['references']))\n",
        "\n",
        "    # garbage collector directives to avoid memory cluttering\n",
        "    del(manager)\n",
        "    del(checkpoint)\n",
        "    del(trainer)\n",
        "    del(encoder)\n",
        "    del(decoder) \n",
        "\n",
        "  # printing results\n",
        "  print(\"***VALIDATION RESULTS***\")\n",
        "  print(results)\n",
        "  print(results_beam)\n",
        "  print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "  print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "  print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "  print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )\n",
        "\n",
        "def test_model(model_name, test_ds, batch_size, decoder_units, max_sequence_length, output_tokenizer, pred_file_name, checkpoint_dir, pred_file_suffix = [\"_testpred.pickle\", \"_testbeampred.pickle\"]):\n",
        "  \"\"\"\n",
        "  Function allowing the test of a model for each of the three seeds requested.\n",
        "  The models must be already trained. At the end it prints the results for each\n",
        "  seed and their mean, both for greedy sampling and beam search decoding.\n",
        "  :params:\n",
        "    model_name: name of the model to be used as encoder\n",
        "    test_ds: test split of the dataset\n",
        "    batch_size: dimension of the batch during training\n",
        "    decoder_units: number of decoder units\n",
        "    max_sequence_length: maximum length for an output sequence\n",
        "    output_tokenizer: the tokenizer instance used to split and analyze output sequences\n",
        "    pred_file_name: prefix for the filename used when saving predictions\n",
        "    checkpoint_dir: directory where checkpoints and predictions will be saved\n",
        "    pred_file_suffix: list of two strings to be used when saving the predictions\n",
        "      for a model. The first string is used for greedy sampling generation and the second\n",
        "      for beam search.\n",
        "  \"\"\"\n",
        "  INF_BS = 64 #Inference batch_size\n",
        "  \n",
        "  \n",
        "  results = []\n",
        "  results_beam = []\n",
        "  for train_seed in [42,1337,2022]:\n",
        "    # creation of the model and util classes\n",
        "    encoder = Encoder(model_name=model_name,\n",
        "                        decoder_units=decoder_units)\n",
        "      \n",
        "    decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                          embedding_dim=100,\n",
        "                          decoder_units=decoder_units,\n",
        "                          batch_size=batch_size,\n",
        "                          max_sequence_length=max_sequence_length)\n",
        "  \n",
        "    trainer = MyTrainer(encoder=encoder,\n",
        "                          decoder=decoder,\n",
        "                          max_length=max_sequence_length)\n",
        "    \n",
        "    checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                  encoder=encoder,\n",
        "                                  decoder=decoder)\n",
        "    \n",
        "  \n",
        "    # required step in order to load correctly the decoder embedding matrix\n",
        "    decoder.embedding.build(input_shape=None)\n",
        "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir+f\"/{train_seed}\")).expect_partial()\n",
        "\n",
        "    prediction = predict_loop(trainer, test_ds, INF_BS, model_name, output_tokenizer)\n",
        "    save_prediction(prediction, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) +  pred_file_suffix[0])\n",
        "\n",
        "    prediction_beam = predict_loop(trainer, test_ds, INF_BS, model_name ,output_tokenizer, beam_search=True)\n",
        "    save_prediction(prediction_beam, checkpoint_dir + pred_file_name + \"_\" + str(train_seed) + pred_file_suffix[1])\n",
        "\n",
        "    results.append(squad_metric.compute(predictions=prediction, references=test_ds['references']))\n",
        "    results_beam.append(squad_metric.compute(predictions=prediction_beam, references=test_ds['references']))\n",
        "\n",
        "  print(\"***TEST RESULTS***\")\n",
        "  print(results)\n",
        "  print(results_beam)\n",
        "  print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "  print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "  print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "  print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )"
      ],
      "metadata": {
        "id": "PQK8ldAw9SIs"
      },
      "id": "PQK8ldAw9SIs",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f1e83f28",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 14\n",
        "EPOCHS = 3\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "TINY_DEC_UNITS = 128\n",
        "ROB_DEC_UNITS = 256"
      ],
      "metadata": {
        "id": "1yhop6aHPLr_"
      },
      "id": "1yhop6aHPLr_",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds\")\n",
        "\n",
        "train_and_val('prajjwal1/bert-tiny',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=TINY_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='tiny',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "1oNmAxBvSVuH",
        "outputId": "6987c73d-d37e-4e16-e8f9-46ee2a623c22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1oNmAxBvSVuH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 6129/6129 [11:19<00:00,  9.02it/s]\n",
            " 33%|███▎      | 1/3 [11:19<22:39, 679.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.064605712890625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:14<00:00,  9.08it/s]\n",
            " 67%|██████▋   | 2/3 [22:34<11:16, 676.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8742226958274841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:13<00:00,  9.10it/s]\n",
            "100%|██████████| 3/3 [33:48<00:00, 676.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7598474025726318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:32<00:00,  2.20it/s]\n",
            "100%|██████████| 335/335 [04:44<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}]\n",
            "[{'exact_match': 12.123469435262349, 'f1': 14.27187375444946}]\n",
            "greedy exact match:11.904651054518366\n",
            "greedy SQUAD-F1:14.289189542326932\n",
            "beam exact match:12.123469435262349\n",
            "beam SQUAD-F1:14.27187375444946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 6129/6129 [11:22<00:00,  8.98it/s]\n",
            " 33%|███▎      | 1/3 [11:23<22:46, 683.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0730599164962769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:11<00:00,  9.12it/s]\n",
            " 67%|██████▋   | 2/3 [22:35<11:16, 676.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8743070363998413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:12<00:00,  9.11it/s]\n",
            "100%|██████████| 3/3 [33:48<00:00, 676.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7575758695602417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:29<00:00,  2.24it/s]\n",
            "100%|██████████| 335/335 [04:39<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}, {'exact_match': 11.960519577261511, 'f1': 14.549653043162628}]\n",
            "[{'exact_match': 12.123469435262349, 'f1': 14.27187375444946}, {'exact_match': 12.197960798919874, 'f1': 14.561944356953724}]\n",
            "greedy exact match:11.932585315889938\n",
            "greedy SQUAD-F1:14.41942129274478\n",
            "beam exact match:12.160715117091112\n",
            "beam SQUAD-F1:14.416909055701591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 6129/6129 [11:16<00:00,  9.05it/s]\n",
            " 33%|███▎      | 1/3 [11:17<22:34, 677.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.065598726272583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:08<00:00,  9.17it/s]\n",
            " 67%|██████▋   | 2/3 [22:26<11:12, 672.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8747037649154663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:08<00:00,  9.16it/s]\n",
            "100%|██████████| 3/3 [33:35<00:00, 671.89s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7593579292297363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:27<00:00,  2.28it/s]\n",
            "100%|██████████| 335/335 [04:38<00:00,  1.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}, {'exact_match': 11.960519577261511, 'f1': 14.549653043162628}, {'exact_match': 11.904651054518366, 'f1': 14.643605437027999}]\n",
            "[{'exact_match': 12.123469435262349, 'f1': 14.27187375444946}, {'exact_match': 12.197960798919874, 'f1': 14.561944356953724}, {'exact_match': 12.095535173890777, 'f1': 14.485326311156506}]\n",
            "greedy exact match:11.923273895432748\n",
            "greedy SQUAD-F1:14.494149340839186\n",
            "beam exact match:12.138988469357665\n",
            "beam SQUAD-F1:14.439714807519897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds_rob\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob\")\n",
        "\n",
        "train_and_val('distilroberta-base',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=ROB_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='rob',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "geZdYK00NgmK",
        "outputId": "c5a32905-d153-409c-c8c5-5585c93d7dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5cf413a2fb084d0bbe06d52fc0511f00",
            "65a872bd25b04430b2405cb9c10f1c89"
          ]
        }
      },
      "id": "geZdYK00NgmK",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5cf413a2fb084d0bbe06d52fc0511f00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65a872bd25b04430b2405cb9c10f1c89",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6129/6129 [39:19<00:00,  2.60it/s]\n",
            " 33%|███▎      | 1/3 [39:21<1:18:42, 2361.43s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current mean 1.0559253692626953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [39:09<00:00,  2.61it/s]\n",
            " 67%|██████▋   | 2/3 [1:18:32<39:15, 2355.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8417209386825562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [39:08<00:00,  2.61it/s]\n",
            "100%|██████████| 3/3 [1:57:43<00:00, 2354.53s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.6954158544540405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [15:30<00:00,  2.78s/it]\n",
            "  0%|          | 0/335 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/resource_loader.py:78: UserWarning: You are currently using TensorFlow 2.9.2 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
            "TensorFlow Addons has compiled its custom ops against TensorFlow 2.11.0, and there are no compatibility guarantees between the two versions. \n",
            "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
            " If you do, do not file an issue on Github. This is a known limitation.\n",
            "\n",
            "It might help you to fallback to pure Python ops by setting environment variable `TF_ADDONS_PY_OPS=1` or using `tfa.options.disable_custom_kernel()` in your code. To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
            "\n",
            "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.11.0 and strictly below 2.12.0.\n",
            " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
            "\n",
            "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/options.py:45: RuntimeWarning: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_addons/seq2seq/beam_search_decoder.py\", line 239, in gather_tree\n",
            "    return _beam_search_so.ops.addons_gather_tree(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/resource_loader.py\", line 68, in ops\n",
            "    self._ops = tf.load_op_library(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/load_library.py\", line 54, in load_op_library\n",
            "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow_addons/custom_ops/seq2seq/_beam_search_ops.so: undefined symbol: _ZN3tsl7strings21FastInt32ToBufferLeftEiPc\n",
            "\n",
            "\n",
            "The gather_tree C++/CUDA custom op could not be loaded.\n",
            "For this reason, Addons will fallback to an implementation written\n",
            "in Python with public TensorFlow ops. There worst you might experience with\n",
            "this is a moderate slowdown on GPU. There can be multiple\n",
            "reason for this loading error, one of them may be an ABI incompatibility between\n",
            "the TensorFlow installed on your system and the TensorFlow used to compile\n",
            "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
            "shared object file was displayed above.\n",
            "\n",
            "If you want this warning to disappear, either make sure the TensorFlow installed\n",
            "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
            "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
            "by setting the enviornment variable `TF_ADDONS_PY_OPS=1`:\n",
            "```bash\n",
            "TF_ADDONS_PY_OPS=1 python my_script.py\n",
            "```\n",
            "or run `tfa.options.disable_custom_kernel()` in your code, after your imports:\n",
            "```python\n",
            "import tensorflow_addons as tfa\n",
            "import ...\n",
            "import ...\n",
            "\n",
            "tfa.options.disable_custom_kernel()\n",
            "```\n",
            "\n",
            "  warnings.warn(warning_msg, RuntimeWarning)\n",
            "100%|██████████| 335/335 [17:33<00:00,  3.14s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 14.241817589273243, 'f1': 17.78899494962537}]\n",
            "[{'exact_match': 14.497881651845988, 'f1': 17.887112794009507}]\n",
            "greedy exact match:14.241817589273243\n",
            "greedy SQUAD-F1:17.78899494962537\n",
            "beam exact match:14.497881651845988\n",
            "beam SQUAD-F1:17.887112794009507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training with distilroberta was stopped by colab limits\n",
        "# so there we print the validation results\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob',\n",
        "            checkpoint_dir=checkpoint_dir,\n",
        "            pred_file_suffix=[\"_pred.pickle\", \"_beampred.pickle\"])"
      ],
      "metadata": {
        "id": "poN9VRhUR1Y8",
        "outputId": "11f17389-38c3-4d89-b621-979a46e69b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e0e3b2a8d8824eaa9ca8cb95891b4625",
            "b5ea6a57b72144518b9d5afda1b7b887",
            "d78dde8d25c64ea59de06475608af78d",
            "2b8e00b854494f0a84e561bc893f37d4",
            "ed936169f3f142908e5bbc037f0af55b",
            "66a93ae2e19647fb8e1bd6449b7c369e",
            "5deea0ee07e949f78968f5fa45acb5a9",
            "4fe78769ed374587b5edf8be723c8c7e",
            "3cbcfaf0864941a2989f1e7d71895cc7",
            "41487cdee2f845e1b9d53e6cf246cd60",
            "1b9062f171b543d3b1eb67285d372447",
            "4d6ac3123a1940f0a2aa415b3a129ecf",
            "fddf583fac2442a9b1b3cd086ad150b8",
            "f557d1af6d994d1488e1cc8cdbe7d3a0",
            "8de04409b42b4d3c8d6e8054b8feed0a",
            "09c27eda99d24c81886e8a1e397692bf",
            "c8b20f290fcc4f2daf0e0b7216c5e2e3",
            "a8f4d2ba6c2048a4b536ce409133dffc",
            "674169832ad54da7bae5582bae68f71d",
            "356548854c7148fe906475739fe65d31",
            "f14e5d7adc73435389b7417639158082",
            "c623f19900a54fe5ae15ab2317dac880"
          ]
        }
      },
      "id": "poN9VRhUR1Y8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0e3b2a8d8824eaa9ca8cb95891b4625"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d6ac3123a1940f0a2aa415b3a129ecf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [16:38<00:00,  2.98s/it]\n",
            "  0%|          | 0/335 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/resource_loader.py:78: UserWarning: You are currently using TensorFlow 2.9.2 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
            "TensorFlow Addons has compiled its custom ops against TensorFlow 2.11.0, and there are no compatibility guarantees between the two versions. \n",
            "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
            " If you do, do not file an issue on Github. This is a known limitation.\n",
            "\n",
            "It might help you to fallback to pure Python ops by setting environment variable `TF_ADDONS_PY_OPS=1` or using `tfa.options.disable_custom_kernel()` in your code. To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
            "\n",
            "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.11.0 and strictly below 2.12.0.\n",
            " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
            "\n",
            "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/options.py:45: RuntimeWarning: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_addons/seq2seq/beam_search_decoder.py\", line 239, in gather_tree\n",
            "    return _beam_search_so.ops.addons_gather_tree(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/resource_loader.py\", line 68, in ops\n",
            "    self._ops = tf.load_op_library(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/load_library.py\", line 54, in load_op_library\n",
            "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow_addons/custom_ops/seq2seq/_beam_search_ops.so: undefined symbol: _ZN3tsl7strings21FastInt32ToBufferLeftEiPc\n",
            "\n",
            "\n",
            "The gather_tree C++/CUDA custom op could not be loaded.\n",
            "For this reason, Addons will fallback to an implementation written\n",
            "in Python with public TensorFlow ops. There worst you might experience with\n",
            "this is a moderate slowdown on GPU. There can be multiple\n",
            "reason for this loading error, one of them may be an ABI incompatibility between\n",
            "the TensorFlow installed on your system and the TensorFlow used to compile\n",
            "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
            "shared object file was displayed above.\n",
            "\n",
            "If you want this warning to disappear, either make sure the TensorFlow installed\n",
            "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
            "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
            "by setting the enviornment variable `TF_ADDONS_PY_OPS=1`:\n",
            "```bash\n",
            "TF_ADDONS_PY_OPS=1 python my_script.py\n",
            "```\n",
            "or run `tfa.options.disable_custom_kernel()` in your code, after your imports:\n",
            "```python\n",
            "import tensorflow_addons as tfa\n",
            "import ...\n",
            "import ...\n",
            "\n",
            "tfa.options.disable_custom_kernel()\n",
            "```\n",
            "\n",
            "  warnings.warn(warning_msg, RuntimeWarning)\n",
            "100%|██████████| 335/335 [18:48<00:00,  3.37s/it]\n",
            "100%|██████████| 335/335 [16:45<00:00,  3.00s/it]\n",
            "100%|██████████| 335/335 [18:45<00:00,  3.36s/it]\n",
            "100%|██████████| 335/335 [16:45<00:00,  3.00s/it]\n",
            "100%|██████████| 335/335 [18:48<00:00,  3.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 13.995064947157688, 'f1': 17.371109268490425}, {'exact_match': 13.627263839098655, 'f1': 17.008573844493572}, {'exact_match': 14.241817589273243, 'f1': 17.78899494962537}]\n",
            "[{'exact_match': 14.26509614041622, 'f1': 17.406625006857944}, {'exact_match': 13.90195074258578, 'f1': 16.85284444704135}, {'exact_match': 14.497881651845988, 'f1': 17.887112794009507}]\n",
            "greedy exact match:13.954715458509861\n",
            "greedy SQUAD-F1:17.389559354203122\n",
            "beam exact match:14.22164284494933\n",
            "beam SQUAD-F1:17.382194082636264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training with distilroberta was stopped by colab limits\n",
        "# so there we print the validation results\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob',\n",
        "            checkpoint_dir=checkpoint_dir,\n",
        "            pred_file_suffix=[\"_pred.pickle\", \"_beampred.pickle\"])"
      ],
      "metadata": {
        "outputId": "77741b49-6c5d-4701-dcdc-250476ebd73a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QfG6wCBBY7r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [08:57<00:00,  1.61s/it]\n",
            "100%|██████████| 335/335 [11:07<00:00,  1.99s/it]\n",
            "100%|██████████| 335/335 [09:00<00:00,  1.61s/it]\n",
            "100%|██████████| 335/335 [11:03<00:00,  1.98s/it]\n",
            "100%|██████████| 335/335 [08:58<00:00,  1.61s/it]\n",
            "100%|██████████| 335/335 [11:02<00:00,  1.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 13.995064947157688, 'f1': 17.371109268490425}, {'exact_match': 13.627263839098655, 'f1': 17.008573844493572}, {'exact_match': 14.241817589273243, 'f1': 17.78899494962537}]\n",
            "[{'exact_match': 14.260440430187625, 'f1': 17.496961384876048}, {'exact_match': 13.892639322128591, 'f1': 16.973901679859594}, {'exact_match': 14.469947390474417, 'f1': 17.970400494380886}]\n",
            "greedy exact match:13.954715458509861\n",
            "greedy SQUAD-F1:17.389559354203122\n",
            "beam exact match:14.207675714263544\n",
            "beam SQUAD-F1:17.480421186372173\n"
          ]
        }
      ],
      "id": "7QfG6wCBBY7r"
    },
    {
      "cell_type": "markdown",
      "id": "7311ba86",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny/hist'\n",
        "\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds_hist\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_hist\")\n",
        "\n",
        "train_and_val('prajjwal1/bert-tiny',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=TINY_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='tiny_hist',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "66NLQ6G5OWRe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "999567f6-e786-4b19-e2d2-515ac7245cc5"
      },
      "id": "66NLQ6G5OWRe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n",
            "100%|██████████| 6129/6129 [11:40<00:00,  8.75it/s]\n",
            " 33%|███▎      | 1/3 [11:40<23:21, 700.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0670831203460693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:24<00:00,  8.95it/s]\n",
            " 67%|██████▋   | 2/3 [23:06<11:31, 691.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8746263980865479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:24<00:00,  8.95it/s]\n",
            "100%|██████████| 3/3 [34:31<00:00, 690.45s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.759445309638977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:36<00:00,  2.14it/s]\n",
            "100%|██████████| 335/335 [04:51<00:00,  1.15it/s]\n",
            "100%|██████████| 6129/6129 [11:28<00:00,  8.90it/s]\n",
            " 33%|███▎      | 1/3 [11:29<22:58, 689.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0788750648498535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:23<00:00,  8.97it/s]\n",
            " 67%|██████▋   | 2/3 [22:53<11:26, 686.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8751189112663269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:23<00:00,  8.97it/s]\n",
            "100%|██████████| 3/3 [34:17<00:00, 685.77s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7595735192298889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:33<00:00,  2.19it/s]\n",
            "100%|██████████| 335/335 [04:47<00:00,  1.16it/s]\n",
            "100%|██████████| 6129/6129 [11:25<00:00,  8.94it/s]\n",
            " 33%|███▎      | 1/3 [11:25<22:51, 685.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0686047077178955\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:22<00:00,  8.99it/s]\n",
            " 67%|██████▋   | 2/3 [22:48<11:23, 683.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8764885663986206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [11:21<00:00,  8.99it/s]\n",
            "100%|██████████| 3/3 [34:10<00:00, 683.57s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7604389190673828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:32<00:00,  2.20it/s]\n",
            "100%|██████████| 335/335 [04:49<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 11.913962474975557, 'f1': 14.435647357982468}, {'exact_match': 12.00242096931887, 'f1': 14.831662593488241}, {'exact_match': 11.81153684994646, 'f1': 14.194647495643768}]\n",
            "[{'exact_match': 12.216583639834257, 'f1': 14.615724631732936}, {'exact_match': 12.309697844406164, 'f1': 14.890212870467654}, {'exact_match': 12.104846594347968, 'f1': 14.181929087624674}]\n",
            "greedy exact match:11.909306764746963\n",
            "greedy SQUAD-F1:14.487319149038157\n",
            "beam exact match:12.21037602619613\n",
            "beam SQUAD-F1:14.562622196608421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob/hist'\n",
        "\n",
        "train_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/train_ds_rob_hist\")\n",
        "val_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob_hist\")\n",
        "\n",
        "train_and_val('distilroberta-base',\n",
        "              train_ds,\n",
        "              val_ds,\n",
        "              epochs=EPOCHS,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              decoder_units=ROB_DEC_UNITS,\n",
        "              max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "              output_tokenizer=output_tokenizer,\n",
        "              pred_file_name='rob_hist',\n",
        "              checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "nsQa40OkOWka",
        "outputId": "c4b36410-0037-49ee-e059-57a9439ee643",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "id": "nsQa40OkOWka",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [41:01<00:00,  2.49it/s]\n",
            " 33%|███▎      | 1/3 [41:03<1:22:07, 2463.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 1.0596537590026855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [40:57<00:00,  2.49it/s]\n",
            " 67%|██████▋   | 2/3 [1:22:02<41:01, 2461.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.8442547917366028\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6129/6129 [40:57<00:00,  2.49it/s]\n",
            "100%|██████████| 3/3 [2:03:02<00:00, 2460.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.6984569430351257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [08:57<00:00,  1.60s/it]\n",
            "100%|██████████| 335/335 [11:07<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 13.841426509614042, 'f1': 17.282489916713295}]\n",
            "[{'exact_match': 14.19526048698729, 'f1': 17.43092894424413}]\n",
            "greedy exact match:13.841426509614042\n",
            "greedy SQUAD-F1:17.282489916713295\n",
            "beam exact match:14.19526048698729\n",
            "beam SQUAD-F1:17.43092894424413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training with distilroberta with history was stopped by colab limits\n",
        "# so there we print the validation results\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob/hist'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds_rob_hist\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob_hist',\n",
        "            checkpoint_dir=checkpoint_dir,\n",
        "            pred_file_suffix=[\"_pred.pickle\", \"_beampred.pickle\"])"
      ],
      "metadata": {
        "outputId": "cf5fd678-82d9-48ea-c903-4f79e3d62346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7d5tkEugfBJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [16:15<00:00,  2.91s/it]\n",
            "100%|██████████| 335/335 [18:34<00:00,  3.33s/it]\n",
            "100%|██████████| 335/335 [16:35<00:00,  2.97s/it]\n",
            "100%|██████████| 335/335 [18:38<00:00,  3.34s/it]\n",
            "100%|██████████| 335/335 [16:28<00:00,  2.95s/it]\n",
            "100%|██████████| 335/335 [18:27<00:00,  3.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 13.841426509614042, 'f1': 17.282489916713295}, {'exact_match': 14.041622049443642, 'f1': 17.43531794791082}, {'exact_match': 13.720378043670562, 'f1': 16.958132144994597}]\n",
            "[{'exact_match': 14.19526048698729, 'f1': 17.43092894424413}, {'exact_match': 14.283718981330601, 'f1': 17.383262530033846}, {'exact_match': 13.939196424414545, 'f1': 16.855144296543195}]\n",
            "greedy exact match:13.867808867576082\n",
            "greedy SQUAD-F1:17.22531333653957\n",
            "beam exact match:14.139391964244146\n",
            "beam SQUAD-F1:17.223111923607057\n"
          ]
        }
      ],
      "id": "U7d5tkEugfBJ"
    },
    {
      "cell_type": "markdown",
      "id": "b5ac768c",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/val_ds\")\n",
        "\n",
        "test_model('prajjwal1/bert-tiny',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=TINY_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='tiny',\n",
        "            checkpoint_dir=checkpoint_dir,\n",
        "           pred_file_suffix=[\"_pred.pickle\", \"_beampred.pickle\"])"
      ],
      "metadata": {
        "id": "x_aFLvY8fIm1",
        "outputId": "35160d4f-99c5-4731-b8fb-8aa4ebd4697f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "x_aFLvY8fIm1",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [02:37<00:00,  2.13it/s]\n",
            "100%|██████████| 335/335 [06:20<00:00,  1.14s/it]\n",
            "100%|██████████| 335/335 [02:15<00:00,  2.48it/s]\n",
            "100%|██████████| 335/335 [06:08<00:00,  1.10s/it]\n",
            "100%|██████████| 335/335 [02:43<00:00,  2.05it/s]\n",
            "100%|██████████| 335/335 [05:26<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 11.904651054518366, 'f1': 14.289189542326932}, {'exact_match': 11.960519577261511, 'f1': 14.549653043162628}, {'exact_match': 11.904651054518366, 'f1': 14.643605437027999}]\n",
            "[{'exact_match': 12.058289492062015, 'f1': 14.320208563323147}, {'exact_match': 12.142092276176731, 'f1': 14.718874109519422}, {'exact_match': 12.030355230690441, 'f1': 14.622539313717411}]\n",
            "greedy exact match:11.923273895432748\n",
            "greedy SQUAD-F1:14.494149340839186\n",
            "beam exact match:12.076912332976397\n",
            "beam SQUAD-F1:14.553873995519993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds\")\n",
        "\n",
        "test_model('prajjwal1/bert-tiny',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=TINY_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='tiny',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "Nnr1YfanbSIs"
      },
      "id": "Nnr1YfanbSIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA NO HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_rob\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "UR90KwNPPebI",
        "outputId": "4e9bde36-e359-4aeb-e8ab-a68b9278cf33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UR90KwNPPebI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [05:35<00:00,  2.73s/it]\n",
            " 80%|███████▉  | 98/123 [05:07<01:18,  3.14s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny/hist'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_hist\")\n",
        "\n",
        "test_model('prajjwal1/bert-tiny',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=TINY_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='tiny_hist',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "7kH75XdyPvFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82ee0d75-2c20-4d4c-eaaa-bae5d67bb2eb"
      },
      "id": "7kH75XdyPvFy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 123/123 [00:41<00:00,  2.98it/s]\n",
            "100%|██████████| 123/123 [01:31<00:00,  1.35it/s]\n",
            "100%|██████████| 123/123 [00:39<00:00,  3.10it/s]\n",
            "100%|██████████| 123/123 [01:29<00:00,  1.38it/s]\n",
            "100%|██████████| 123/123 [00:40<00:00,  3.01it/s]\n",
            "100%|██████████| 123/123 [01:30<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***TEST RESULTS***\n",
            "[{'exact_match': 12.124273806516797, 'f1': 14.392046008515898}, {'exact_match': 12.086385450871433, 'f1': 14.668835115967326}, {'exact_match': 12.073755998989643, 'f1': 14.23343061197177}]\n",
            "[{'exact_match': 12.47789845920687, 'f1': 14.779871710239322}, {'exact_match': 12.452639555443294, 'f1': 14.840252331149317}, {'exact_match': 12.250568325334681, 'f1': 14.217070933285694}]\n",
            "greedy exact match:12.09480508545929\n",
            "greedy SQUAD-F1:14.431437245484998\n",
            "beam exact match:12.393702113328281\n",
            "beam SQUAD-F1:14.612398324891444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA WITH HISTORY\n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob/hist'\n",
        "\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_rob_hist\")\n",
        "\n",
        "test_model('distilroberta-base',\n",
        "            test_ds,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            decoder_units=ROB_DEC_UNITS,\n",
        "            max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "            output_tokenizer=output_tokenizer,\n",
        "            pred_file_name='rob_hist',\n",
        "            checkpoint_dir=checkpoint_dir)"
      ],
      "metadata": {
        "id": "4-4EXMxEPz6x"
      },
      "id": "4-4EXMxEPz6x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = [{'prediction_text': translated[i - 128].split(\"<end>\")[0], 'id':str(i)} for i in range(128, 256)]\n",
        "print(type(prediction[0]))\n",
        "for i in prediction[0:10]:\n",
        "  print(i[\"prediction_text\"])\n",
        "  print(YQA_val[int(i[\"id\"])])\n",
        "  print(XQA_val[int(i[\"id\"])])"
      ],
      "metadata": {
        "id": "g_Q4mJbLSuPm"
      },
      "id": "g_Q4mJbLSuPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "92c7e98f",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_worst_errors(prediction_prefix, prediction_suffix, ref_dataset):\n",
        "  squad = load(\"squad\")\n",
        "  predictions = []\n",
        "  for seed in [42,1337,2022]:\n",
        "    with open(prediction_prefix + str(seed) + prediction_suffix, \"rb\") as f:\n",
        "      new_list = pickle.load(f)\n",
        "      new_list.sort(key=lambda x: int(x[\"id\"]))\n",
        "      predictions.append(new_list)\n",
        "      \n",
        "  categories = np.unique(ref_dataset[\"source\"])\n",
        "\n",
        "  source_dict = {cat:[] for cat in categories}\n",
        "  refd = ref_dataset[\"references\"]\n",
        "  for pred in tqdm(range(len(predictions[0]))):\n",
        "    #ATTENTION: the following instructions is based on the assumption that\n",
        "    # the id of each example is the row of the id itself, as it follows\n",
        "    #from our dataset construciton\n",
        "    ref = refd[int(predictions[0][pred][\"id\"])]\n",
        "    if ref[\"id\"] != predictions[0][pred][\"id\"] or ref[\"id\"] != predictions[1][pred][\"id\"] or ref[\"id\"] != predictions[2][pred][\"id\"]:\n",
        "      print(\"error with ids: example\" + ref[\"id\"])\n",
        "    \n",
        "    f1 = squad.compute(predictions=[predictions[0][pred]],\n",
        "                       references=[ref])[\"f1\"]\n",
        "\n",
        "    f1 += squad.compute(predictions=[predictions[1][pred]],\n",
        "                                     references = [ref])[\"f1\"]\n",
        "\n",
        "    f1 += squad.compute(predictions=[predictions[2][pred]],\n",
        "                        references = [ref])[\"f1\"]\n",
        "    \n",
        "    f1 = f1/3\n",
        "    source_dict[ref_dataset[\"source\"][int(predictions[0][pred][\"id\"])]].append((predictions[0][pred][\"id\"] , f1))\n",
        "\n",
        "\n",
        "  return source_dict\n",
        "\n",
        "def print_orderered_predictions(source_dict, prediction_prefix, prediction_suffix, ref_dataset, question_dataset, kind=\"worst\", qty=5, skip_yn=False):\n",
        "  predictions = []\n",
        "  refd = ref_dataset[\"references\"]\n",
        "  for seed in [42,1337,2022]:\n",
        "    with open(prediction_prefix + str(seed) + prediction_suffix, \"rb\") as f:\n",
        "      new_list = pickle.load(f)\n",
        "      new_list.sort(key=lambda x: int(x[\"id\"]))\n",
        "      predictions.append(new_list)\n",
        "  \n",
        "  for key in source_dict.keys():\n",
        "    source_dict[key].sort(key=lambda x : x[1], reverse=True if kind==\"best\" else False)\n",
        "    print(\"-------------\" + key + \"-------------\")\n",
        "    i = 0\n",
        "    j = 0\n",
        "    while i<qty and j<len(source_dict[key]):\n",
        "      id = source_dict[key][j][0]\n",
        "      if skip_yn and refd[int(id)][\"answers\"][\"text\"][0] in [\"yes\", \"no\"]:\n",
        "        j = j + 1\n",
        "      else:\n",
        "        print(\"question + passage: \" + str(XQA_test[int(id)]))\n",
        "        print(\"true answer: \" + str(refd[int(id)][\"answers\"][\"text\"]))\n",
        "        print(\"answer with seed 42: \" + predictions[0][int(id)][\"prediction_text\"])\n",
        "        print(\"answer with seed 1337: \" + predictions[1][int(id)][\"prediction_text\"])\n",
        "        print(\"answer with seed 2022: \" + predictions[2][int(id)][\"prediction_text\"])\n",
        "        print(\"f1: \" + str(source_dict[key][j][1]))\n",
        "        i = i + 1\n",
        "        j = j + 1\n"
      ],
      "metadata": {
        "id": "v1tVCI94ne7w"
      },
      "id": "v1tVCI94ne7w",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT TINY NO HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/tinytiny_\", \"_testbeampred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "qQ4P1Rz3whvV",
        "outputId": "edfbbe35-7dea-4453-bf96-bdde22b6d445",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qQ4P1Rz3whvV",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7918/7918 [03:44<00:00, 35.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tinytiny_\", \"_testbeampred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "CFGqqJyS8dkB",
        "outputId": "08f7cd55-0c29-4cdd-f12a-4f7bddd910e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CFGqqJyS8dkB",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------cnn-------------\n",
            "question + passage: ['Whom?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. [SEP]Is someone in showbiz?[SEP]Yes.']\n",
            "true answer: ['dennis farina']\n",
            "answer with seed 42: his writer \n",
            "answer with seed 1337: steven komisarjevsky \n",
            "answer with seed 2022: michael komisarjevsky \n",
            "f1: 0.0\n",
            "question + passage: ['What did he do?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. [SEP]Whom?[SEP]Dennis Farina[SEP]Is someone in showbiz?[SEP]Yes.']\n",
            "true answer: ['actor']\n",
            "answer with seed 42: he said a writer \n",
            "answer with seed 1337: he was a writer \n",
            "answer with seed 2022: he said a writer \n",
            "f1: 0.0\n",
            "question + passage: ['Is he still alive?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. [SEP]What did he do?[SEP]Actor[SEP]Whom?[SEP]Dennis Farina[SEP]Is someone in showbiz?[SEP]Yes.']\n",
            "true answer: ['no']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['Anything recent?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. [SEP]Was he in movies?[SEP]Yes[SEP]Is he still alive?[SEP]No[SEP]What did he do?[SEP]Actor[SEP]Whom?[SEP]Dennis Farina[SEP]Is someone in showbiz?[SEP]Yes.']\n",
            "true answer: ['no']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['Who cast him?', '(CNN) -- Dennis Farina, the dapper, mustachioed cop-turned-actor best known for his tough-as-nails work in such TV series as \"Law & Order,\" \"Crime Story,\" and \"Miami Vice,\" has died. He was 69. \\n\\n\"We are deeply saddened by the loss of a great actor and a wonderful man,\" said his publicist, Lori De Waal, in a statement Monday. \"Dennis Farina was always warmhearted and professional, with a great sense of humor and passion for his profession. He will be greatly missed by his family, friends and colleagues.\" \\n\\nFarina, who had a long career as a police officer in Chicago, got into acting through director Michael Mann, who used him as a consultant and cast him in his 1981 movie, \"Thief.\" That role led to others in such Mann-created shows as \"Miami Vice\" (in which Farina played a mobster) and \"Crime Story\" (in which he starred as Lt. Mike Torello). \\n\\nFarina also had roles, generally as either cops or gangsters, in a number of movies, including \"Midnight Run\" (1988), \"Get Shorty\" (1995), \"The Mod Squad\" (1999) and \"Snatch\" (2000). \\n\\nIn 2004, he joined the cast of the long-running \"Law & Order\" after Jerry Orbach\\'s departure, playing Detective Joe Fontana, a role he reprised on the spinoff \"Trial by Jury.\" Fontana was known for flashy clothes and an expensive car, a distinct counterpoint to Orbach\\'s rumpled Lennie Briscoe. \\n\\nFarina was on \"Law & Order\" for two years, partnered with Jesse L. Martin\\'s Ed Green. Martin\\'s character became a senior detective after Farina left the show. [SEP]What happened in the early 80\\'s?[SEP]Farina was cast in a film[SEP]Anything recent?[SEP]No[SEP]Was he in movies?[SEP]Yes[SEP]Is he still alive?[SEP]No[SEP]What did he do?[SEP]Actor[SEP]Whom?[SEP]Dennis Farina[SEP]Is someone in showbiz?[SEP]Yes.']\n",
            "true answer: ['michael mann']\n",
            "answer with seed 42: his man \n",
            "answer with seed 1337: a writer \n",
            "answer with seed 2022: his young \n",
            "f1: 0.0\n",
            "-------------gutenberg-------------\n",
            "question + passage: ['What worked her way northward?', 'CHAPTER XXII \\n\\nNorthward, along the leeward coast of Malaita, the _Ariel_ worked her leisurely way, threading the colour-riotous lagoon that lay between the shore-reefs and outer-reefs, daring passages so narrow and coral-patched that Captain Winters averred each day added a thousand grey hairs to his head, and dropping anchor off every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life. For Harley and Villa Kennan were in no hurry. So long as the way was interesting, they dared not how long it proved from anywhere to anywhere. \\n\\nDuring this time Jerry learned a new name for himself--or, rather, an entire series of names for himself. This was because of an aversion on Harley Kennan\\'s part against renaming a named thing. \\n\\n\"A name he must have had,\" he argued to Villa. \"Haggin must have named him before he sailed on the _Arangi_. Therefore, nameless he must be until we get back to Tulagi and find out his real name.\" \\n\\n\"What\\'s in a name?\" Villa had begun to tease. \\n\\n\"Everything,\" her husband retorted. \"Think of yourself, shipwrecked, called by your rescuers \\'Mrs. Riggs,\\' or \\'Mademoiselle de Maupin,\\' or just plain \\'Topsy.\\' And think of me being called \\'Benedict Arnold,\\' or \\' Judas,\\' or . . . or . . . \\'Haman.\\' No, keep him nameless, until we find out his original name.\" \\n\\n\"Must call him something,\" she objected. \"Can\\'t think of him without thinking something.\" \\n\\n\"Then call him many names, but never the same name twice. Call him \\'Dog\\' to-day, and \\'Mister Dog\\' to-morrow, and the next day something else.\" ']\n",
            "true answer: ['the ariel']\n",
            "answer with seed 42: the stays \n",
            "answer with seed 1337: the path \n",
            "answer with seed 2022: the path \n",
            "f1: 0.0\n",
            "question + passage: ['What lay between the shore-reefs and outer-reefs?', 'CHAPTER XXII \\n\\nNorthward, along the leeward coast of Malaita, the _Ariel_ worked her leisurely way, threading the colour-riotous lagoon that lay between the shore-reefs and outer-reefs, daring passages so narrow and coral-patched that Captain Winters averred each day added a thousand grey hairs to his head, and dropping anchor off every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life. For Harley and Villa Kennan were in no hurry. So long as the way was interesting, they dared not how long it proved from anywhere to anywhere. \\n\\nDuring this time Jerry learned a new name for himself--or, rather, an entire series of names for himself. This was because of an aversion on Harley Kennan\\'s part against renaming a named thing. \\n\\n\"A name he must have had,\" he argued to Villa. \"Haggin must have named him before he sailed on the _Arangi_. Therefore, nameless he must be until we get back to Tulagi and find out his real name.\" \\n\\n\"What\\'s in a name?\" Villa had begun to tease. \\n\\n\"Everything,\" her husband retorted. \"Think of yourself, shipwrecked, called by your rescuers \\'Mrs. Riggs,\\' or \\'Mademoiselle de Maupin,\\' or just plain \\'Topsy.\\' And think of me being called \\'Benedict Arnold,\\' or \\' Judas,\\' or . . . or . . . \\'Haman.\\' No, keep him nameless, until we find out his original name.\" \\n\\n\"Must call him something,\" she objected. \"Can\\'t think of him without thinking something.\" \\n\\n\"Then call him many names, but never the same name twice. Call him \\'Dog\\' to-day, and \\'Mister Dog\\' to-morrow, and the next day something else.\" [SEP]What worked her way northward?[SEP]The _Ariel_']\n",
            "true answer: ['lagoon']\n",
            "answer with seed 42: fish \n",
            "answer with seed 1337: the depth \n",
            "answer with seed 2022: fish \n",
            "f1: 0.0\n",
            "question + passage: ['Who was the Captain?', 'CHAPTER XXII \\n\\nNorthward, along the leeward coast of Malaita, the _Ariel_ worked her leisurely way, threading the colour-riotous lagoon that lay between the shore-reefs and outer-reefs, daring passages so narrow and coral-patched that Captain Winters averred each day added a thousand grey hairs to his head, and dropping anchor off every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life. For Harley and Villa Kennan were in no hurry. So long as the way was interesting, they dared not how long it proved from anywhere to anywhere. \\n\\nDuring this time Jerry learned a new name for himself--or, rather, an entire series of names for himself. This was because of an aversion on Harley Kennan\\'s part against renaming a named thing. \\n\\n\"A name he must have had,\" he argued to Villa. \"Haggin must have named him before he sailed on the _Arangi_. Therefore, nameless he must be until we get back to Tulagi and find out his real name.\" \\n\\n\"What\\'s in a name?\" Villa had begun to tease. \\n\\n\"Everything,\" her husband retorted. \"Think of yourself, shipwrecked, called by your rescuers \\'Mrs. Riggs,\\' or \\'Mademoiselle de Maupin,\\' or just plain \\'Topsy.\\' And think of me being called \\'Benedict Arnold,\\' or \\' Judas,\\' or . . . or . . . \\'Haman.\\' No, keep him nameless, until we find out his original name.\" \\n\\n\"Must call him something,\" she objected. \"Can\\'t think of him without thinking something.\" \\n\\n\"Then call him many names, but never the same name twice. Call him \\'Dog\\' to-day, and \\'Mister Dog\\' to-morrow, and the next day something else.\" [SEP]Were the passages wide?[SEP]No[SEP]What lay between the shore-reefs and outer-reefs?[SEP]Lagoon[SEP]What worked her way northward?[SEP]The _Ariel_']\n",
            "true answer: ['winters']\n",
            "answer with seed 42: captain \n",
            "answer with seed 1337: captain zippo \n",
            "answer with seed 2022: captain zippo \n",
            "f1: 0.0\n",
            "question + passage: ['Were Harley and Villa in a hurry?', 'CHAPTER XXII \\n\\nNorthward, along the leeward coast of Malaita, the _Ariel_ worked her leisurely way, threading the colour-riotous lagoon that lay between the shore-reefs and outer-reefs, daring passages so narrow and coral-patched that Captain Winters averred each day added a thousand grey hairs to his head, and dropping anchor off every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life. For Harley and Villa Kennan were in no hurry. So long as the way was interesting, they dared not how long it proved from anywhere to anywhere. \\n\\nDuring this time Jerry learned a new name for himself--or, rather, an entire series of names for himself. This was because of an aversion on Harley Kennan\\'s part against renaming a named thing. \\n\\n\"A name he must have had,\" he argued to Villa. \"Haggin must have named him before he sailed on the _Arangi_. Therefore, nameless he must be until we get back to Tulagi and find out his real name.\" \\n\\n\"What\\'s in a name?\" Villa had begun to tease. \\n\\n\"Everything,\" her husband retorted. \"Think of yourself, shipwrecked, called by your rescuers \\'Mrs. Riggs,\\' or \\'Mademoiselle de Maupin,\\' or just plain \\'Topsy.\\' And think of me being called \\'Benedict Arnold,\\' or \\' Judas,\\' or . . . or . . . \\'Haman.\\' No, keep him nameless, until we find out his original name.\" \\n\\n\"Must call him something,\" she objected. \"Can\\'t think of him without thinking something.\" \\n\\n\"Then call him many names, but never the same name twice. Call him \\'Dog\\' to-day, and \\'Mister Dog\\' to-morrow, and the next day something else.\" [SEP]Did he have red hair?[SEP]No[SEP]Who was the Captain?[SEP]Winters[SEP]Were the passages wide?[SEP]No[SEP]What lay between the shore-reefs and outer-reefs?[SEP]Lagoon[SEP]What worked her way northward?[SEP]The _Ariel_']\n",
            "true answer: ['no']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['What coast did the Ariel work her way up leisurely?', 'CHAPTER XXII \\n\\nNorthward, along the leeward coast of Malaita, the _Ariel_ worked her leisurely way, threading the colour-riotous lagoon that lay between the shore-reefs and outer-reefs, daring passages so narrow and coral-patched that Captain Winters averred each day added a thousand grey hairs to his head, and dropping anchor off every walled inlet of the outer reef and every mangrove swamp of the mainland that looked promising of cannibal life. For Harley and Villa Kennan were in no hurry. So long as the way was interesting, they dared not how long it proved from anywhere to anywhere. \\n\\nDuring this time Jerry learned a new name for himself--or, rather, an entire series of names for himself. This was because of an aversion on Harley Kennan\\'s part against renaming a named thing. \\n\\n\"A name he must have had,\" he argued to Villa. \"Haggin must have named him before he sailed on the _Arangi_. Therefore, nameless he must be until we get back to Tulagi and find out his real name.\" \\n\\n\"What\\'s in a name?\" Villa had begun to tease. \\n\\n\"Everything,\" her husband retorted. \"Think of yourself, shipwrecked, called by your rescuers \\'Mrs. Riggs,\\' or \\'Mademoiselle de Maupin,\\' or just plain \\'Topsy.\\' And think of me being called \\'Benedict Arnold,\\' or \\' Judas,\\' or . . . or . . . \\'Haman.\\' No, keep him nameless, until we find out his original name.\" \\n\\n\"Must call him something,\" she objected. \"Can\\'t think of him without thinking something.\" \\n\\n\"Then call him many names, but never the same name twice. Call him \\'Dog\\' to-day, and \\'Mister Dog\\' to-morrow, and the next day something else.\" [SEP]Were Harley and Villa in a hurry?[SEP]No[SEP]Did he have red hair?[SEP]No[SEP]Who was the Captain?[SEP]Winters[SEP]Were the passages wide?[SEP]No[SEP]What lay between the shore-reefs and outer-reefs?[SEP]Lagoon[SEP]What worked her way northward?[SEP]The _Ariel_']\n",
            "true answer: ['malaita']\n",
            "answer with seed 42: english \n",
            "answer with seed 1337: australia \n",
            "answer with seed 2022: australia \n",
            "f1: 0.0\n",
            "-------------mctest-------------\n",
            "question + passage: ['Did she live alone?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "true answer: ['no']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['Who did she live with?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "true answer: ['with her mommy and 5 sisters']\n",
            "answer with seed 42: mary \n",
            "answer with seed 1337: mary \n",
            "answer with seed 2022: mary \n",
            "f1: 0.0\n",
            "question + passage: ['What color were her sisters?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Who did she live with?[SEP]with her mommy and 5 sisters[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "true answer: ['orange and white']\n",
            "answer with seed 42: male \n",
            "answer with seed 1337: blue \n",
            "answer with seed 2022: black \n",
            "f1: 0.0\n",
            "question + passage: ['Whose paint was it?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]What did she do to try to make herself the same color as her sisters?[SEP]she painted herself[SEP]Was Cotton happy that she looked different than the rest of her family?[SEP]no[SEP]What color were her sisters?[SEP]orange and white[SEP]Who did she live with?[SEP]with her mommy and 5 sisters[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "true answer: ['the farmer']\n",
            "answer with seed 42: white \n",
            "answer with seed 1337: the cow \n",
            "answer with seed 2022: black \n",
            "f1: 0.0\n",
            "question + passage: [\"What did Cotton's mother and siblings do when they saw her painted orange?\", 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Whose paint was it?[SEP]the farmer[SEP]What did she do to try to make herself the same color as her sisters?[SEP]she painted herself[SEP]Was Cotton happy that she looked different than the rest of her family?[SEP]no[SEP]What color were her sisters?[SEP]orange and white[SEP]Who did she live with?[SEP]with her mommy and 5 sisters[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "true answer: ['they started laughing']\n",
            "answer with seed 42: eat \n",
            "answer with seed 1337: a cow \n",
            "answer with seed 2022: her mother \n",
            "f1: 0.0\n",
            "-------------race-------------\n",
            "question + passage: ['Who is at the door?', 'My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag. \\n\\nI know this lady. It is not her first visit. She is the boy\\'s grandmother, and her daughter bought the house next door last October. \\n\\nHer daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients. \\n\\nI know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice. \\n\\nCommunication between us is somewhat affected by the fact that she doesn\\'t speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother\\'s cooking and salt intake. Instantly, tears welled in my eyes. \\n\\n\"Your mother just can\\'t be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\" \\n\\n\"Oh, no, Lucy.\" Nicole said. \"Mum doesn\\'t like western food. Don\\'t worry about it; she has to cook for the three of them anyway, and she wants to do it.\" \\n\\nThe doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me. \\n\\nI am now working on some more Chinese words--it\\'s the least I can do after such display of kindness. \\n\\n\"Thank you\" is, of course, the first one. Somehow, it seems inadequate.']\n",
            "true answer: ['an elderly chinese lady and a little boy']\n",
            "answer with seed 42: her mother \n",
            "answer with seed 1337: jenny \n",
            "answer with seed 2022: her mother \n",
            "f1: 0.0\n",
            "question + passage: ['What?', 'My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag. \\n\\nI know this lady. It is not her first visit. She is the boy\\'s grandmother, and her daughter bought the house next door last October. \\n\\nHer daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients. \\n\\nI know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice. \\n\\nCommunication between us is somewhat affected by the fact that she doesn\\'t speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother\\'s cooking and salt intake. Instantly, tears welled in my eyes. \\n\\n\"Your mother just can\\'t be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\" \\n\\n\"Oh, no, Lucy.\" Nicole said. \"Mum doesn\\'t like western food. Don\\'t worry about it; she has to cook for the three of them anyway, and she wants to do it.\" \\n\\nThe doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me. \\n\\nI am now working on some more Chinese words--it\\'s the least I can do after such display of kindness. \\n\\n\"Thank you\" is, of course, the first one. Somehow, it seems inadequate.[SEP]Is she carrying something?[SEP]Yes[SEP]Who is at the door?[SEP]An elderly Chinese lady and a little boy']\n",
            "true answer: ['a paper carrier bag']\n",
            "answer with seed 42: her baby \n",
            "answer with seed 1337: her mom \n",
            "answer with seed 2022: her mother \n",
            "f1: 0.0\n",
            "question + passage: ['Who is her daughter?', 'My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag. \\n\\nI know this lady. It is not her first visit. She is the boy\\'s grandmother, and her daughter bought the house next door last October. \\n\\nHer daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients. \\n\\nI know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice. \\n\\nCommunication between us is somewhat affected by the fact that she doesn\\'t speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother\\'s cooking and salt intake. Instantly, tears welled in my eyes. \\n\\n\"Your mother just can\\'t be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\" \\n\\n\"Oh, no, Lucy.\" Nicole said. \"Mum doesn\\'t like western food. Don\\'t worry about it; she has to cook for the three of them anyway, and she wants to do it.\" \\n\\nThe doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me. \\n\\nI am now working on some more Chinese words--it\\'s the least I can do after such display of kindness. \\n\\n\"Thank you\" is, of course, the first one. Somehow, it seems inadequate.[SEP]Do I know her?[SEP]Yes[SEP]What?[SEP]a paper carrier bag[SEP]Is she carrying something?[SEP]Yes[SEP]Who is at the door?[SEP]An elderly Chinese lady and a little boy']\n",
            "true answer: ['nicole']\n",
            "answer with seed 42: mary \n",
            "answer with seed 1337: mary \n",
            "answer with seed 2022: her mother \n",
            "f1: 0.0\n",
            "question + passage: ['Where does Nicole live?', 'My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag. \\n\\nI know this lady. It is not her first visit. She is the boy\\'s grandmother, and her daughter bought the house next door last October. \\n\\nHer daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients. \\n\\nI know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice. \\n\\nCommunication between us is somewhat affected by the fact that she doesn\\'t speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother\\'s cooking and salt intake. Instantly, tears welled in my eyes. \\n\\n\"Your mother just can\\'t be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\" \\n\\n\"Oh, no, Lucy.\" Nicole said. \"Mum doesn\\'t like western food. Don\\'t worry about it; she has to cook for the three of them anyway, and she wants to do it.\" \\n\\nThe doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me. \\n\\nI am now working on some more Chinese words--it\\'s the least I can do after such display of kindness. \\n\\n\"Thank you\" is, of course, the first one. Somehow, it seems inadequate.[SEP]Who is her daughter?[SEP]Nicole[SEP]Do I know her?[SEP]Yes[SEP]What?[SEP]a paper carrier bag[SEP]Is she carrying something?[SEP]Yes[SEP]Who is at the door?[SEP]An elderly Chinese lady and a little boy']\n",
            "true answer: ['shanghai']\n",
            "answer with seed 42: her hand \n",
            "answer with seed 1337: in her mother's \n",
            "answer with seed 2022: in her bedroom \n",
            "f1: 0.0\n",
            "question + passage: ['How is she related to the boy?', 'My doorbell rings. On the step, I find the elderly Chinese lady, small and slight, holding the hand of a little boy. In her other hand, she holds a paper carrier bag. \\n\\nI know this lady. It is not her first visit. She is the boy\\'s grandmother, and her daughter bought the house next door last October. \\n\\nHer daughter, Nicole, speaks fluent English. But she is now in Shanghai, and her parents are here with the little boy. Nicole has obviously told her mother that I am having heart surgery soon, so her mother has decided I need more nutrients. \\n\\nI know what is inside the bag--a thermos with hot soup and a stainless-steel container with rice, vegetables and either chicken, meat or shrimp, sometimes with a kind of pancake. This has become an almost-daily practice. \\n\\nCommunication between us is somewhat affected by the fact that she doesn\\'t speak English and all I can say in Chinese is hello. Once, she brought an iPad as well as the food. She pointed to the screen, which displayed a message from her daughter telling me that her mother wanted to know if the food was all right and whether it was too salty. I am not used to iPads, so she indicated I should go with her to her house. Then, she handed the iPad to her husband and almost immediately I found myself looking at Nicole in Shanghai and discussing her mother\\'s cooking and salt intake. Instantly, tears welled in my eyes. \\n\\n\"Your mother just can\\'t be bringing me meals like this all the time,\" I insisted. \"I can hardly do dishes in return.\" \\n\\n\"Oh, no, Lucy.\" Nicole said. \"Mum doesn\\'t like western food. Don\\'t worry about it; she has to cook for the three of them anyway, and she wants to do it.\" \\n\\nThe doorbell keeps ringing and there is the familiar brown paper carrier bag, handed smilingly to me. \\n\\nI am now working on some more Chinese words--it\\'s the least I can do after such display of kindness. \\n\\n\"Thank you\" is, of course, the first one. Somehow, it seems inadequate.[SEP]Where does Nicole live?[SEP]Shanghai[SEP]Who is her daughter?[SEP]Nicole[SEP]Do I know her?[SEP]Yes[SEP]What?[SEP]a paper carrier bag[SEP]Is she carrying something?[SEP]Yes[SEP]Who is at the door?[SEP]An elderly Chinese lady and a little boy']\n",
            "true answer: ['mother']\n",
            "answer with seed 42: she is a baby \n",
            "answer with seed 1337: she likes her \n",
            "answer with seed 2022: she likes her \n",
            "f1: 0.0\n",
            "-------------wikipedia-------------\n",
            "question + passage: ['How many burroughs are there?', 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n\\nThe North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul\\'s Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.']\n",
            "true answer: ['five']\n",
            "answer with seed 42: two \n",
            "answer with seed 1337: three \n",
            "answer with seed 2022: two \n",
            "f1: 0.0\n",
            "question + passage: ['What separates it from new jersey?', 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n\\nThe North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul\\'s Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.[SEP]Where is it?[SEP]In the southwest of the city[SEP]Is staten island one?[SEP]Yes[SEP]and state?[SEP]New York[SEP]in what city?[SEP]New York City[SEP]How many burroughs are there?[SEP]five']\n",
            "true answer: ['arthur kill and the kill van kull']\n",
            "answer with seed 42: the city \n",
            "answer with seed 1337: new haven \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['What is its population?', 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n\\nThe North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul\\'s Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.[SEP]What separates it from new jersey?[SEP]Arthur Kill and the Kill Van Kull[SEP]Where is it?[SEP]In the southwest of the city[SEP]Is staten island one?[SEP]Yes[SEP]and state?[SEP]New York[SEP]in what city?[SEP]New York City[SEP]How many burroughs are there?[SEP]five']\n",
            "true answer: ['476015']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: it is a new haven \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['Is it the most populated?', 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n\\nThe North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul\\'s Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.[SEP]What is its population?[SEP]476,015[SEP]What separates it from new jersey?[SEP]Arthur Kill and the Kill Van Kull[SEP]Where is it?[SEP]In the southwest of the city[SEP]Is staten island one?[SEP]Yes[SEP]and state?[SEP]New York[SEP]in what city?[SEP]New York City[SEP]How many burroughs are there?[SEP]five']\n",
            "true answer: ['no']\n",
            "answer with seed 42: yes \n",
            "answer with seed 1337: yes \n",
            "answer with seed 2022: yes \n",
            "f1: 0.0\n",
            "question + passage: ['what ethnicity is the majority?', 'Staten Island is one of the five boroughs of New York City in the U.S. state of New York. In the southwest of the city, Staten Island is the southernmost part of both the city and state of New York, with Conference House Park at the southern tip of the island and the state. The borough is separated from New Jersey by the Arthur Kill and the Kill Van Kull, and from the rest of New York by New York Bay. With a 2016 Census-estimated population of 476,015, Staten Island is the least populated of the boroughs but is the third-largest in area at . Staten Island is the only borough of New York with a non-Hispanic White majority. The borough is coextensive with Richmond County, and until 1975 was the Borough of Richmond. Its flag was later changed to reflect this. Staten Island has been sometimes called \"the forgotten borough\" by inhabitants who feel neglected by the city government. \\n\\nThe North Shore—especially the neighborhoods of St. George, Tompkinsville, Clifton, and Stapleton—is the most urban part of the island; it contains the designated St. George Historic District and the St. Paul\\'s Avenue-Stapleton Heights Historic District, which feature large Victorian houses. The East Shore is home to the F.D.R. Boardwalk, the fourth-longest in the world. The South Shore, site of the 17th-century Dutch and French Huguenot settlement, developed rapidly beginning in the 1960s and 1970s and is now mostly suburban in character. The West Shore is the least populated and most industrial part of the island.[SEP]Is it the most populated?[SEP]no[SEP]What is its population?[SEP]476,015[SEP]What separates it from new jersey?[SEP]Arthur Kill and the Kill Van Kull[SEP]Where is it?[SEP]In the southwest of the city[SEP]Is staten island one?[SEP]Yes[SEP]and state?[SEP]New York[SEP]in what city?[SEP]New York City[SEP]How many burroughs are there?[SEP]five']\n",
            "true answer: ['non-hispanic white']\n",
            "answer with seed 42: the north groups \n",
            "answer with seed 1337: canada \n",
            "answer with seed 2022: new haven \n",
            "f1: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tinytiny_\", \"_testbeampred.pickle\", test_ds, XQA_test, kind=\"best\", skip_yn=True)"
      ],
      "metadata": {
        "id": "lyxBZF07vk5B",
        "outputId": "2986c6e5-6976-489a-de6b-5e1ea97528a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lyxBZF07vk5B",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------cnn-------------\n",
            "question + passage: ['What news agency does Tony work for?', 'Fort Lauderdale, Florida (CNN) -- Just taking a sip of water or walking to the bathroom is excruciatingly painful for 15-year-old Michael Brewer, who was burned over 65 percent of his body after being set on fire, allegedly by a group of teenagers. \\n\\n\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\" his mother, Valerie Brewer, told CNN on Wednesday. \\n\\nBrewer and her husband, Michael Brewer, Sr., spoke to CNN\\'s Tony Harris, a day after a 13-year-old boy who witnessed last month\\'s attack publicly read a written statement: \\n\\n\"I want to express my deepest sympathy to Mikey and his family,\" Jeremy Jarvis said. \"I will pray for Mikey to grow stronger every day and for Mikey\\'s speedy recovery.\" \\n\\nJarvis\\' older brother has been charged in the October 12 attack in Deerfield Beach, Florida. \\n\\nWhen asked about the teen\\'s statement, Valerie Brewer -- who knows the Jarvis family -- said she \"can\\'t focus on that.\" \\n\\n\"I would really like to stay away from that because that brings negative energy to me and I don\\'t need that right now,\" she said. \\n\\nHer son remains in guarded condition at the University of Miami\\'s Jackson Memorial Hospital Burn Center. He suffered second- and third-degree burns over about two-thirds of his body, according to the hospital\\'s associate director, Dr. Carl Schulman. \\n\\nThe teen faces a lifelong recovery from his injuries, Schulman told CNN\\'s Harris. [SEP]How so?[SEP]His parents.[SEP]Are they related to the victim?[SEP]Yes[SEP]Who spoke to Tony Harris?[SEP]Valerie Brewer and her husband Michael Brewer, Sr.[SEP]How long before he recovers from his injury?[SEP]He has a lifelong recoery.[SEP]Is the victim still in the hospital?[SEP]Yes[SEP]Who was that?[SEP]Jeremy Jarvis\\' older brother.[SEP]Do we know who caused the burns?[SEP]Yes[SEP]How badly?[SEP]over 65% of his body[SEP]What happened to him?[SEP]He was burned[SEP]What is the subject of the story?[SEP]Michael Brewer']\n",
            "true answer: ['cnn']\n",
            "answer with seed 42: cnn \n",
            "answer with seed 1337: cnn \n",
            "answer with seed 2022: cnn \n",
            "f1: 100.0\n",
            "question + passage: ['What party does he belong to?', 'Richmond, Virginia (CNN) -- The Virginia governor\\'s race, billed as the marquee battle of an otherwise anticlimactic 2013 election cycle, is shaping up to be a foregone conclusion. \\n\\nDemocrat Terry McAuliffe, the longtime political fixer and moneyman, hasn\\'t trailed in a poll since May. Barring a political miracle, Republican Ken Cuccinelli will be delivering a concession speech on Tuesday evening in Richmond. \\n\\nIn recent cycles, the Virginia race has been a key off-year barometer of national political sentiment. Four years ago, Republican Bob McDonnell won in blowout fashion, a victory that presaged the following year\\'s GOP midterm wave. In 2005, Democrat Tim Kaine captured the governor\\'s mansion, tapping into anxiety about President George W. Bush\\'s handling of the Iraq War and Hurricane Katrina. \\n\\nNot so this year. The McAuliffe-Cuccinelli race has been defined by small-bore issues and character attacks rather than sweeping national concerns. \\n\\nBut despite the lack of late fireworks, there are plenty of crucial insights to be gleaned from the Virginia campaign. \\n\\nHere\\'s what you need to know about this year\\'s most important race: \\n\\n1. The 2012 playbook is still potent for Democrats \\n\\nMcAuliffe isn\\'t exactly squeaky-clean. A longtime wheeler-dealer who has been less than forthcoming with his tax returns, \"the Macker\" has a history of eyebrow-raising business ventures that make for dangerous campaign fodder. The opposition research book on the former Democratic National Committee chairman is as thick a Virginia live oak. \\n\\nBut Democrats have successfully turned the race into a referendum on Cuccinelli, defining him over the summer as a right-wing zealot. A Washington Post poll last week showed that two-thirds of McAuliffe supporters said they were voting against Cuccinelli, rather than for McAuliffe. [SEP]Who is his opponent?[SEP]Ken Cuccinelli[SEP]Who is the democratic candidate?[SEP]Terry McAuliffe[SEP]Where?[SEP]Virginia[SEP]What are the candidates running for?[SEP]Governor']\n",
            "true answer: ['republican']\n",
            "answer with seed 42: republican \n",
            "answer with seed 1337: republican \n",
            "answer with seed 2022: republican \n",
            "f1: 100.0\n",
            "question + passage: ['When?', '(CNN) -- Chelsea\\'s star striker Didier Drogba has been suffering from malaria, his club manager revealed on Tuesday, but the Ivory Coast player will still line up for the London derby against Fulham in the English Premier League on Wednesday. \\n\\nDrogba started on the bench for Chelsea\\'s 2-0 defeat to Liverpool on Sunday, having missed recent matches against Aston Villa and Spartak Moscow due to a suspected virus. \\n\\nHowever, the results of blood tests showed that he had in fact contracted the tropical disease. \\n\\n\"A test showed malaria,\" Chelsea manager Carlo Ancelotti told his club\\'s official website. \"He lost his condition, he lost power. \\n\\n\"Didier had a difficulty to train because he didn\\'t feel good, he didn\\'t have power to train. He was unselfish to play also when he was not 100 percent.\" \\n\\nBut the Italian said Drogba was now back to health and would be fit for the league leaders\\' home clash with Fulham on Wednesday. \\n\\n\"He suffered obviously but after treatment, he will be better,\" Ancelotti said. \"One time it was serious, now there is the possibility to treat and come back well. He is okay. Tomorrow he will play.\" \\n\\nAncelotti said Ghana midfielder Michael Essien would return to the Chelsea line-up, having missed the Liverpool game with a toe problem, but Frank Lampard is not yet ready to make his long-awaited return. \\n\\nThe England midfielder, who has been sidelined following a hernia operation, is scheduled to make his comeback against Sunderland on Sunday. \\n\\n\"Lampard has been training with us and he is good. He is able to play; he is fit because he worked very hard physically,\" Ancelotti said. [SEP]Who will he play against when he comes back?[SEP]Sunderland[SEP]Did he have to have surgery?[SEP]yes[SEP]What was wrong with him?[SEP]a hernia.[SEP]What about Frank Lampard?[SEP]not yet[SEP]Why wasn\\'t he playing?[SEP]a toe problem[SEP]What position does he play?[SEP]midfielder[SEP]Who else is coming back for the game?[SEP]Michael Essie[SEP]Did he say that he suffered?[SEP]Yes[SEP]Who is he?[SEP]Chelsea manager[SEP]Who said he was ready to play again?[SEP]Ancelotti[SEP]How many?[SEP]Two[SEP]Did he miss any games?[SEP]Yes[SEP]When?[SEP]Wednesday[SEP]Against who?[SEP]Fulham[SEP]Is he going to play anyway?[SEP]Yes[SEP]What\\'s his name?[SEP]Didier Drogba[SEP]Who had malaria?[SEP]Chelsea\\'s star striker']\n",
            "true answer: ['sunday']\n",
            "answer with seed 42: sunday \n",
            "answer with seed 1337: sunday \n",
            "answer with seed 2022: sunday \n",
            "f1: 100.0\n",
            "question + passage: ['Which news outlet did an interview with Carlos?', '(CNN) -- The bodies of six men -- including a California educator -- were found Thursday in the north-central Mexican state of Durango, hours after they had been abducted from a nearby restaurant, the man\\'s relatives said Friday. \\n\\n\"He was needlessly and senselessly murdered,\" said Carlos Salcedo, 37, about his brother, Augustin Roberto \"Bobby\" Salcedo, of El Monte, east of Los Angeles. \\n\\nBobby Salcedo, 33, had traveled with his wife to visit her family in Gomez Palacio, his brother said. They were eating in a restaurant Wednesday night when armed men barged in, forced everyone onto the floor and abducted all six men who were in the party, Carlos Salcedo told CNN in a telephone interview. \\n\\nAt 7 a.m. Thursday, police notified his sister-in-law that they had found her husband\\'s body in a local ravine with bullet wounds to the head and chest, he said. \\n\\n\"All indications are that this was just random, a violent act, just a case of being in the wrong place at the wrong time,\" he told reporters in El Monte. \\n\\n\"What we really want to do is just shed a light on this incident and the senseless, violent acts that are happening across the border from us and really just put a spotlight on this and make sure that we find justice.\" \\n\\n\"He was a brilliant, a bright star for our community, and he as taken from us,\" said El Monte Mayor Andre Quintero of Salcedo, who served on the city school district board. \"He was stolen from us and now we need to hold them accountable for what they did.\" [SEP]Was this a random act?[SEP]yes[SEP]What body parts were he shot at?[SEP]head and chest[SEP]On what day?[SEP]Thursday[SEP]What time was the police notified?[SEP]7 a.m[SEP]They were visiting his wife\\'s family who lived where?[SEP]Gomez Palacio[SEP]How old was he?[SEP]37[SEP]And what was the name of his brother who was killed?[SEP]Augustin Roberto \"Bobby\" Salcedo[SEP]Who stated that his brother was murdered in a senseless way?[SEP]Carlos Salcedo[SEP]Where were they abducted from?[SEP]a nearby restaurant[SEP]Is that in Mexico?[SEP]yes[SEP]Where did this happen/[SEP]Durango[SEP]Were one of those men a teacher?[SEP]Yes[SEP]Who was murdered?[SEP]six men']\n",
            "true answer: ['cnn']\n",
            "answer with seed 42: cnn \n",
            "answer with seed 1337: cnn \n",
            "answer with seed 2022: cnn \n",
            "f1: 100.0\n",
            "question + passage: ['What news outlet did Biven speak with?', '(CNN) -- A body discovered at Churchill Downs on Sunday, a day after the storied Louisville racetrack hosted the Kentucky Derby, may have been the victim of a homicide, police said. \\n\\nWorkers in the barn area discovered the body early in the morning and notified track security, which called police, said Robert Biven, a spokesman for the Louisville Metropolitan Police Department. \\n\\n\"We just got the call just prior to 5 a.m. to respond to the backside\" of the racetrack, Biven told CNN. \\n\\nPolice spokeswoman Alicia Smiley said police suspect foul play. \\n\\nThe body, which has not been identified, appears to be a Latino man in his 30s or 40s, Biven said. \\n\\nAbout 400 people were located Saturday night in the rear of the racetrack, he said. \"So we are trying to speak with as many people as we possibly can,\" he said. \"We do have a few leads coming in.\" An autopsy is to be carried out Monday morning. \\n\\nBiven described the track\\'s backside as \"like a mini city,\" with 48 barns, workers\\' dormitories and areas where trainers live. \"It\\'s a 24-hour operation,\" he said. \\n\\nI\\'ll Have Another wins Kentucky Derby \\n\\nOperations at the racetrack were to continue normally on Sunday, Churchill Downs spokesman John Asher said. No races are scheduled at the track for three days, but cleanup from Saturday\\'s race was to continue and the racetrack museum was to be open, he said. \\n\\nCNN\\'s Kara Devlin and Christine Sever contributed to this report \\n\\n[SEP]What event had the track hosted the day before?[SEP]the Kentucky Derby[SEP]In what city?[SEP]Louisville[SEP]Is that a racetrack?[SEP]Yes[SEP]Where?[SEP]at Churchill Downs[SEP]On what day was the body found?[SEP]on Sunday[SEP]Who is Robert Biven?[SEP]a spokesman for the Louisville Metropolitan Police Department[SEP]And whom did they call?[SEP]police[SEP]Whom did they contact about it?[SEP]track security[SEP]What time of day did workers locate the body?[SEP]early in the morning']\n",
            "true answer: ['cnn']\n",
            "answer with seed 42: cnn \n",
            "answer with seed 1337: cnn \n",
            "answer with seed 2022: cnn \n",
            "f1: 100.0\n",
            "-------------gutenberg-------------\n",
            "question + passage: ['who did they prefer?', 'CHAPTER VI.—LEO ASSERTS HIS RIGHTS. \\n\\nAt once a crowd of performers surrounded the pair. Very few of them liked Jack Snipper, and they wondered what Leo would do should the gymnast attack the boy. \\n\\n“Call me a braggart, will you!” roared Snipper. \\n\\n“Don’t you dare to touch me with that club!” replied Leo calmly. \\n\\n“I’ll teach you a lesson!” \\n\\nAnd, swinging the Indian club over his head, Jack Snipper made a savage blow at the young gymnast. \\n\\nHad the stick struck Leo the boy’s head would have sustained a severe injury. \\n\\nBut as quick as a flash Leo dodged, and the Indian club merely circled through the empty air. \\n\\n“For shame, Snipper!” \\n\\n“Do you want to kill the boy?” \\n\\n“What harm has he done?” \\n\\nAnd so the cries ran on. \\n\\n“Mind your own affairs!” shouted the maddened gymnast. “I’m going to teach the boy a lesson!” \\n\\nAgain he sprang at Leo. \\n\\nBut now suddenly the Indian club was caught. A dexterous twist, and it went flying out of reach across the dressing tent. \\n\\nThen, before Snipper could recover, he received a stinging slap full in the face that sent him staggering backward on the grass. \\n\\nA shout of approval went up. \\n\\n“Good for Leo!” \\n\\n“That’s right, boy, stand up for your rights!” \\n\\nThe shout brought Adam Lambert, the general manager, to the scene. \\n\\nNo sooner had he appeared than all the performers walked away. It was against the rules to fight, and every one present was liable to a heavy fine. [SEP]what were they surrounded by?[SEP]a crowd of performers[SEP]if it connected what would have happened?[SEP]the boy’s head would have sustained a severe injury.[SEP]how severe a blow was it?[SEP]a savage blow[SEP]who ws it aimed at?[SEP]Leo[SEP]what did Jack swing?[SEP]An Indian club[SEP]which chapter are we reading?[SEP]Chapter 6.']\n",
            "true answer: ['leo']\n",
            "answer with seed 42: leo \n",
            "answer with seed 1337: leo \n",
            "answer with seed 2022: leo \n",
            "f1: 100.0\n",
            "question + passage: ['How many people are eating together?', 'CHAPTER XXIII \\n\\nLOVERS \\n\\nBernard Maddison kept his engagement that evening, and dined alone with Lady Thurwell and Helen. There had been some talk of going to the opera afterwards, but no one seemed to care about it, and so it dropped through. \\n\\n\"For my part,\" Lady Thurwell said, as they sat lingering over their dessert, \"I shall quite enjoy an evening\\'s rest. You literary men, Mr. Maddison, talk a good deal about being overworked, but you know nothing of the life of a chaperon in the season. I tell Helen that she is sadly wanting in gratitude. We do everything worth doing--picture galleries, matinées, shopping, afternoon calls, dinners, dances, receptions--why, there\\'s no slavery like it.\" \\n\\nHelen laughed softly. \\n\\n\"We do a great deal too much, aunt,\" she said. \"I am almost coming round to my father\\'s opinion. You know, Mr. Maddison, he very seldom comes to London, and then only when he wants to pay a visit to his gunmaker, or to renew his hunting kit, or something of that sort. London life does not suit him at all.\" \\n\\n\"I think your father a very wise man,\" he answered. \"He seeks his pleasures in a more wholesome manner.\" \\n\\nShe looked thoughtful. \\n\\n\"Yes, I suppose, ethically, the life of a man about town is on a very low level. That is why one meets so few who interest one, as a rule. Don\\'t you think all this society life very frivolous, Mr. Maddison?\" \\n\\n\"I am not willing to be its judge,\" he answered. \"Yet it is a moral axiom that the higher we seek for our pleasures the greater happiness we attain to. I am an uncompromising enemy to what is known as fashionable society, so I will draw no conclusions.\" [SEP]Does Maddison find it all shallow?[SEP]he draws no conclusions[SEP]How many interesting people does she feel one tends to meet?[SEP]few[SEP]Did she immediately dismiss the thought?[SEP]no[SEP]Why\\'s that?[SEP]He seeks his pleasures in a more wholesome manner[SEP]Who thinks that\\'s a smart move?[SEP]Mr. Maddison[SEP]Any other reason?[SEP]or to renew his hunting kit[SEP]Why does he come then?[SEP]when he wants to pay a visit to his gunmaker[SEP]Does he visit there often?[SEP]no[SEP]Who does city life not favor?[SEP]Helen\\'s father']\n",
            "true answer: ['three']\n",
            "answer with seed 42: three \n",
            "answer with seed 1337: three \n",
            "answer with seed 2022: three \n",
            "f1: 100.0\n",
            "question + passage: ['How many other folks were there?', 'CHAPTER IV \\n\\nThe Princess looked up with ill-concealed eagerness as Forrest entered. \\n\\n\"Well,\" she asked, \"have you any news?\" \\n\\nForrest shook his head. \\n\\n\"None,\" he answered. \"I am up for the day only. Cecil will not let me stay any longer. He was here himself the day before yesterday. We take it by turns to come away.\" \\n\\n\"And there is nothing to tell me?\" the Princess asked. \"No change of any sort?\" \\n\\n\"None,\" Forrest answered. \"It is no good attempting to persuade ourselves that there is any.\" \\n\\n\"What are you up for, then?\" she asked. \\n\\nHe laughed hardly. \\n\\n\"I am like a diver,\" he answered, \"who has to come to the surface every now and then for fresh air. Life down at Salthouse is very nearly the acme of stagnation. Our only excitement day by day is the danger--and the hope.\" \\n\\n\"Is Cecil getting braver?\" the Princess asked. \\n\\n\"I think that he is, a little,\" Forrest answered. \\n\\nThe Princess nodded. \\n\\n\"We met him at the Bellamy Smiths\\',\" she said. \"It was quite a reunion. Andrew was there, and the Duke.\" \\n\\nForrest\\'s face darkened. \\n\\n\"Meddling fool,\" he muttered. \"Do you know that there are two detectives now in Salthouse? They come and go and ask all manner of questions. One of them pretends that he believes Engleton was drowned, and walks always on the beach and hires boatmen to explore the creeks. The other sits in the inn and bribes the servants with drinks to talk. But don\\'t let\\'s talk about this any longer. How is Jeanne?\" [SEP]Where did they meet him?[SEP]Bellamy Smiths[SEP]What was it?[SEP]he is[SEP]Did she get any response?[SEP]yes[SEP]What was that?[SEP]Is Cecil getting braver[SEP]Did she ask anything about Cecil?[SEP]yes[SEP]Did he feel good about it?[SEP]no[SEP]Who did Forrest compared himself?[SEP]a diver[SEP]Who was that?[SEP]Cecil[SEP]Did anyone obsturcting him?[SEP]yes[SEP]Did they have any messase?[SEP]no[SEP]Who did she ask?[SEP]Forrest[SEP]Who was looking for some message?[SEP]The Princess']\n",
            "true answer: ['two']\n",
            "answer with seed 42: two \n",
            "answer with seed 1337: two \n",
            "answer with seed 2022: two \n",
            "f1: 100.0\n",
            "question + passage: ['How many?', \"CHAPTER XXIX \\n\\nHave you seen but a bright lily grow, Before rude hands have touched it? Have you marked but the fall of the snow, Before the soil hath smutched it?--BEN JONSON \\n\\nAt the end of a week Mervyn made his appearance in a vehement hurry. Cecily's next sister, an officer's wife, was coming home with two little children, for a farewell visit before going to the Cape, and Maria and Bertha must make way for her. So he wanted to take Phoebe home that afternoon to get the Underwood ready for them. \\n\\n'Mervyn, how can I go? I am not nearly ready.' \\n\\n'What can you have been doing then?' he exclaimed, with something of his old temper. \\n\\n'This house has been in such a state.' \\n\\n'Well, you were not wanted to nurse the sick man, were you? I thought you were one that was to be trusted. What more is there to do?' \\n\\nPhoebe looked at her list of commissions, and found herself convicted. Those patterns ought to have been sent back two days since. What had she been about? Listening to Mr. Randolf's explanations of the _Hiawatha_ scenery! Why had she not written a note about that hideous hearth-rug? Because Mr. Randolf was looking over Stowe's _Survey of London_. Methodical Phoebe felt herself in disgrace, and yet, somehow, she could not be sorry enough; she wanted a reprieve from exile at Hiltonbury, alone and away from all that was going on. At least she should hear whether _Macbeth_, at the Princess's Theatre, fulfilled Mr. Randolf's conceptions of it; and if Mr. Currie approved his grand map of the Newcastle district, with the little trees that she had taught him to draw. [SEP]Does the officer's wife have children?[SEP]Yes[SEP]Who is Cecily's sister?[SEP]an officer's wife[SEP]What did Mervyn do at week's end?[SEP]made his appearance[SEP]What did she teach Mr. Currie to draw?[SEP]little trees[SEP]From where?[SEP]at Hiltonbury[SEP]What did Phoebe want a reprieve from?[SEP]exile\"]\n",
            "true answer: ['two']\n",
            "answer with seed 42: two \n",
            "answer with seed 1337: two \n",
            "answer with seed 2022: two \n",
            "f1: 100.0\n",
            "question + passage: ['in what city', 'CHAPTER XIII. \\n\\nA JOYFUL MEETING. \\n\\nIt is highly probable that one might have searched over New York City that night and not found a happier household than that of Mrs. Green\\'s. Paul was so wonderfully happy in the thought that he was going back to Chicago, where, even though he could not see his parents, he should find relatives and friends, that he could talk of little else. Even the theatre was forgotten by him; for when Mopsey spoke of the necessity of getting another boy to take his place in the dramatic company he hardly gave the matter a thought, except to say that he hoped they would make plenty of money out of it. And Paul\\'s partners were happy, more happy than they could possibly have been by any other outlay of their money; Paul\\'s pleasure reflected on them to such a degree that they became almost as much excited as he was before the evening was over. \\n\\nGood Mrs. Green alternately laughed and cried, until she seemed to realize that such nervousness was not exactly suitable to the occasion, and then she busied herself by reading one of the papers Ben had brought home. \\n\\nMaster Treat had spent so much time on the good work he had carried through so successfully, and then had paid so much more attention to the boy he was going to surprise than to the sale of his goods, that, instead of helping Johnny as had been his purpose when he took some of his papers to sell, he was a drawback, and the consequence was that Mrs. Green had three evening papers to read, while Messrs. Jones and Treat had been \"stuck\" just that number. [SEP]whose house was happy?[SEP]Mrs. Green\\'s[SEP]what chapter is this?[SEP]XIII.']\n",
            "true answer: ['new york city']\n",
            "answer with seed 42: new york city \n",
            "answer with seed 1337: new haven \n",
            "answer with seed 2022: new york city \n",
            "f1: 80.0\n",
            "-------------mctest-------------\n",
            "question + passage: ['how many vehicles did they need to get there?', \"Jenny's family lived in a small apartment in Seattle. One day Jenny came home from school and her mom told her that the family was moving to Utah. Jenny was sad to leave her friends. Jenny was sad to leave her school. Jenny helped her mom pack boxes and clean their apartment to get ready for the move. Soon the day came when Jenny's dad brought a large truck to the parking lot and all of the family's things were put inside. Jenny and her mom rode in their car and her dad drove the truck towards Utah. Jenny loved getting to eat lots of yummy fast food on the way. When the family got to their new home in Utah, Jenny helped her parents to take all of the boxes into the house. She loved her new bedroom! When Jenny was emptying box of her toys, there was a knock at the door. It was a little girl who wanted Jenny to play! Jenny was going to like Utah![SEP]Did Jenny help unpack?[SEP]yes[SEP]who was she leaving behind?[SEP]her friends[SEP]was Jenny happy?[SEP]no[SEP]what did they live in?[SEP]in a small apartment[SEP]in a big house?[SEP]no[SEP]where were they presently?[SEP]in Seattle[SEP]where were they going?[SEP]to Utah[SEP]Did Jenny help her mom pack?[SEP]yes\"]\n",
            "true answer: ['two']\n",
            "answer with seed 42: two \n",
            "answer with seed 1337: two \n",
            "answer with seed 2022: two \n",
            "f1: 100.0\n",
            "question + passage: ['How many?', \"Brendan loves cats. He owns 8 cats. He has 7 girl cats and only 1 boy cat. Brendan brushes the cats' hair every day. He makes sure to feed them every morning and evening and always checks to see if the cats have water. Sometimes he feeds them special treats because he loves them. Each cat gets 3 treats. He doesn't give them food like chips and cake and candy, because those foods aren't good for cats. He likes to play with the cats. The cats like to chase balls of paper that Brendan makes for them. Some of his cats have orange fur, some have black fur, some are spotted and one is white. The white cat is Brendan's favorite. She is the first cat he owned. Her name is Snowball. When he first got Snowball she was a kitten. His other cats are named Fluffy, Salem, Jackie, Cola, Snickers, Pumpkin and Whiskers.[SEP]What do they get fed?[SEP]treats[SEP]What is groomed?[SEP]cat's hair[SEP]How many?[SEP]7 girl cats and only 1 boy cat[SEP]Are there more males or females?[SEP]females[SEP]How many does he have?[SEP]Eight[SEP]What does he care for?[SEP]cats\"]\n",
            "true answer: ['three']\n",
            "answer with seed 42: three \n",
            "answer with seed 1337: three \n",
            "answer with seed 2022: three \n",
            "f1: 100.0\n",
            "question + passage: ['When did the snow melt?', 'On a snowy winter morning, the brown-haired lady saw a squirrel that was hurt. It only had three legs, and it looked hungry. She put some corn out for the squirrel to eat, but other bully squirrels came, too. The brown-haired lady started giving the little squirrel peanuts to eat. She gave some to the bully squirrels, too, so they would leave the three-legged squirrel alone. \\n\\nThe winter snow melted and then it was spring. The grass turned green and the air was warm. Now, when the little squirrel with three legs would come to see the brown-haired lady with the peanuts, it would take the peanuts and dig a little hole and hide the peanuts for later. The squirrel would hold the peanut in its mouth and dig and dig and dig, and then it would put the peanut in the hole and pat it down with its little front paw. Then it would run back over to the brown-haired lady and get some more peanuts to eat.[SEP]What did she feed them?[SEP]peanuts[SEP]Did She feed other squirrels?[SEP]yes[SEP]What color hair did the lady have?[SEP]brown[SEP]what did the lady put out for the squirrel?[SEP]corn[SEP]Was he hungry?[SEP]yes[SEP]How many?[SEP]three[SEP]Did the squirrel have legs?[SEP]yes[SEP]Was it snowing?[SEP]yes[SEP]Who seen a squirrel?[SEP]the lady']\n",
            "true answer: ['spring']\n",
            "answer with seed 42: spring \n",
            "answer with seed 1337: spring \n",
            "answer with seed 2022: spring \n",
            "f1: 100.0\n",
            "question + passage: ['What gender was the parent?', \"Maxine was a happy frog that lived in a beautiful pond by the river. She loved to play in the water and take a bath every day. But her friends, Martin, Edgar, and Cindy didn't like to take baths. So one day when she was swimming alone, she met a new friend names Thomas. Thomas loved to take lots of baths, so he became friends with Maxine. But Martin, Edgar, and Cindy didn't like Thomas. So one day when Maxine and Thomas were swimming, Cindy did something mean. She threw rocks and Maxine and Thomas. Maxine's dad saw what happened and he was very mad. He went over and yelled at Cindy for what she did. After that Cindy didn't throw any rocks, and Maxine and Thomas could swim together and take lots of baths. They were very happy since they could play in the water as much as they wanted without other frogs being mean to them.[SEP]Who had a parent intervene?[SEP]Maxine[SEP]Which male enjoyed the water?[SEP]Thomas[SEP]At whom?[SEP]Cindy[SEP]Who yelled?[SEP]MAxine's dad[SEP]What mean thing did she do?[SEP]She threw rocks[SEP]Who was mean?[SEP]Cindy[SEP]Which female didn't?[SEP]Cindy[SEP]Which of the four friends enjoyed bathing?[SEP]Maxine\"]\n",
            "true answer: ['male']\n",
            "answer with seed 42: male \n",
            "answer with seed 1337: male \n",
            "answer with seed 2022: male \n",
            "f1: 100.0\n",
            "question + passage: ['How many ingredients did he already have?', \"Mike wanted to make a cake for his Mom's birthday. His dad was going to help him. Mike had eggs, milk, and flour at his house, but no sugar! Dad told Mike to take his bicycle to the store so he could buy sugar for the cake. On his way to the store, Mike saw his friend, Sally, at the park. He rode over to say hello. Mike and Sally played lots of games at the park. After a long time, Mike saw it was starting to get dark. He needed to hurry if he was going to make it to the store and get home before night time. Mike rode as fast as he could, and made it to the store. The store was really big, but Mike found the sugar really fast. When Mike was on his way to the front of the store to pay for the sugar, he saw a toy he had been wanting for a long time. But Mike only had enough money to pay for the sugar or the toy. Mike didn't know what to do! The cake would taste good and would make his mom happy. But, the toy was so cool! Mike bought the sugar for his mom's cake, because she was always so nice to him. He could always get the toy another time. \\n\\n\\n\\n2. What did Mike find at the store that he wanted to buy[SEP]Who wanted to bake something?[SEP]Mike\"]\n",
            "true answer: ['three']\n",
            "answer with seed 42: three \n",
            "answer with seed 1337: three \n",
            "answer with seed 2022: three \n",
            "f1: 100.0\n",
            "-------------race-------------\n",
            "question + passage: ['How often did they visit each other?', 'Brownie and Spotty were neighbor dogs who met every day to play together. These two loved each other and played together so often that they had worn a path through the grass of the field between their respective houses. One evening, Brownie\\'s family noticed that Brownie hadn\\'t returned home. They went looking for him with no success and by the next week he was still missing. Curiously, Spotty showed up at Brownie\\'s house alone. Barking, whining and generally pestering Brownie\\'s human family. Busy with their own lives, they just ignored the nervous little neighbor dog. Continuously,Ted, Brownie\\'s owner, was disturbed by the angry, determined little dog. Spotty followed Ted about, barking insistently, then rushing toward a nearby empty lot and back, as if to say, \"Follow me! It\\'s urgent!\" Eventually, Ted followed Spotty to a deserted spot half a mile from the house. There Ted found his beloved Brownie alive, one of his hind legs crushed in a steel leghold trap. Horrified, Ted now wished he\\'d taken Spotty\\'s earlier appeals seriously. Then Ted noticed something quite remarkable. Spotty had done more than simply led Brownie\\'s human owner to his trapped friend. In a circle around the injured dog, Ted found an array of dog food and table scraps which were later identified as the remains of every meal Spotty had been fed that week! Spotty had been visiting Brownie regularly, in the hope of keeping his friend alive by sacrificing his own comfort. Spotty had evidently stayed with Brownie to protect him from hunger and other dangers, and keep his spirits up. Brownie\\'s leg was treated by a veterinarian and he recovered. For many years thereafter, the two families watched the faithful friends chasing each other down that well worn path between their houses.[SEP]Who were the two canines who lived next door to each other?[SEP]Brownie and Spotty']\n",
            "true answer: ['every day']\n",
            "answer with seed 42: every day \n",
            "answer with seed 1337: every day \n",
            "answer with seed 2022: every day \n",
            "f1: 100.0\n",
            "question + passage: ['True or false: the dog is ugly.', \"Can you imagine keeping an alien dog as a pet? This is what happens in CJ7--a wonderful movie made in China. Maybe some of you saw it. It came out in January, 2008. The movie is about a poor man Ti, his son Dicky and their alien dog CJ7. Dicky, a 10-year-old boy, lives a poor life with his father Ti, a worker. One day,his father finds a ball in the trash and he gives it to Dicky. The ball becomes a cute alien dog. It's a small dog with big eyes and green hair. It can talk and do magic . Soon the dog comes to love Ti and his son. It goes to school with Dicky. It makes him laugh, but it makes trouble, too. When Ti falls off a building and dies, CJ7 saves his life. Because the dog loses all its power , it becomes a doll. But Dicky still wears the dog around his neck. He hopes that CJ7 will come back to life one day.[SEP]What does the ball turn into?[SEP]an alien dog\"]\n",
            "true answer: ['false']\n",
            "answer with seed 42: false \n",
            "answer with seed 1337: false \n",
            "answer with seed 2022: false \n",
            "f1: 100.0\n",
            "question + passage: ['what sport?', 'GERALD Christian is in Grade 8 at Ridge Road Middle School in North Carolina, US. She is a member of her school basketball team. Late last month, the 14-year-old faced a big problem. Her mother lost her job. She thought she couldn\\'t pay the $ 50 fee for the city\\'s sports meet this year. Christian was not the only one who had this problem. Some other middle school players in the city had the same problem. That\\'s why famous NBA player Michael Jordan gave $ 250, 000 to the city earlier this month. He wanted to help the poor students. Jordan said: \"I know there are kids who get an education by playing sports. We need to keep sports alive for them.\" Christian was _ . \"Really? I can\\'t believe Michael did that for us. These days, I go to bed thinking about it and I wake up thinking about it,\" she said. \"Now the problem is over. \" Christian wanted to say \"thanks\" to Jordan. \"Michael, thank you for giving me the chance to show myself. I will do my best at the meet.[SEP]does Gerald play any sports?[SEP]yes[SEP]what state?[SEP]North Carolina[SEP]what is the name of the school he goes to?[SEP]Ridge Road Middle School[SEP]what grade is he in?[SEP]Grade 8[SEP]did he think about it all the time?[SEP]yes[SEP]Was Christian surprised by this?[SEP]yes[SEP]why did michael jordan donate $250,000?[SEP]He wanted to help the poor students']\n",
            "true answer: ['basketball']\n",
            "answer with seed 42: basketball \n",
            "answer with seed 1337: basketball \n",
            "answer with seed 2022: basketball \n",
            "f1: 100.0\n",
            "question + passage: ['what is this language called?', 'My summer hols wr CWOT. B4, we usd 2 go 2 NY 2C my bro, his GF & thr3:-@ kids FTF. ILNY, it\\'s gr8. Can you understand this sentence? If you can\\'t, don\\'t feel too bad; neither could the middle school teacher in England who received this as homework. This is Netspeak: the language of computerized communication found on Internet or cell phones. To new comers, it can look like a completely foreign language. So, what is the translation of the sentence above? My summer holidays were a complete waste of time. Before, we used to go to New York to see my brother, his girlfriend, and their three screaming kids face to face. I love New York. It\\'s great. School teachers and parents say this new form of writing is harming the English language. Increasing spelling and grammatical mistakes can be seen in students\\' writing. They fear the language could become corrupted . \"Everyone should just relax\", say linguists . They believe Netspeak is in fact more of a good thing. David Crystal, from the University of Wales, argues that Netspeak and Internet create a new language use and the almost lost art of diary writing, has been picked up again. Geoffrey Nurberg, from Stanford University, agrees. \"People get better at writing by writing,\" he says. \"kids who are now doing text messaging, e-mails, and instant messages will write at least as well as, and possibly better than their parents.\" Linguist James says, for centuries, it is believed without exception that young people are harming the language. And you can _ that when today\\'s teenagers become tomorrow\\'s parents. They too will think this way. James argues that languages do not and cannot become corrupted. They simply change to meet the new needs. However, Netspeakers do agree that it is important to teach young people how to speak and write standard English. Cynthia McVey says, \"I can understand Netspeak worries teachers and it\\'s important that they get across to their pupils that text messaging is for fun, but learning to write proper English is a must for their future.\" Perhaps we should give teenagers a little more trust anyway. Erin, aged 12, says, \"I wouldn\\'t use text language in my homework. Texting is just for fun. \"[SEP]what does gf mean?[SEP]girlfriend[SEP]what does cwot mean?[SEP]complete waste of time[SEP]who has three children?[SEP]my brother[SEP]where does Geoffrey work?[SEP]Stanford University[SEP]what does he think netspeak creates?[SEP]A new language use[SEP]who is David Crystal?[SEP]Professor at the University of Wales']\n",
            "true answer: ['netspeak']\n",
            "answer with seed 42: netspeak \n",
            "answer with seed 1337: netspeak \n",
            "answer with seed 2022: netspeak \n",
            "f1: 100.0\n",
            "question + passage: ['What network affiliate is KABC?', 'Time was running out, and Mark Dickinson wasn\\'t sure whether he\\'d get to see his dying 2-year-old grandson one last time. A long line at Los Angeles International Airport\\'s security checkpoint had kept him from getting to his gate on time. \\n\\nHis grandson Caden would be taken off life support in a matter of hours in Denver, Colorado, with or without his grandfather\\'s presence, according to CNN affiliate KABC. \\n\\n\"I was kind of panicking because I was running late, and I really thought I wasn\\'t going to make the flight,\" Dickinson told KABC. \\n\\nThat\\'s when a pilot from Southwest Airlines stepped up and held the flight at the gate until Dickinson arrived. The pilot was standing by the air bridge waiting for him when Dickinson arrived in socks, so rushed that he just grabbed his shoes at security and ran through the terminal. \\n\\n\"I told him, \\'Thank you so much. I can\\'t tell you how much I appreciated that.\\' And he said, \\'No problem. They can\\'t leave without me anyway,\\'\"Dickinson told KABC. \\n\\nAuthorities say Dickinson\\'s grandson, Caden Rodgers, suffered a head injury after his mother\\'s boyfriend threw him across the room. The boyfriend reportedly told police he was drunk and high on marijuana at the time. The child later died and the boyfriend has been charged with first-degree murder, according to the Aurora Sentinel. \\n\\nThanks to the pilot, Dickinson made it to Colorado in time to say goodbye to his grandson. Most airlines would punish any staff member who holds up a flight, according to consumer advocate Christopher Elliott, who broke the story of the sympathetic pilot on his blog. However, a Southwest spokeswoman said the pilot\\'s actions were praiseworthy. \\n\\n\"You can\\'t hold a plane for every late customer, but I think we would all agree that these were extenuating circumstances and the pilot absolutely made the right decision,\" Southwest spokeswoman Marilee McInnis said. \"I don\\'t think you could ask for a better example of great service for our customers.\"[SEP]Why did he want to go to Denver?[SEP]see his dying 2-year-old grandson[SEP]Where was Mark flying from?[SEP]Los Angeles[SEP]How old was Caden?[SEP]Two[SEP]According to what publication?[SEP]Aurora Sentinel[SEP]What?[SEP]first-degree murder[SEP]Was he charged with anything?[SEP]yes[SEP]Did he admit it to the police?[SEP]yes[SEP]What drug was he high on?[SEP]marijuana[SEP]Was he doing the cocaine or the meth?[SEP]no[SEP]Was the boyfriend inebriated at the time?[SEP]yes[SEP]What did the dude do to the little boy?[SEP]he threw him[SEP]Who?[SEP]his mother\\'s boyfriend[SEP]Did someone hurt him?[SEP]yes[SEP]What type of injury did he suffer?[SEP]head injury[SEP]Who is Dickinson\\'s grandson?[SEP]Caden']\n",
            "true answer: ['cnn']\n",
            "answer with seed 42: cnn \n",
            "answer with seed 1337: cnn \n",
            "answer with seed 2022: cnn \n",
            "f1: 100.0\n",
            "-------------wikipedia-------------\n",
            "question + passage: ['True or False: Israel was unable to reopen the Straits.', 'The Six-Day War (Hebrew: , \"Milhemet Sheshet Ha Yamim\"; Arabic: , \"an-Naksah\", \"The Setback\" or , \"Ḥarb 1967\", \"War of 1967\"), also known as the June War, 1967 Arab–Israeli War, or Third Arab–Israeli War, was fought between June 5 and 10, 1967 by Israel and the neighboring states of Egypt (known at the time as the United Arab Republic), Jordan, and Syria. \\n\\nRelations between Israel and its neighbours had never fully normalised following the 1948 Arab–Israeli War. In 1956 Israel invaded the Egyptian Sinai, with one of its objectives being the reopening of the Straits of Tiran which Egypt had blocked to Israeli shipping since 1950. Israel was subsequently forced to withdraw, but won a guarantee that the Straits of Tiran would remain open. Whilst the United Nations Emergency Force was deployed along the border, there was no demilitarisation agreement. \\n\\nIn the period leading up to June 1967, tensions became dangerously heightened. Israel reiterated its post-1956 position that the closure of the straits of Tiran to its shipping would be a \"casus belli\" and in late May Nasser announced the straits would be closed to Israeli vessels. Egypt then mobilised its forces along its border with Israel, and on 5 June Israel launched what it claimed were a series of preemptive airstrikes against Egyptian airfields. Claims and counterclaims relating to this series of events are one of a number of controversies relating to the conflict.[SEP]When?[SEP]since 1950[SEP]What had been done to the Straits?[SEP]Egypt had blocked them to Israeli shipping[SEP]When did Isreal invade the Sinai?[SEP]1956[SEP]What is it called in Hebrew?[SEP]Milhemet Sheshet Ha Yamim[SEP]When was the Six-Day War fought?[SEP]June 5 and 10, 1967']\n",
            "true answer: ['false']\n",
            "answer with seed 42: false \n",
            "answer with seed 1337: false \n",
            "answer with seed 2022: false \n",
            "f1: 100.0\n",
            "question + passage: ['How many lineages are there?', 'Ordination is the process by which individuals are consecrated, that is, set apart as clergy to perform various religious rites and ceremonies. The process and ceremonies of ordination vary by religion and denomination. One who is in preparation for, or who is undergoing the process of ordination is sometimes called an ordinand. The liturgy used at an ordination is sometimes referred to as an ordination. \\n\\nThe tradition of the ordained monastic community (\"sangha\") began with the Buddha, who established orders of monks and later of nuns. The procedure of ordination in Buddhism is laid down in the Vinaya and Patimokkha or Pratimoksha scriptures. There exist three intact ordination lineages nowadays in which one can receive an ordination according to the Buddha\\'s teachings: \\n\\nSaicho repeatedly requested that the Japanese government allow the construction of a Mahayana ordination platform. Permission was granted in 822 CE, seven days after Saicho died. The platform was finished in 827 CE at Enryaku-ji temple on Mount Hiei, and was the first in Japan. Prior to this, those wishing to become monks/nuns were ordained using the Hinayana precepts, whereas after the Mahayana ordination platform, people were ordained with the Bodhisattva precepts as listed in the Brahma Net Sutra.[SEP]Where can you find the procedure outlinw?[SEP]Pratimoksha scriptures[SEP]What else is Buddha responsible for?[SEP]established orders of monks[SEP]Who did it begin with?[SEP]Buddha[SEP]What is the meaning of it?[SEP]process by which individuals are consecrated[SEP]What is the article about?[SEP]Ordination']\n",
            "true answer: ['three']\n",
            "answer with seed 42: three \n",
            "answer with seed 1337: three \n",
            "answer with seed 2022: three \n",
            "f1: 100.0\n",
            "question + passage: ['How many locations do not belong to any province?', 'Spain and its autonomous communities are divided into fifty provinces (, ; sing. \"provincia\"). Ceuta, Melilla and the Plazas de soberanía are not part of any provinces. \\n\\nThe layout of Spain\\'s provinces closely follows the pattern of the territorial division of the country carried out in 1833. The only major change of provincial borders since that time has been the sub-division of the Canary Islands into two provinces rather than one. \\n\\nHistorically, the provinces served mainly as transmission belts for policies enacted in Madrid, as Spain was a highly centralised state for most of its history. The importance of the provinces has declined since the adoption of the system of autonomous communities in the period of the Spanish transition to democracy. They nevertheless remain electoral districts for national elections and as geographical references: for instance in postal addresses and telephone codes. \\n\\nA small town would normally be identified as being in, say, Valladolid province rather than the autonomous community of Castile and León. The provinces were the \"building-blocks\" from which the autonomous communities were created. Consequently, no province is divided between more than one of these communities. \\n\\nMost of the provinces—with the exception of Álava/Araba, Asturias/Asturies, Bizkaia/Vizcaya, Cantabria, Gipuzkoa/Gipúzcoa, Illes Balears/Islas Baleares, La Rioja, and Nafarroa/Navarra—are named after their principal town. Only two capitals of autonomous communities—Mérida in Extremadura and Santiago de Compostela in Galicia—are not also the capitals of provinces.[SEP]What made the province more unimportant?[SEP]the adoption of the system of autonomous communities[SEP]Which are they?[SEP]Mérida and Santiago de Compostela[SEP]How many are not the provinces\\' capital?[SEP]Two[SEP]How many aren\\'t?[SEP]Eight[SEP]What are most provinces named after?[SEP]their principal town[SEP]and?[SEP]its autonomous communities[SEP]What location is divided into fifty provinces?[SEP]Spain[SEP]Where are they enacted?[SEP]in Madrid[SEP]What were provinces historically for?[SEP]transmission belts for policies enacted']\n",
            "true answer: ['three']\n",
            "answer with seed 42: three \n",
            "answer with seed 1337: three \n",
            "answer with seed 2022: three \n",
            "f1: 100.0\n",
            "question + passage: ['How many things are brighter?', \"Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a giant planet with a mass one-thousandth that of the Sun, but two and a half times that of all the other planets in the Solar System combined. Jupiter and Saturn are gas giants; the other two giant planets, Uranus and Neptune are ice giants. Jupiter has been known to astronomers since antiquity. The Romans named it after their god Jupiter. When viewed from Earth, Jupiter can reach an apparent magnitude of −2.94, bright enough for its reflected light to cast shadows, and making it on average the third-brightest object in the night sky after the Moon and Venus. \\n\\nJupiter is primarily composed of hydrogen with a quarter of its mass being helium, though helium comprises only about a tenth of the number of molecules. It may also have a rocky core of heavier elements, but like the other giant planets, Jupiter lacks a well-defined solid surface. Because of its rapid rotation, the planet's shape is that of an oblate spheroid (it has a slight but noticeable bulge around the equator). The outer atmosphere is visibly segregated into several bands at different latitudes, resulting in turbulence and storms along their interacting boundaries. A prominent result is the Great Red Spot, a giant storm that is known to have existed since at least the 17th century when it was first seen by telescope. Surrounding Jupiter is a faint planetary ring system and a powerful magnetosphere. Jupiter has at least 69 moons, including the four large Galilean moons discovered by Galileo Galilei in 1610. Ganymede, the largest of these, has a diameter greater than that of the planet Mercury.[SEP]Is it the most bright object at night?[SEP]no[SEP]How many planets is it away from the Sun?[SEP]it is the fifth planet from the Sun[SEP]Who gave it its name?[SEP]The Romans[SEP]How long have people known about it?[SEP]since antiquity[SEP]How much bigger is it than all the other planets together?[SEP]two and a half times[SEP]And what element?[SEP]hydrogen[SEP]What is it mostly made of?[SEP]gas[SEP]What is the largest planet in the solar system?[SEP]Jupiter\"]\n",
            "true answer: ['two']\n",
            "answer with seed 42: two \n",
            "answer with seed 1337: two \n",
            "answer with seed 2022: two \n",
            "f1: 100.0\n",
            "question + passage: ['what country is it in?', \"Mumbai (; also known as Bombay, the official name until 1995) is the capital city of the Indian state of Maharashtra. It is the most populous city in India with an estimated city population of 18.4\\xa0million. Along with the neighbouring regions of the Mumbai Metropolitan Region, it is second most populous metropolitan area in India, with a population of 21.3\\xa0million . Mumbai lies on the Konkan on the west coast of India and has a deep natural harbour. \\n\\nIn 2008, Mumbai was named an alpha world city. It is also the wealthiest city in India, Mumbai has the highest number of millionaires and billionaires among all cities in India. \\n\\nThe seven islands that came to constitute Mumbai were home to communities of fishing colonies of the Koli people. For centuries, the islands were under the control of successive indigenous empires before being ceded to the Portuguese Empire and subsequently to the East India Company when in 1661 Charles II of England married Catherine of Braganza and as part of her dowry Charles received the ports of Tangier and Seven Islands of Bombay. During the mid-18th century, Bombay was reshaped by the Hornby Vellard project, which undertook reclamation of the area between the seven islands from the sea. Along with construction of major roads and railways, the reclamation project, completed in 1845, transformed Bombay into a major seaport on the Arabian Sea. Bombay in the 19th century was characterised by economic and educational development. During the early 20th century it became a strong base for the Indian independence movement. Upon India's independence in 1947 the city was incorporated into Bombay State. In 1960, following the Samyukta Maharashtra Movement, a new state of Maharashtra was created with Bombay as the capital.[SEP]are they named in the article?[SEP]No[SEP]how many islands make up the city?[SEP]seven[SEP]is it land locked?[SEP]No[SEP]when did that change?[SEP]1995[SEP]is it still officially called that?[SEP]No[SEP]what?[SEP]Bombay[SEP]was it ever called something else?[SEP]Yes[SEP]is it poor city?[SEP]No[SEP]what happened in 2008?[SEP]Mumbai was named an alpha world city\"]\n",
            "true answer: ['india']\n",
            "answer with seed 42: india \n",
            "answer with seed 1337: india \n",
            "answer with seed 2022: india \n",
            "f1: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DISTILROBERTA NO HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_rob\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/robrob_\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "Y4FxyBRY8wAi"
      },
      "execution_count": null,
      "outputs": [],
      "id": "Y4FxyBRY8wAi"
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/robrob_\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "SUCp5EzY8wAo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "SUCp5EzY8wAo"
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/robrob_\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "t8_TsoNL8wAo"
      },
      "execution_count": null,
      "outputs": [],
      "id": "t8_TsoNL8wAo"
    },
    {
      "cell_type": "code",
      "source": [
        "# TINYBERT WITH HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_hist\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/tiny/histtiny_hist\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "16FwFlx79Jku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "16FwFlx79Jku"
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tiny/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "d4xmsKk79Jku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "d4xmsKk79Jku"
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/tiny/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "4m2oC28H9Jku"
      },
      "execution_count": null,
      "outputs": [],
      "id": "4m2oC28H9Jku"
    },
    {
      "cell_type": "code",
      "source": [
        "# TINYBERT WITH HISTORY\n",
        "test_ds = load_from_disk(\"/content/gdrive/MyDrive/ckpt/test_ds_hist\")\n",
        "source_dict = find_worst_errors(\"/content/gdrive/MyDrive/ckpt/dom/rob/histtiny_hist\", \"_testpred.pickle\", test_ds)"
      ],
      "metadata": {
        "id": "hRT7aauu_och"
      },
      "execution_count": null,
      "outputs": [],
      "id": "hRT7aauu_och"
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/rob/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test)"
      ],
      "metadata": {
        "id": "F80JZKNT_och"
      },
      "execution_count": null,
      "outputs": [],
      "id": "F80JZKNT_och"
    },
    {
      "cell_type": "code",
      "source": [
        "print_orderered_predictions(source_dict, \"/content/gdrive/MyDrive/ckpt/dom/rob/histtiny_hist\", \"_testpred.pickle\", test_ds, XQA_test, kind=\"best\")"
      ],
      "metadata": {
        "id": "XY9_ajeA_och"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XY9_ajeA_och"
    },
    {
      "cell_type": "markdown",
      "id": "f1814004",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a1b2b9",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0967c209",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23929660",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c56a612",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bac4b9",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0109beae5794bde9205e0472492247b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0c19cfae8ee413bbc609554c4f7b7fb",
              "IPY_MODEL_eb5f2221c2c34e178bf63eb951c8b364",
              "IPY_MODEL_c0a0a3ca88ee4e0a89ffc3d8764ab422"
            ],
            "layout": "IPY_MODEL_a2df50f8ec134d68bc9eedbf72a82d07"
          }
        },
        "e0c19cfae8ee413bbc609554c4f7b7fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16fd76e11a141eda802867957bbf1fd",
            "placeholder": "​",
            "style": "IPY_MODEL_85b6c27036574928b2fbe3ca46fbe70b",
            "value": "100%"
          }
        },
        "eb5f2221c2c34e178bf63eb951c8b364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eda94a2471f42a2a053c8056e733a51",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_923afc43e2df4769926aab1a6538a455",
            "value": 8
          }
        },
        "c0a0a3ca88ee4e0a89ffc3d8764ab422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87f9076e747a48909bde7e0e06df4ea6",
            "placeholder": "​",
            "style": "IPY_MODEL_fcbdbecd070045bb8ebb1ba74c74eeb9",
            "value": " 8/8 [00:09&lt;00:00,  1.35s/ba]"
          }
        },
        "a2df50f8ec134d68bc9eedbf72a82d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d16fd76e11a141eda802867957bbf1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b6c27036574928b2fbe3ca46fbe70b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eda94a2471f42a2a053c8056e733a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "923afc43e2df4769926aab1a6538a455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87f9076e747a48909bde7e0e06df4ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcbdbecd070045bb8ebb1ba74c74eeb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b78fe51459504e95a5ac26ba47d9a039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf54fcfd0cd247ffa81c36a13f10febb",
              "IPY_MODEL_434ea6be2d994423bb5bb02e008e4b6f",
              "IPY_MODEL_3c68ac9b84894bec974a218229655897"
            ],
            "layout": "IPY_MODEL_0c805526d5094699b17bd178bd3e929b"
          }
        },
        "bf54fcfd0cd247ffa81c36a13f10febb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64d0693afc64073bad450e686a3bf26",
            "placeholder": "​",
            "style": "IPY_MODEL_25e739df9b9d45b7aac69761722f01af",
            "value": "100%"
          }
        },
        "434ea6be2d994423bb5bb02e008e4b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_356c91e8155d4734a7a54cb84e4b520f",
            "max": 7918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8239b71822054c3285d9149edf198d29",
            "value": 7918
          }
        },
        "3c68ac9b84894bec974a218229655897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ebb85ea66174a26a362e814978dcff8",
            "placeholder": "​",
            "style": "IPY_MODEL_7c61fa7981ca432499623ef6ca9e89f3",
            "value": " 7918/7918 [00:00&lt;00:00, 9405.91ex/s]"
          }
        },
        "0c805526d5094699b17bd178bd3e929b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a64d0693afc64073bad450e686a3bf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e739df9b9d45b7aac69761722f01af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "356c91e8155d4734a7a54cb84e4b520f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8239b71822054c3285d9149edf198d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ebb85ea66174a26a362e814978dcff8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c61fa7981ca432499623ef6ca9e89f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "039c5405ee7644d5bdb7e7aa0daefa09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ff7d5d25a8a4fdbacb13849e475028b",
              "IPY_MODEL_aa68da4d34b94755a8fb2e6d3db79aba",
              "IPY_MODEL_c8b8aadea5624c70bf778d5392f54178"
            ],
            "layout": "IPY_MODEL_518416137aba4b8c809b263d3fe659be"
          }
        },
        "9ff7d5d25a8a4fdbacb13849e475028b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f48493b6464d8d9fbe34518325aee1",
            "placeholder": "​",
            "style": "IPY_MODEL_8a3dea3833bc4e23b2296901d9500f45",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "aa68da4d34b94755a8fb2e6d3db79aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342c3e64589a4e41a8ca34a14b9c678a",
            "max": 7918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36d912985df846d49a5e4f6407b05346",
            "value": 7918
          }
        },
        "c8b8aadea5624c70bf778d5392f54178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8db3efc9039246a3a424740e15c049eb",
            "placeholder": "​",
            "style": "IPY_MODEL_5cd50e430ca54ec9a01157eed41d214e",
            "value": " 7918/7918 [00:14&lt;00:00, 8215.74 examples/s]"
          }
        },
        "518416137aba4b8c809b263d3fe659be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "94f48493b6464d8d9fbe34518325aee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a3dea3833bc4e23b2296901d9500f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "342c3e64589a4e41a8ca34a14b9c678a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d912985df846d49a5e4f6407b05346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8db3efc9039246a3a424740e15c049eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd50e430ca54ec9a01157eed41d214e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0e3b2a8d8824eaa9ca8cb95891b4625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5ea6a57b72144518b9d5afda1b7b887",
              "IPY_MODEL_d78dde8d25c64ea59de06475608af78d",
              "IPY_MODEL_2b8e00b854494f0a84e561bc893f37d4"
            ],
            "layout": "IPY_MODEL_ed936169f3f142908e5bbc037f0af55b"
          }
        },
        "b5ea6a57b72144518b9d5afda1b7b887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a93ae2e19647fb8e1bd6449b7c369e",
            "placeholder": "​",
            "style": "IPY_MODEL_5deea0ee07e949f78968f5fa45acb5a9",
            "value": "Downloading: 100%"
          }
        },
        "d78dde8d25c64ea59de06475608af78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fe78769ed374587b5edf8be723c8c7e",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cbcfaf0864941a2989f1e7d71895cc7",
            "value": 480
          }
        },
        "2b8e00b854494f0a84e561bc893f37d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41487cdee2f845e1b9d53e6cf246cd60",
            "placeholder": "​",
            "style": "IPY_MODEL_1b9062f171b543d3b1eb67285d372447",
            "value": " 480/480 [00:00&lt;00:00, 32.8kB/s]"
          }
        },
        "ed936169f3f142908e5bbc037f0af55b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a93ae2e19647fb8e1bd6449b7c369e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5deea0ee07e949f78968f5fa45acb5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fe78769ed374587b5edf8be723c8c7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cbcfaf0864941a2989f1e7d71895cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41487cdee2f845e1b9d53e6cf246cd60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9062f171b543d3b1eb67285d372447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d6ac3123a1940f0a2aa415b3a129ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fddf583fac2442a9b1b3cd086ad150b8",
              "IPY_MODEL_f557d1af6d994d1488e1cc8cdbe7d3a0",
              "IPY_MODEL_8de04409b42b4d3c8d6e8054b8feed0a"
            ],
            "layout": "IPY_MODEL_09c27eda99d24c81886e8a1e397692bf"
          }
        },
        "fddf583fac2442a9b1b3cd086ad150b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8b20f290fcc4f2daf0e0b7216c5e2e3",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f4d2ba6c2048a4b536ce409133dffc",
            "value": "Downloading: 100%"
          }
        },
        "f557d1af6d994d1488e1cc8cdbe7d3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_674169832ad54da7bae5582bae68f71d",
            "max": 331070498,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_356548854c7148fe906475739fe65d31",
            "value": 331070498
          }
        },
        "8de04409b42b4d3c8d6e8054b8feed0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14e5d7adc73435389b7417639158082",
            "placeholder": "​",
            "style": "IPY_MODEL_c623f19900a54fe5ae15ab2317dac880",
            "value": " 331M/331M [00:10&lt;00:00, 58.5MB/s]"
          }
        },
        "09c27eda99d24c81886e8a1e397692bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8b20f290fcc4f2daf0e0b7216c5e2e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f4d2ba6c2048a4b536ce409133dffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "674169832ad54da7bae5582bae68f71d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "356548854c7148fe906475739fe65d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14e5d7adc73435389b7417639158082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c623f19900a54fe5ae15ab2317dac880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bd1337bc16e431a945d91419f08b570": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_624b7eaf24dd4ca9a2bab42e625e7b23",
              "IPY_MODEL_4435751b55fe46b58ea6a571a8a28a98",
              "IPY_MODEL_1c7578d1c0654a5882254ad544c82fd4"
            ],
            "layout": "IPY_MODEL_46edd2b91c1e43859975368e59d5e46e"
          }
        },
        "624b7eaf24dd4ca9a2bab42e625e7b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dfc7ad83e12402fb05843e5a2cfeb90",
            "placeholder": "​",
            "style": "IPY_MODEL_c1c5f9fe435842108e28673da86b74eb",
            "value": "100%"
          }
        },
        "4435751b55fe46b58ea6a571a8a28a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c6bd12ff95409b8c7ea10c2dec1b9c",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df3325bf87b24d9a9b87bb37df4900c9",
            "value": 86
          }
        },
        "1c7578d1c0654a5882254ad544c82fd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff90be31268849ac8f391fc1fbe2931e",
            "placeholder": "​",
            "style": "IPY_MODEL_f64c92fc7ab242b296df5df1ae565783",
            "value": " 86/86 [01:14&lt;00:00,  1.28ba/s]"
          }
        },
        "46edd2b91c1e43859975368e59d5e46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfc7ad83e12402fb05843e5a2cfeb90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c5f9fe435842108e28673da86b74eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17c6bd12ff95409b8c7ea10c2dec1b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3325bf87b24d9a9b87bb37df4900c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff90be31268849ac8f391fc1fbe2931e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64c92fc7ab242b296df5df1ae565783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a56b9400f24b4506b99112d9258f0bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f8a92a4e5c1406b94095b8ceff4ee99",
              "IPY_MODEL_281598e24b7147e3ab9733b3c953fed2",
              "IPY_MODEL_ed41b8d67962432b91dcb045bb7305af"
            ],
            "layout": "IPY_MODEL_5fff8d4f4d474502a44c8ea6ffd50086"
          }
        },
        "8f8a92a4e5c1406b94095b8ceff4ee99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e02079bb28434e12915633e51267047f",
            "placeholder": "​",
            "style": "IPY_MODEL_5d88f575dc0e47e4ab5323b66ff71ec2",
            "value": "100%"
          }
        },
        "281598e24b7147e3ab9733b3c953fed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f209fd6954994ab4948682cb90ac5cb0",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad18e03447114e8a857836cf711160b3",
            "value": 86
          }
        },
        "ed41b8d67962432b91dcb045bb7305af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077a694007d24b18a140281edeab976b",
            "placeholder": "​",
            "style": "IPY_MODEL_eadd5c9121b8460c998fc9a285c6506d",
            "value": " 86/86 [00:01&lt;00:00, 65.59ba/s]"
          }
        },
        "5fff8d4f4d474502a44c8ea6ffd50086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02079bb28434e12915633e51267047f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d88f575dc0e47e4ab5323b66ff71ec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f209fd6954994ab4948682cb90ac5cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad18e03447114e8a857836cf711160b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "077a694007d24b18a140281edeab976b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eadd5c9121b8460c998fc9a285c6506d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2405da8484eb4b8e8247688d0e02dc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6b936e7581e644e98ef84cb3b7a3d840",
              "IPY_MODEL_370deb64231a4ae1b42610bfa4665486",
              "IPY_MODEL_afa3624556434dd596378f577ac1037c"
            ],
            "layout": "IPY_MODEL_bf58fd99a15d4538a6e92768f9fa735c"
          }
        },
        "6b936e7581e644e98ef84cb3b7a3d840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27843725e3b84b81aa5d9e465bfdc320",
            "placeholder": "​",
            "style": "IPY_MODEL_c261e9123be046e1b04723cc097745be",
            "value": "100%"
          }
        },
        "370deb64231a4ae1b42610bfa4665486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0f7b209e8e344d1bc20f3881c9bfbed",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f5365ee933c4bc3b8a0febe0290a0e8",
            "value": 86
          }
        },
        "afa3624556434dd596378f577ac1037c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce44261845642ceb7f0dfdfe453621c",
            "placeholder": "​",
            "style": "IPY_MODEL_84d9854c7daf479da2f3322395866d17",
            "value": " 86/86 [00:01&lt;00:00, 77.34ba/s]"
          }
        },
        "bf58fd99a15d4538a6e92768f9fa735c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27843725e3b84b81aa5d9e465bfdc320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c261e9123be046e1b04723cc097745be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0f7b209e8e344d1bc20f3881c9bfbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f5365ee933c4bc3b8a0febe0290a0e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fce44261845642ceb7f0dfdfe453621c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d9854c7daf479da2f3322395866d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c76f5c7f4a4945a3893576388e4db546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37b78047e5e941609bfcdab4565d3e34",
              "IPY_MODEL_d84ca56e55714667a0dffc6296e9d3d2",
              "IPY_MODEL_10a43dbe50d4489d9e413da54a03d1bb"
            ],
            "layout": "IPY_MODEL_c49374eb6d044460950a0da7394bf7d1"
          }
        },
        "37b78047e5e941609bfcdab4565d3e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fbe610571e34f808c3c73a6102275ca",
            "placeholder": "​",
            "style": "IPY_MODEL_107c68c0a6ed4a1a8a68f3246342f9ff",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "d84ca56e55714667a0dffc6296e9d3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09af26594af34adab0e4253926553688",
            "max": 85807,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6d8bc02f4844ee9becd49046c8bed73",
            "value": 85807
          }
        },
        "10a43dbe50d4489d9e413da54a03d1bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3be9d52dde60465c94727836955d165d",
            "placeholder": "​",
            "style": "IPY_MODEL_38a1dfa473f847f696b94fa0ad0013e8",
            "value": " 85807/85807 [00:01&lt;00:00, 67898.00 examples/s]"
          }
        },
        "c49374eb6d044460950a0da7394bf7d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1fbe610571e34f808c3c73a6102275ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "107c68c0a6ed4a1a8a68f3246342f9ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09af26594af34adab0e4253926553688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d8bc02f4844ee9becd49046c8bed73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3be9d52dde60465c94727836955d165d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a1dfa473f847f696b94fa0ad0013e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "776e8997f6d4457896027e25435bd136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0413a3cc0ca449f3ba1872e618cd4a28",
              "IPY_MODEL_8a0ee58f67d048a3bc490a15b80bc22c",
              "IPY_MODEL_03822042f6a144fca4d30d7084c67647"
            ],
            "layout": "IPY_MODEL_8285759e2dee4a139135e288aa4c09be"
          }
        },
        "0413a3cc0ca449f3ba1872e618cd4a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2d835f8d4eb40bb857612fa0f76cdde",
            "placeholder": "​",
            "style": "IPY_MODEL_e97a9ef2f7cf4e41a873d403133ac667",
            "value": "100%"
          }
        },
        "8a0ee58f67d048a3bc490a15b80bc22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d95039cb424cbf8cb1eec98d7ebf8c",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a01b34f58c2427e9336d8e3b5d4e1e8",
            "value": 22
          }
        },
        "03822042f6a144fca4d30d7084c67647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_953f56d7c6004e07b4fe7327b7a7e8ad",
            "placeholder": "​",
            "style": "IPY_MODEL_61d0694679c74efcb3120210042d2853",
            "value": " 22/22 [00:18&lt;00:00,  1.35ba/s]"
          }
        },
        "8285759e2dee4a139135e288aa4c09be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2d835f8d4eb40bb857612fa0f76cdde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e97a9ef2f7cf4e41a873d403133ac667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39d95039cb424cbf8cb1eec98d7ebf8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a01b34f58c2427e9336d8e3b5d4e1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "953f56d7c6004e07b4fe7327b7a7e8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61d0694679c74efcb3120210042d2853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "813ffbd42adf47bd866881800b623977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec7d4998ece34a6896d7aa63f598366b",
              "IPY_MODEL_59226e51ddef4ac5805c6bb74711b543",
              "IPY_MODEL_a31bb6c9cdce436d9134de11ef4f62ab"
            ],
            "layout": "IPY_MODEL_a0c2e563ea9d466db751703148a884cd"
          }
        },
        "ec7d4998ece34a6896d7aa63f598366b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb3522cf30b44b784c7f6616d24e6f7",
            "placeholder": "​",
            "style": "IPY_MODEL_9824ecdc6bd3459ca32368349f0a03a5",
            "value": "100%"
          }
        },
        "59226e51ddef4ac5805c6bb74711b543": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f93cd99da4d47328b32eba2bf9282c7",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09b7b0d268a1448d991254eac5036f54",
            "value": 21479
          }
        },
        "a31bb6c9cdce436d9134de11ef4f62ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1aa7a38536049fda9a95f0b712fd563",
            "placeholder": "​",
            "style": "IPY_MODEL_07d9d018ad314f389196ead6241ac251",
            "value": " 21479/21479 [00:02&lt;00:00, 4845.35ex/s]"
          }
        },
        "a0c2e563ea9d466db751703148a884cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb3522cf30b44b784c7f6616d24e6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9824ecdc6bd3459ca32368349f0a03a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f93cd99da4d47328b32eba2bf9282c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b7b0d268a1448d991254eac5036f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1aa7a38536049fda9a95f0b712fd563": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d9d018ad314f389196ead6241ac251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ce5b1cabdf84977ad674347963410a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_273ca89a769240a8aa8106c9b5cec519",
              "IPY_MODEL_694c84af95fb4010974868438149cc60",
              "IPY_MODEL_0beba010f657448d8151148006e51cc3"
            ],
            "layout": "IPY_MODEL_2b7a739e9f4b488d884b1477ec1f344b"
          }
        },
        "273ca89a769240a8aa8106c9b5cec519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38f9382be394422b9d7147fa10ec8017",
            "placeholder": "​",
            "style": "IPY_MODEL_805706bcdc1d4dadb4a61bb08ed60f6b",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "694c84af95fb4010974868438149cc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_010f4a329db94ecdaabea6d3ecbc845f",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b97adc55f6a4177bacf9d9b56bdb4af",
            "value": 21479
          }
        },
        "0beba010f657448d8151148006e51cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cd64219b7ad40239d8dcfe1bb54385e",
            "placeholder": "​",
            "style": "IPY_MODEL_5be6678c69f5431991601de29e9f21dc",
            "value": " 21479/21479 [00:00&lt;00:00, 91079.78 examples/s]"
          }
        },
        "2b7a739e9f4b488d884b1477ec1f344b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "38f9382be394422b9d7147fa10ec8017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "805706bcdc1d4dadb4a61bb08ed60f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "010f4a329db94ecdaabea6d3ecbc845f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b97adc55f6a4177bacf9d9b56bdb4af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7cd64219b7ad40239d8dcfe1bb54385e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be6678c69f5431991601de29e9f21dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c92f70d51445aeba4a88634118cfa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a69a5df68484a8abcbe921738b05733",
              "IPY_MODEL_2d2005b4ae3b40f4b35f106b0fe2c821",
              "IPY_MODEL_cc6a8aac265f4718b8618eb92f9fb18c"
            ],
            "layout": "IPY_MODEL_4a95eda09682413f95c457f91780081a"
          }
        },
        "8a69a5df68484a8abcbe921738b05733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18e347a9cf0f449e899414cac02ead43",
            "placeholder": "​",
            "style": "IPY_MODEL_37e624ff8f244f6e8afe8b6bdf36b0bc",
            "value": "Downloading: 100%"
          }
        },
        "2d2005b4ae3b40f4b35f106b0fe2c821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e329caf173d4623a720f082a9acff29",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7bf3beff83b4f328686cc9b81e04dd9",
            "value": 480
          }
        },
        "cc6a8aac265f4718b8618eb92f9fb18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29cff18d2f1c43018b006a6bc71ac3e5",
            "placeholder": "​",
            "style": "IPY_MODEL_e8a693af87b246e39a002302aabfe739",
            "value": " 480/480 [00:00&lt;00:00, 21.7kB/s]"
          }
        },
        "4a95eda09682413f95c457f91780081a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18e347a9cf0f449e899414cac02ead43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37e624ff8f244f6e8afe8b6bdf36b0bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e329caf173d4623a720f082a9acff29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7bf3beff83b4f328686cc9b81e04dd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29cff18d2f1c43018b006a6bc71ac3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a693af87b246e39a002302aabfe739": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f51a016d264f1eb85071dc37b7b7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_351314f7e10346989a9a9eb8cd43c9f3",
              "IPY_MODEL_1464be09ed2f44d49fa6762c6c66b237",
              "IPY_MODEL_f8817ac5ab424f05bdbda261fa703603"
            ],
            "layout": "IPY_MODEL_bee5328ba2174cea9a192ed29c507765"
          }
        },
        "351314f7e10346989a9a9eb8cd43c9f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52f52b2538f84e84a5cbebb06ef3c57e",
            "placeholder": "​",
            "style": "IPY_MODEL_2d463d4fcc7c447ea37cb9a3b5d837ee",
            "value": "Downloading: 100%"
          }
        },
        "1464be09ed2f44d49fa6762c6c66b237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3766b037385b4957abc32ee4e382bc6d",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0bfbf9f713c49318a060502edbdeeff",
            "value": 898823
          }
        },
        "f8817ac5ab424f05bdbda261fa703603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d77d211ee309472c8b4a4f5f234bf5ac",
            "placeholder": "​",
            "style": "IPY_MODEL_39285a05bcf24321ad5411e04d45712d",
            "value": " 899k/899k [00:01&lt;00:00, 950kB/s]"
          }
        },
        "bee5328ba2174cea9a192ed29c507765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52f52b2538f84e84a5cbebb06ef3c57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d463d4fcc7c447ea37cb9a3b5d837ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3766b037385b4957abc32ee4e382bc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0bfbf9f713c49318a060502edbdeeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d77d211ee309472c8b4a4f5f234bf5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39285a05bcf24321ad5411e04d45712d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b09311a71804a1ca1aa458be4a206cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_106c6e88517c4a5c8cb56f91b1fb4cbe",
              "IPY_MODEL_cf837f5ef6be468aa28e80651d4597ed",
              "IPY_MODEL_9088e12eeb4a4608901d0fa52a1396b4"
            ],
            "layout": "IPY_MODEL_9f53190325894c028e7b8a4c69d35d17"
          }
        },
        "106c6e88517c4a5c8cb56f91b1fb4cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95173ed6eeba4f8fa4c921f9716ae8e8",
            "placeholder": "​",
            "style": "IPY_MODEL_8e27a4428b284a82831b5bc888052bc4",
            "value": "Downloading: 100%"
          }
        },
        "cf837f5ef6be468aa28e80651d4597ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6cbc67139ea46dc891e0392ea78de4c",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82fd6d341c094ad5ab182c063148d86e",
            "value": 456318
          }
        },
        "9088e12eeb4a4608901d0fa52a1396b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c7f96badcfd463ea7385ca3776ae3cd",
            "placeholder": "​",
            "style": "IPY_MODEL_4c94483778564b46ac06ee64c707f9c4",
            "value": " 456k/456k [00:01&lt;00:00, 528kB/s]"
          }
        },
        "9f53190325894c028e7b8a4c69d35d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95173ed6eeba4f8fa4c921f9716ae8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e27a4428b284a82831b5bc888052bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6cbc67139ea46dc891e0392ea78de4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82fd6d341c094ad5ab182c063148d86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c7f96badcfd463ea7385ca3776ae3cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c94483778564b46ac06ee64c707f9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd41687be904c3fb9a7ad0289c0e6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78bc5f6558294884847858240edc5d7b",
              "IPY_MODEL_b2018aef547146aabab70f0e90db9646",
              "IPY_MODEL_ddaf89e1320b44808d33f01f250f156e"
            ],
            "layout": "IPY_MODEL_4950ee1d976346269fb0c5ce4c9e372d"
          }
        },
        "78bc5f6558294884847858240edc5d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ea9fb3b2aee4fe783d02e53d7b1974a",
            "placeholder": "​",
            "style": "IPY_MODEL_5d8cd3d744b74828a793cd877b45d401",
            "value": "Downloading: 100%"
          }
        },
        "b2018aef547146aabab70f0e90db9646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf06a81affc47c49ea90cc942b10337",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cdac443da464807acec14c3e5b57035",
            "value": 1355863
          }
        },
        "ddaf89e1320b44808d33f01f250f156e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e06390ea463f4757bb6f90f8a170d6ca",
            "placeholder": "​",
            "style": "IPY_MODEL_1df3cf36c9a3457cae50d32cfc691c4a",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 1.10MB/s]"
          }
        },
        "4950ee1d976346269fb0c5ce4c9e372d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea9fb3b2aee4fe783d02e53d7b1974a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8cd3d744b74828a793cd877b45d401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eaf06a81affc47c49ea90cc942b10337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cdac443da464807acec14c3e5b57035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e06390ea463f4757bb6f90f8a170d6ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1df3cf36c9a3457cae50d32cfc691c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}