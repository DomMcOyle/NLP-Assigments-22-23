{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/NLP-Assigments-22-23/blob/Assignment-2/Assignment2DP(G)RobMeaningful.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d23b6c",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3f451b",
      "metadata": {
        "id": "bd3f451b"
      },
      "source": [
        "## Deadlines\n",
        "\n",
        "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
        "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
        "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ada8c8",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c07553",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4907f8d",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: a question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3760b5",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cfee64",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "## The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996fa650",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3e7d0",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb6c37e",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa786e2",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26d68b7",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c7558c",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01cdad7",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "8aUY2EWyoS0x",
        "outputId": "30dfb73b-9018-497a-abfc-6c6bcd12eb36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8aUY2EWyoS0x",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.13 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.26.13)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6643e14",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "358bac70",
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f6ab3ff",
      "metadata": {
        "id": "5f6ab3ff",
        "outputId": "8002c384-90ae-4ab0-adfd-954a6c657301",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CoQA train data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-train-v1.0.json: 49.0MB [00:08, 5.83MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n",
            "Downloading CoQA test data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-dev-v1.0.json: 9.09MB [00:03, 2.86MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e42311",
      "metadata": {
        "id": "40e42311"
      },
      "source": [
        "#### Data Inspection\n",
        "\n",
        "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from datasets import Dataset, load_from_disk\n",
        "import pickle\n",
        "import re\n",
        "from evaluate import load\n",
        "\n",
        "\n",
        "def set_seed(SEED):\n",
        "  random.seed(SEED) # if you're using random\n",
        "  np.random.seed(SEED) # if you're using numpy\n",
        "  torch.manual_seed(SEED) # torch.cuda.manual_seed_all(SEED) is not required\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  tf.random.set_seed(SEED) # setting the seed for tensorflow too\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "def extract_data(split_dataset):\n",
        "  \"\"\"\n",
        "  function extracting data from the list of dictionaries in the CoQA dataset\n",
        "  :params:\n",
        "    split_dataset: list of dictionaries from where to extract the pairs of question and passage and corresponding the answer\n",
        "  \"\"\"  \n",
        "  XQA = [] # list that will contain pairs (P,Q)\n",
        "  YQA = [] # list that will contain the Answers\n",
        "  for d in split_dataset: # scan each document\n",
        "    for i in range(len(d[\"questions\"])): # scan each question\n",
        "      if d[\"answers\"][i][\"span_end\"]!=-1: # discard unanswerable questions\n",
        "        single_example = [] # prepare the single example...\n",
        "        single_example.append(d[\"questions\"][i][\"input_text\"]) #... with the question ...\n",
        "        single_example.append(d[\"story\"]) # ...and the passage\n",
        "        XQA.append(single_example) # and append it\n",
        "        YQA.append(d[\"answers\"][i][\"input_text\"]) # add the answer\n",
        "  return XQA, YQA"
      ],
      "metadata": {
        "id": "h7_OLYpXkm56"
      },
      "id": "h7_OLYpXkm56",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f57334e0",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42 \n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "4Q6YfLkhyFXZ"
      },
      "id": "4Q6YfLkhyFXZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('coqa/train.json') as f:\n",
        "  # loading the training json\n",
        "  train_json = json.load(f)\n",
        "\n",
        "with open('coqa/test.json') as f:\n",
        "  # loading the test json\n",
        "  test_json = json.load(f)\n",
        "\n",
        "# splitting training data\n",
        "train_data, val_data = train_test_split(train_json[\"data\"],\n",
        "                                        train_size=0.8,\n",
        "                                        shuffle=True,\n",
        "                                        random_state=seed)\n",
        "# extracting X as list of pairs [Passage,Question] and Y as a list of strings (Answers) \n",
        "XQA_train, YQA_train = extract_data(train_data)\n",
        "XQA_val, YQA_val = extract_data(val_data)\n",
        "XQA_test, YQA_test = extract_data(test_json[\"data\"])\n",
        "del(train_json)\n",
        "del(test_json)\n",
        "\n",
        "print(\"First training example:\")\n",
        "print(XQA_train[0:17])\n",
        "print(YQA_train[0:17])\n",
        "print(\"First validation example:\")\n",
        "print(XQA_val[0])\n",
        "print(YQA_val[0])\n",
        "print(\"First test example:\")\n",
        "print(XQA_test[0])\n",
        "print(YQA_test[0])"
      ],
      "metadata": {
        "id": "0s8Ux69Fq1j-",
        "outputId": "b7aa4142-1909-4899-c2af-8e152b9e7071",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0s8Ux69Fq1j-",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First training example:\n",
            "[['Where is this taking place?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What is being voted on?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What day of the week did they vote?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['When was the last one held?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What else happened then?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Where are people voting?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What is something they turned into a place to vote?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Did anyone have to wait?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Who speaks about this?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Did Millicent have a sibling?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['What was his name?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is he still alive?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is she planning to get married?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['To who?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Do other people know about this?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is she having cold feet?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is Clarence an inconsiderate guy?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"]]\n",
            "['Tunisia', 'Representatives  are being chosen', 'Sunday', '1956', 'Country gained its independence', 'Menzah neighborhood', 'Schools', 'Yes', 'Cnn', 'yes', 'George', 'no', 'yes', 'Clarence', 'no', 'yes', 'no']\n",
            "First validation example:\n",
            "['Who was playing in the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "the team from Liverpool\n",
            "First test example:\n",
            "['What color was Cotton?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".']\n",
            "white\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## broken example fix:\n",
        "print(XQA_train[61])\n",
        "print(YQA_train[61])\n",
        "YQA_train[61] = 'October'\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mOxQbmUq0W",
        "outputId": "23d7f27d-781a-4b79-91ed-ecb984352078"
      },
      "id": "o4mOxQbmUq0W",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what month?', 'Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features. \\n\\nIn 1981, Microsoft hired Charles Simonyi, the primary developer of Bravo, the first GUI word processor, which was developed at Xerox PARC. Simonyi started work on a word processor called \"Multi-Tool Word\" and soon hired Richard Brodie, a former Xerox intern, who became the primary software engineer. \\n\\nMicrosoft announced Multi-Tool Word for Xenix and MS-DOS in 1983. Its name was soon simplified to \"Microsoft Word\". Free demonstration copies of the application were bundled with the November 1983 issue of \"PC World\", making it the first to be distributed on-disk with a magazine. That year Microsoft demonstrated Word running on Windows.']\n",
            "Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features.\n",
            "October\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230a21de",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xPPBaBkEa9N3",
        "outputId": "dc12a77f-cf3f-4a96-c4f5-c6d63b20b6d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xPPBaBkEa9N3",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS A SEPARATOR ##########################################################\n",
        "\n",
        "\"\"\"\n",
        "This was tested with:\n",
        "tensorflow==2.6\n",
        "tensorflow-gpu==2.6\n",
        "tensorflow-addons==0.16.1\n",
        "transformers==4.18.0\n",
        "Keras==2.6.0\n",
        "\n",
        "Note 1: Simple adaptation of tf_seq2seq_lstm.py script\n",
        "Note 2: make sure Keras and Tensorflow versions match!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "import time\n",
        "\n",
        "# check if training can be performed on GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included) \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                                reduction='none') # from logits means that it returns values after a \n",
        "                                                                                  # softmax application, thus it is useless to\n",
        "                                                                                  # add a softmax activation layer if this parameter is set to \n",
        "                                                                                  # true (or even dangerous because it squashes the values)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)            # here it is possible to tweak the learning rate\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask # pointwise product\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # NOTABENE: it is necessary to add token_type_ids to see how it performs\n",
        "            if self.encoder.use_token_type_ids:\n",
        "              encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask'],\n",
        "                                                                  'token_type_ids': inputs['token_type_ids']})\n",
        "            else:\n",
        "              encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask']})\n",
        "            decoder_input = inputs['y_padded'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['y_padded'][:, 1:]  # ignore <start>\n",
        "\n",
        "            # encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs[0][0],\n",
        "            #                                                    'attention_mask': inputs[0][1]})\n",
        "            # decoder_input = inputs[1][:, :-1]\n",
        "            # real_target = inputs[1][:, 1:]\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output) # setup in order to perform attention queries over the \n",
        "                                                           # embedding space\n",
        "\n",
        "            # decoder initialization, check build_initial_state for additional insights\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            # the input is then passed to the initialized decoder and we obtain predictions\n",
        "            # in rnn_output format because the model is BERT-emdedding-sequence-sequence, so the\n",
        "            # last layer is still a sequence of cells (a RNN)\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "            # we compute the losses over the computed predictions\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "        # gradients of the loss computed for this minibatch considering trainable\n",
        "        # parameters of encoder and decoder\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        # applies gradients to the trainable variables using Adam\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids, \n",
        "        })\n",
        "        if self.encoder.use_token_type_ids:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "        else:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        # samples the possible answer with greedy technique, we could possibly\n",
        "        # use a variant here such as beam search at inference time \n",
        "        # We could not do this at training time, since the Sampler used at training\n",
        "        # is not designed to project the token in an embedding space before computing\n",
        "        # the next one. The aforementioned embedding space\n",
        "        # is changing at each backpropagation step anyways, thus we stick with\n",
        "        # the computation of the argmax of the logits using TrainingSampler.\n",
        "        # NOTABENE: we can still change this sampler, find a way to penalize repetitions\n",
        "        # and perform the beam search\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler() \n",
        "        # we have a decoder for training and a decoder for test time, thus\n",
        "        # we need to re-define the training decoder each time we want to\n",
        "        # train a new batch\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # decoder_initial_state is still an output of the encoder, we pass it to\n",
        "        # the decoder_instance in order to get the outputs\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "    def beam_translate(self, results, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(results[0][:,0,:])\n",
        "\n",
        "    def beam_generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None, beam_width=3):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids, \n",
        "        })\n",
        "        if self.encoder.use_token_type_ids:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "        else:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "        \n",
        "        # From official documentation\n",
        "        # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "        # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "        # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "        # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "\n",
        "        encoder_output = tfa.seq2seq.tile_batch(encoder_output, multiplier=beam_width)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "        hidden_state = tfa.seq2seq.tile_batch([encoder_h, encoder_s], multiplier=beam_width)\n",
        "        decoder_initial_state = self.decoder.build_initial_state(beam_width*batch_size, hidden_state)\n",
        "\n",
        "        # Instantiate BeamSearchDecoder\n",
        "        decoder_instance = tfa.seq2seq.BeamSearchDecoder(self.decoder.wrapped_decoder_cell,\n",
        "                                                          beam_width=beam_width,\n",
        "                                                          output_layer=self.decoder.generation_dense,\n",
        "                                                          maximum_iterations=self.max_length)\n",
        "        decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "\n",
        "        # The BeamSearchDecoder object's call() function takes care of everything.\n",
        "        outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, \n",
        "                                                                  start_tokens=start_tokens,\n",
        "                                                                  end_token=end_token,\n",
        "                                                                  initial_state=decoder_initial_state)\n",
        "        # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
        "        # The final beam predictions are stored in outputs.predicted_id\n",
        "        # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
        "        # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
        "        # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
        "\n",
        "\n",
        "        # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "        # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "        # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
        "        final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
        "        beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
        "\n",
        "        return final_outputs.numpy(), beam_scores.numpy()\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True, trainable=False)\n",
        "        self.model.trainable=False\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "        self.reducer2 = tf.keras.layers.Dense(decoder_units)\n",
        "        self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size = 512)\n",
        "        self.use_token_type_ids = model_name=='prajjwal1/bert-tiny'\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        model_output = self.model(inputs)\n",
        "        \n",
        "        # all_outputs has shape (batch_size * 512 * 128)\n",
        "        all_outputs = model_output[0] # output of the last layer of the model\n",
        "        #pooled_output = model_output[1] # last layer but processed by a linear \n",
        "                                        # layer and a tanh\n",
        "        \n",
        "        # cls coding\n",
        "        hidden_pooled = all_outputs[:, 0, :]\n",
        "        cell_state = self.avg_pool(all_outputs)\n",
        "        cell_state = tf.reshape(cell_state, [all_outputs.shape[0], all_outputs.shape[2]])\n",
        "\n",
        "        # NOTABENE: it could be possible to add something to improve the encoding7\n",
        "        \n",
        "        # pooled output has shape (batch_size * 128)\n",
        "        hidden_state = self.reducer(hidden_pooled)\n",
        "        cell_state = self.reducer2(cell_state)\n",
        "        #return all_outputs, self.reducer(model_output[1]), self.reducer(model_output[1])\n",
        "        return all_outputs, hidden_state, cell_state\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        # NOTABENE: it is possible to change the embedding dimension and the number of LSTM cells\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        # NOTABENE: It could be possible to swap LSTMCell with GRUCell\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "        # NOTABENE: Just one type of attention, it could be changed to seek for different\n",
        "        # results\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units) # adds the attention mechanism after a single\n",
        "                                                                                # LSTM cell, because we pass a word at the time\n",
        "        # dense layer needed to generate the distribution values over \n",
        "        # the size of the vocabulary (probability for each word)\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        # Above we describe why this cannot be changed and why it resambles\n",
        "        # the greedysampler\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        # after initializing the tensors within the attention layer to 0 we add\n",
        "        # the designated initialization that allow us to query the embedding space,\n",
        "        # which is passed as encoder_state.\n",
        "        # We load the embedding of a single batch and we actually don't freeze \n",
        "        # the parameters related to BERT, that are modified and can possibly \n",
        "        # overfit. \n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state) \n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        # as shown in calls, inputs is a dictionary with entries: \n",
        "        # \"input_ids\" : _encoder_output_\n",
        "        # \"initial_state\" : _result_of_build_initial_state_\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n",
        "\n",
        "## MODEL NAME\n",
        "model_name = 'distilroberta-base'\n",
        "#model_name = 'prajjwal1/bert-tiny'\n",
        "# THIS IS A SEPARATOR ##########################################################"
      ],
      "metadata": {
        "id": "tgypImQXgQhh"
      },
      "id": "tgypImQXgQhh",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_string(x):\n",
        "  return re.sub('[!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n]',\"\",x)\n",
        "  \n",
        "# this tokenizer doen't filter anything, so a word and the concatenation of the\n",
        "# same word with a punctuation will have different embeddings\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<UNK>')#, analyzer = custom_analyzer) # here we use a custom analyzer\n",
        "output_tokenizer.fit_on_texts([\"<start> \" + i + \" <end>\" for i in YQA_train])\n",
        "\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_output_length = max([len(i) for i in YQA_train])\n",
        "print(\"Max input output found: \" + str(max([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)])))\n",
        "#max_sequence_length = max(512, max_output_length)\n",
        "print(\"99° percentile of training set answer length:\" + str(np.quantile([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)], 0.99)))\n",
        "# actual percentile is 17, given that each string has the beginnning and ending token\n",
        "max_sequence_length = 20\n",
        "\n",
        "\n",
        "print(np.argmax([len(i) for i in YQA_train]))\n",
        "print(XQA_train[7529])\n",
        "print(YQA_train[7529])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "bRzqq374GQOC",
        "outputId": "c6a35a67-3aee-4a0e-9a3f-9f7c677f55cb"
      },
      "id": "bRzqq374GQOC",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input output found: 83\n",
            "99° percentile of training set answer length:13.0\n",
            "7529\n",
            "[\"What symptoms of addiction does Orzack's center list?\", 'Caught in the Web A few months ago, it wasn\\'t unusual for 47-year-old Carla Toebe to spend 15 hours per day online. She\\'d wake up early, turn on her laptop and chat on Internet dating sites and instant-messaging programs - leaving her bed for only brief intervals. Her household bills piled up, along with the dishes and dirty laundry, but it took near-constant complaints from her four daughters before she realized she had a problem. \"I was starting to feel like my whole world was falling apart - kind of slipping into a depression,\" said Carla. \"I knew that if I didn\\'t get off the dating sites, I\\'d just keep going,\" detaching herself further from the outside world. Toebe\\'s conclusion: She felt like she was \"addicted\" to the Internet. She\\'s not alone. Concern about excessive Internet use isn\\'t new. As far back as 1995, articles in medical journals and the establishment of a Pennsylvania treatment center for overusers generated interest in the subject. There\\'s still no consensus on how much time online constitutes too much or whether addiction is possible. But as reliance on the Web grows, there are signs that the question is getting more serious attention: Last month, a study published in CNS Spectrums claimed to be the first large-scale look at excessive Internet use. The American Psychiatric Association may consider listing Internet addiction in the next edition of its diagnostic manual. And scores of online discussion boards have popped up on which people discuss negative experiences tied to too much time on the Web. \"There\\'s no question that there\\'re people who\\'re seriously in trouble because they\\'re overdoing their Internet involvement,\" said psychiatrist Ivan Goldberg. Goldberg calls the problem a disorder rather than a true addiction. Jonathan Bishop, a researcher in Wales specializing in online communities, is more skeptical. \"The Internet is an environment,\" he said. \"You can\\'t be addicted to the environment.\" Bishop describes the problem as simply a matter of priorities, which can be solved by encouraging people to prioritize other life goals and plans in place of time spent online. The new CNS Spectrums study was based on results of a nationwide telephone survey of more than 2,500 adults. Like the 2005 survey, this one was conducted by Stanford University researchers.About 6% of respondents reported that \"their relationships suffered because of excessive Internet use.\" About 9% attempted to conceal \"nonessential Internet use,\" and nearly 4% reported feeling \"preoccupied by the Internet when offline.\" About 8% said they used the Internet as a way to escape problems, and almost 14% reported they \"found it hard to stay away from the Internet for several days at a time.\" \"The Internet problem is still in its infancy,\" said Elias Aboujaoude, a Stanford professor. No single online activity is to blame for excessive use, he said. \"They\\'re online in chat rooms, checking e-mail, or writing blogs. not limited to porn or gambling\" websites. Excessive Internet use should be defined not by the number of hours spent online but \"in terms of losses,\" said Maressa Orzack, a Harvard University professor. \"If it\\'s a loss you\\'re not getting to work, and family relationships are breaking down as a result, then it\\'s too much.\" Since the early 1990s, several clinics have been established in the U. S. to treat heavy Internet users. They include the Center for Internet Addiction Recovery and the Center for Internet Behavior. The website for Orzack\\'s center lists the following among the psychological symptoms of computer addiction: * Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders, Orzack said. When she discusses Internet habits with her patients, they often report that being online offers a \"sense of belonging, and escape, excitement fun,\" she said. \"Some people say relief...because they find themselves so relaxed.\" Some parts of the Internet seem to draw people in more than others. Internet gamers spend countless hours competing in games against people from all over the world. One such game, called World of Warcraft, is cited on many sites by posters complaining of a \"gaming addiction.\" Andrew Heidrich, an education network administrator from Sacramento, plays World of Warcraft for about two to four hours every other night, but that\\'s nothing compared with the 40 to 60 hours a week he spent playing online games when he was in college. He cut back only after a full-scale family intervention , in which s told him he\\'d gained weight. \"There\\'s this whole culture of competition that sucks people in\" with online gaming, said Heidrich, now a father of two. \"People do it at the expense of everything that was a constant in their lives.\" Heidrich now visits websites that discuss gaming addiction regularly \"to remind myself to keep my love for online games in check.\" Toebe also regularly visits a site where posters discuss Internet overuse. In August, when she first realized she had a problem, she posted a message on a Yahoo Internet addiction group with the subject line: \"I have an Internet Addiction.\" \"I\\'m self-employed and need the Internet for my work, but I\\'m failing to accomplish my work,to take care of my home, to give attention to my children,\" she wrote in a message sent to the group.\"I have no money or insurance to get professional help; I can\\'t even pay my mortgage and face losing everything.\" Since then, Toebe said, she has kept her promise to herself to cut back on her Internet use. \"I have a boyfriend now, and I\\'m not interested in online dating,\" she said by phone last week. \"It\\'s a lot better now.\"']\n",
            "Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dataset\n",
        "train_ds = Dataset.from_dict({\"xqa\": XQA_train, \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_train]})\n",
        "train_ds = train_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_token\": output_tokenizer.texts_to_sequences(x[\"yqa\"])}, batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_padded\": tf.keras.preprocessing.sequence.pad_sequences(x[\"y_token\"],\n",
        "                                                                     padding='post',\n",
        "                                                                     maxlen=max_sequence_length)}, batched=True\n",
        ")\n",
        "train_ds = train_ds.remove_columns([\"xqa\", \"yqa\", \"y_token\"])\n",
        "train_ds = train_ds.with_format(type=\"tensorflow\")\n",
        "if model_name == 'prajjwal1/bert-tiny':\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds\")\n",
        "else:\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds_rob\")"
      ],
      "metadata": {
        "id": "nErpyDpLhRV8"
      },
      "id": "nErpyDpLhRV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions are in lower case, so we consider the labels in lower case\n",
        "val_ds = Dataset.from_dict({\"xqa\": XQA_val, \"yqa\": [filter_string(i.lower()) for i in YQA_val], \"id_placeholder\": list(range(len(YQA_val)))})\n",
        "val_ds = val_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "val_ds = val_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "val_ds = val_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds\")\n",
        "else:\n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds_rob\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "79e56498c50b4fa29c45109d76ac8d64",
            "b3d218feaf24409ab2edb61c73163921",
            "c7c250141d264908a36a6f0fceb14eac",
            "c545aabad16f4065a11a17d2e54be241",
            "75111a970d7d40d7bfb8d59a7aab1f1b",
            "ec92b1f648c54a1db9dff0fefb04f539",
            "5161fa5586784bb4a0aae8c8f9bc38b7",
            "55b2c2981f6a446c8c69a34b664ad5b0",
            "8364eb00a35e45bd9ed37fe7dc84691e",
            "9922ec01bacb49b69bec57f1d4d3e53f",
            "4f3cfdae388443a790dbc09641a32f25",
            "b685e7a63f214a2683c998a4909ac42d",
            "0a5696e29b9741f7ad96bd1c54e793e8",
            "95c56243b1884e2d9f41a13fd12ca240",
            "30f78e534dce4d0fafffb9dd3898cd63",
            "62f1aa6069e54b3dbd62ee71791685a7",
            "8e88f0d0939341108018a2e3ac6f14b9",
            "4b756f72f0ad4328801da86f0be5fb17",
            "bc5bf595aa3d4feaa753dd918b5b183f",
            "ab245fb96472490c8902b3257cbb54ec",
            "ff19bde574314b169e7a766a55ddaede",
            "6c534d7a3ffa4e7dbcf968aa93fef5dd",
            "fa148be17340419aad767c033d2cfdf3",
            "4722ccaecdc84fdfb54ed6a9bcacc5c1",
            "b35412242af84ef29c0d03f2f63ccdc9",
            "2c899b486a624bca829a481124e138f5",
            "0394f0d7aa2647ad806f64ad9b0823e3",
            "55ac2d5ef1f848f984eb5ec7777073ed",
            "d1020c9de2174aa1b18a5c9da4668baf",
            "72fa9874e6cf43b7842e46acf2833505",
            "477ed81af1bd4c55ab71c4c5a1e0e09e",
            "045dd1d214a24659add10aa061052e00",
            "fdfc3b263190421ebfc6b649d5e4bba8"
          ]
        },
        "id": "b9VyzKdnAuKz",
        "outputId": "9bc241b1-6930-4b09-9326-72ba037a85a1"
      },
      "id": "b9VyzKdnAuKz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79e56498c50b4fa29c45109d76ac8d64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/21479 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b685e7a63f214a2683c998a4909ac42d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/21479 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa148be17340419aad767c033d2cfdf3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions are in lower case, so we consider the labels in lower case\n",
        "test_ds = Dataset.from_dict({\"xqa\": XQA_test, \"yqa\": [filter_string(i.lower()) for i in YQA_test], \"id_placeholder\": list(range(len(YQA_test)))})\n",
        "test_ds = test_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "test_ds = test_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "test_ds = test_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds\")\n",
        "else:\n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds_rob\")"
      ],
      "metadata": {
        "id": "83_mH8gTRY5z",
        "outputId": "509b4f12-9a7a-4b09-ec3c-850673648d75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "13e998d19ca24b21b8e4b44c8aea402b",
            "e2c8711ef5a545f28ebe965f133f9eb8",
            "cea36772bdbd46778646c59bbd241ce1",
            "30842d100e5b4c7f9f5d42bba3c91c1f",
            "7fd3f0d255cf41b5b20535599a265834",
            "10bda7aff4d74da28daa4e8d5b9b04ed",
            "e498b49a1452430183903deb3a0d85b7",
            "4e9162d13918483ab81e71a186449285",
            "e750ae84b7424ad9965dd6189026d60c",
            "7f5ae88aaaca40cb87c3291cc8423b91",
            "7a283f8de4f045cab05d4b52f016e5a9",
            "f24dea57d52d43c380fe48dc58533813",
            "94f4478d453a4d439ec274d588cafcc6",
            "432977a4916b433aaeadec78199692ee",
            "582120de0e8c48aeb65cf09610dcdf61",
            "7cd1c58b17b8450797aba2a6d726a891",
            "0f7e627e6a9a4df38bf38b4d96644e51",
            "d9a30bc48ad34732bbfcf7abaa632b6f",
            "bb730ea387f44b3f936eb859042da750",
            "65732d03efb841c2a1c9d32898896119",
            "0f6b1734641a4ee9aad046fee249dfd0",
            "2764a0c3cf614be38e04dd31978ceb76",
            "b9f1a45651ea48df8e7d4577682a2549",
            "3df78bbedfd04106adb3ca3b4407e1f3",
            "2d561ddd003b4b22b1a5498b382cdcca",
            "7460c85724fe426ab969d3e099234a62",
            "d857ea98afb2410a8c8e51242a572454",
            "19fe3d5f477d414889edf0765cb52038",
            "b0284ad8f5914a5a824e04bd83ef15b9",
            "fe8d424228494ccd8a320ba1d1eca69d",
            "f964ce4647bd42d7b2c7e9ed2a3649bd",
            "3fccde1d913f47d584932a5a77ce083e",
            "2c2776bb18b9425b9e03b440a74f75e4"
          ]
        }
      },
      "id": "83_mH8gTRY5z",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/8 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13e998d19ca24b21b8e4b44c8aea402b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/7918 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f24dea57d52d43c380fe48dc58533813"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/7918 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f1a45651ea48df8e7d4577682a2549"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "max_sequence_length = 20\n",
        "if model_name == 'prajjwal1/bert-tiny':\n",
        "  train_ds = load_from_disk(\"gdrive/MyDrive/ckpt/train_ds\")\n",
        "  val_ds = load_from_disk(\"gdrive/MyDrive/ckpt/val_ds\")\n",
        "  test_ds = load_from_disk(\"gdrive/MyDrive/ckpt/test_ds\")\n",
        "else:\n",
        "  train_ds = load_from_disk(\"gdrive/MyDrive/ckpt/train_ds_rob\")\n",
        "  val_ds = load_from_disk(\"gdrive/MyDrive/ckpt/val_ds_rob\")\n",
        "  test_ds = load_from_disk(\"gdrive/MyDrive/ckpt/test_ds_rob\")"
      ],
      "metadata": {
        "id": "q5V3J1qzG3cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17733dbf-4ef0-454d-8e72-3dab824390a0"
      },
      "id": "q5V3J1qzG3cq",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(trainer, dataset, epochs, batch_size, checkpoint, checkpoint_prefix):\n",
        "  steps_per_epoch = len(dataset)//batch_size\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    batch_index = 0\n",
        "    cumulative_loss = 0\n",
        "\n",
        "    for batch_index in tqdm(range(steps_per_epoch), position=0, leave=True):\n",
        "      loss = trainer.batch_fit(dataset[batch_index*batch_size:batch_index*batch_size+batch_size])\n",
        "      cumulative_loss += loss\n",
        "\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "    mean_loss = cumulative_loss / batch_index\n",
        "    print(f\"Current mean {mean_loss}\")\n",
        "\n",
        "\n",
        "def predict_loop(trainer, dataset, inference_batch_size,model_name,output_tokenizer, beam_search=False):\n",
        "  ttids=None\n",
        "  if beam_search:\n",
        "    generation_func = trainer.beam_generate\n",
        "    translation_func = trainer.beam_translate\n",
        "  else:\n",
        "    generation_func = trainer.generate\n",
        "    translation_func = trainer.translate\n",
        "  \n",
        "  inference_step = len(dataset) // inference_batch_size\n",
        "  predictions = []\n",
        "  for step_index in tqdm(range(inference_step)):\n",
        "    starting_index = step_index*inference_batch_size\n",
        "    ending_index = step_index*inference_batch_size + inference_batch_size\n",
        "    if model_name == 'prajjwal1/bert-tiny':  \n",
        "      ttids = dataset[\"token_type_ids\"][starting_index : ending_index]\n",
        "    generated = generation_func(output_tokenizer=output_tokenizer, \n",
        "                                  input_ids=dataset[\"input_ids\"][starting_index : ending_index],\n",
        "                                  token_type_ids=ttids,\n",
        "                                  attention_mask=dataset[\"attention_mask\"][starting_index : ending_index])\n",
        "    translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "  # all this mess with indexes is needed in order to have coherent ids in the field \"id\"\n",
        "    list_to_add = [{'prediction_text': translated[i - starting_index].split(\"<end>\")[0], 'id':str(i)} for i in range(starting_index, ending_index)]\n",
        "    predictions.extend(list_to_add)\n",
        "  if model_name == 'prajjwal1/bert-tiny':  \n",
        "    ttids = dataset[\"token_type_ids\"][(inference_step)*inference_batch_size :]\n",
        "  \n",
        "  generated = generation_func(output_tokenizer = output_tokenizer, \n",
        "                             input_ids=dataset[\"input_ids\"][(inference_step)*inference_batch_size :],\n",
        "                             token_type_ids=ttids,\n",
        "                             attention_mask=dataset[\"attention_mask\"][(inference_step)*inference_batch_size :])\n",
        "  translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "\n",
        "  predictions.extend([{'prediction_text': translated[i - (inference_step)*inference_batch_size].split(\"<end>\")[0], \n",
        "                    'id':str(i)} for i in range((inference_step)*inference_batch_size, \n",
        "                                                len(dataset))])\n",
        "  return predictions\n",
        "  \n",
        "def save_prediction(prediction, filename):\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(prediction, f)"
      ],
      "metadata": {
        "id": "bIsHB5JGHGzE"
      },
      "id": "bIsHB5JGHGzE",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 14\n",
        "EPOCHS = 3\n",
        "INF_BS = 64\n",
        "squad_metric = load(\"squad\")\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "  decoder_units = 128\n",
        "else: \n",
        "  checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "  decoder_units = 512\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "print(checkpoint_prefix)"
      ],
      "metadata": {
        "id": "1yhop6aHPLr_",
        "outputId": "c84d4c83-51cb-4880-c841-0d7665d46715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "cc2f8d7ff21d4bb6865d370913caa3c9",
            "c2dafb7889d74944a21b6597f0ef3a90",
            "3eaf0b050f064461a875826c45abb446",
            "12bdb3a67e9a4e738abcced853bbf6e2",
            "11ca014ff73b4362a66102892aab69fb",
            "f82b8f91a8f74e879d67437665af6038",
            "5c12546b4fb44d2299292195b219abc7",
            "fcb08e940f4e4c319bb745c29ff62df8",
            "7631fdd1db3c47698968771f9e99fcda",
            "a11877a1910c4c2ea683d2200833fd11",
            "4ac758f3ee1b4affbbcfe17376a912de",
            "42b1f0dd36444c30bc92e8d896e52da5",
            "e39e7686555e4a39afabff1168ddeb69",
            "0e4c03ed739d4dcd9584d3b0acf76ddf",
            "4c53288d0b9542b1aa048c3aa9d2971f",
            "f04b6f787f32480cba1d2a4e82037584",
            "c8e0b2587c21488c911455d457a86866",
            "89afd73dd4104b95a9d7ee5b313f04d9",
            "bfd7c1d48cd343b6b081878e95786ec0",
            "cd1ee5bea9dc4ba39f2cde2a9ea9abbb",
            "69e3e79e02d54d8eabc07f81e1e28632",
            "5cbb879682b14d03a4c7f9d05d5e3f47"
          ]
        }
      },
      "id": "1yhop6aHPLr_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc2f8d7ff21d4bb6865d370913caa3c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading extra modules:   0%|          | 0.00/3.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42b1f0dd36444c30bc92e8d896e52da5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./gdrive/MyDrive/ckpt/dom/tiny/ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "results_beam = []\n",
        "for train_seed in [42,1337,2022]:\n",
        "  set_seed(train_seed)\n",
        "\n",
        "  encoder = Encoder(model_name=model_name,\n",
        "                        decoder_units=decoder_units)\n",
        "    \n",
        "  # Testing the decoder\n",
        "  decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                        embedding_dim=100,\n",
        "                        decoder_units=decoder_units,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        max_sequence_length=max_sequence_length)\n",
        "  # Training\n",
        "  trainer = MyTrainer(encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        max_length=max_sequence_length)\n",
        "  \n",
        "  checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "  \n",
        "  train_loop(trainer, train_ds, EPOCHS, BATCH_SIZE, checkpoint, checkpoint_prefix + str(train_seed))\n",
        "\n",
        "  prediction = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer)\n",
        "  save_prediction(prediction, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_pred.pickle\")\n",
        "\n",
        "  prediction_beam = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer, beam_search=True)\n",
        "  save_prediction(prediction_beam, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_beampred.pickle\")\n",
        "\n",
        "  results.append(squad_metric.compute(predictions=prediction, references=val_ds['references']))\n",
        "  results_beam.append(squad_metric.compute(predictions=prediction_beam, references=val_ds['references']))\n",
        "\n",
        "  del(checkpoint)\n",
        "  del(trainer)\n",
        "  del(encoder)\n",
        "  del(decoder) \n",
        "\n",
        "print(\"***VALIDATION RESULTS***\")\n",
        "print(results)\n",
        "print(results_beam)\n",
        "print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQK8ldAw9SIs",
        "outputId": "1e19d44f-19b6-49f7-d2bc-d6632eebc708"
      },
      "id": "PQK8ldAw9SIs",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n",
            " 33%|███▎      | 1/3 [00:05<00:10,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
            " 67%|██████▋   | 2/3 [00:05<00:02,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  6.30it/s]\n",
            "100%|██████████| 3/3 [00:05<00:00,  1.92s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [01:46<00:00,  3.14it/s]\n",
            "  0%|          | 0/335 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/resource_loader.py:78: UserWarning: You are currently using TensorFlow 2.9.2 and trying to load a custom op (custom_ops/seq2seq/_beam_search_ops.so).\n",
            "TensorFlow Addons has compiled its custom ops against TensorFlow 2.11.0, and there are no compatibility guarantees between the two versions. \n",
            "This means that you might get segfaults when loading the custom op, or other kind of low-level errors.\n",
            " If you do, do not file an issue on Github. This is a known limitation.\n",
            "\n",
            "It might help you to fallback to pure Python ops by setting environment variable `TF_ADDONS_PY_OPS=1` or using `tfa.options.disable_custom_kernel()` in your code. To do that, see https://github.com/tensorflow/addons#gpucpu-custom-ops \n",
            "\n",
            "You can also change the TensorFlow version installed on your system. You would need a TensorFlow version equal to or above 2.11.0 and strictly below 2.12.0.\n",
            " Note that nightly versions of TensorFlow, as well as non-pip TensorFlow like `conda install tensorflow` or compiled from source are not supported.\n",
            "\n",
            "The last solution is to find the TensorFlow Addons version that has custom ops compatible with the TensorFlow installed on your system. To do that, refer to the readme: https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/options.py:45: RuntimeWarning: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_addons/seq2seq/beam_search_decoder.py\", line 239, in gather_tree\n",
            "    return _beam_search_so.ops.addons_gather_tree(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/resource_loader.py\", line 68, in ops\n",
            "    self._ops = tf.load_op_library(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/load_library.py\", line 54, in load_op_library\n",
            "    lib_handle = py_tf.TF_LoadLibrary(library_filename)\n",
            "tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow_addons/custom_ops/seq2seq/_beam_search_ops.so: undefined symbol: _ZN3tsl7strings21FastInt32ToBufferLeftEiPc\n",
            "\n",
            "\n",
            "The gather_tree C++/CUDA custom op could not be loaded.\n",
            "For this reason, Addons will fallback to an implementation written\n",
            "in Python with public TensorFlow ops. There worst you might experience with\n",
            "this is a moderate slowdown on GPU. There can be multiple\n",
            "reason for this loading error, one of them may be an ABI incompatibility between\n",
            "the TensorFlow installed on your system and the TensorFlow used to compile\n",
            "TensorFlow Addons' custom ops. The stacktrace generated when loading the\n",
            "shared object file was displayed above.\n",
            "\n",
            "If you want this warning to disappear, either make sure the TensorFlow installed\n",
            "is compatible with this version of Addons, or tell TensorFlow Addons to\n",
            "prefer using Python implementations and not custom C++/CUDA ones. You can do that\n",
            "by setting the enviornment variable `TF_ADDONS_PY_OPS=1`:\n",
            "```bash\n",
            "TF_ADDONS_PY_OPS=1 python my_script.py\n",
            "```\n",
            "or run `tfa.options.disable_custom_kernel()` in your code, after your imports:\n",
            "```python\n",
            "import tensorflow_addons as tfa\n",
            "import ...\n",
            "import ...\n",
            "\n",
            "tfa.options.disable_custom_kernel()\n",
            "```\n",
            "\n",
            "  warnings.warn(warning_msg, RuntimeWarning)\n",
            "100%|██████████| 335/335 [02:04<00:00,  2.68it/s]\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 1/1 [00:05<00:00,  5.53s/it]\n",
            " 33%|███▎      | 1/3 [00:05<00:11,  5.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
            " 67%|██████▋   | 2/3 [00:05<00:02,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.21it/s]\n",
            "100%|██████████| 3/3 [00:05<00:00,  1.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [01:43<00:00,  3.24it/s]\n",
            "100%|██████████| 335/335 [02:15<00:00,  2.47it/s]\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
            "100%|██████████| 1/1 [00:03<00:00,  3.81s/it]\n",
            " 33%|███▎      | 1/3 [00:03<00:07,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.13it/s]\n",
            " 67%|██████▋   | 2/3 [00:03<00:01,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.73it/s]\n",
            "100%|██████████| 3/3 [00:04<00:00,  1.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 335/335 [01:53<00:00,  2.95it/s]\n",
            "100%|██████████| 335/335 [02:34<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***VALIDATION RESULTS***\n",
            "[{'exact_match': 0.004655710228595372, 'f1': 0.0}, {'exact_match': 0.004655710228595372, 'f1': 0.0}, {'exact_match': 3.6733553703617488, 'f1': 4.005414664896016}]\n",
            "[{'exact_match': 0.004655710228595372, 'f1': 0.0}, {'exact_match': 0.004655710228595372, 'f1': 0.0}, {'exact_match': 0.09776991480050282, 'f1': 0.1039553583899224}]\n",
            "greedy exact match:1.2275555969396466\n",
            "greedy SQUAD-F1:1.3351382216320051\n",
            "beam exact match:0.03569377841923119\n",
            "beam SQUAD-F1:0.03465178612997413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(model_name=model_name,\n",
        "                        decoder_units=decoder_units)\n",
        "    \n",
        "# Testing the decoder\n",
        "decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                        embedding_dim=100,\n",
        "                        decoder_units=decoder_units,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        max_sequence_length=max_sequence_length)\n",
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        max_length=max_sequence_length)\n",
        "  \n",
        "checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "  \n",
        "results = []\n",
        "results_beam = []\n",
        "for train_seed in [42,1337,2022]:\n",
        "\n",
        "  checkpoint.restore(checkpoint_prefix + str(train_seed)+\"-3\")\n",
        "\n",
        "  prediction = predict_loop(trainer, test_ds, INF_BS, model_name, output_tokenizer)\n",
        "  save_prediction(prediction, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_testpred.pickle\")\n",
        "\n",
        "  prediction_beam = predict_loop(trainer, test_ds, INF_BS, model_name ,output_tokenizer, beam_search=True)\n",
        "  save_prediction(prediction_beam, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_testbeampred.pickle\")\n",
        "\n",
        "  results.append(squad_metric.compute(predictions=prediction, references=test_ds['references']))\n",
        "  results_beam.append(squad_metric.compute(predictions=prediction_beam, references=test_ds['references']))\n",
        "\n",
        "print(\"***TEST RESULTS***\")\n",
        "print(results)\n",
        "print(results_beam)\n",
        "print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )"
      ],
      "metadata": {
        "id": "1oNmAxBvSVuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaf91c0-3e8a-499e-a2c4-1160b97264a0"
      },
      "id": "1oNmAxBvSVuH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f59090cd070>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = [{'prediction_text': translated[i - 128].split(\"<end>\")[0], 'id':str(i)} for i in range(128, 256)]\n",
        "print(type(prediction[0]))\n",
        "for i in prediction[0:10]:\n",
        "  print(i[\"prediction_text\"])\n",
        "  print(YQA_val[int(i[\"id\"])])\n",
        "  print(XQA_val[int(i[\"id\"])])"
      ],
      "metadata": {
        "id": "g_Q4mJbLSuPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cbcc40-7de2-47d5-ac01-d8fd5389f44d"
      },
      "id": "g_Q4mJbLSuPm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "4-2 \n",
            "the team from Liverpool\n",
            "['Who was playing in the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "real madrid \n",
            "Manchester City\n",
            "['who was playing against them?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "4-2 \n",
            "3-0\n",
            "['What was the score?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "sunday \n",
            "Monday\n",
            "['When was the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "the penalty penalty league \n",
            "Premier League\n",
            "['What league are they in?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "yes \n",
            "No\n",
            "['Is liverpool leading in the rankings?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "yes \n",
            "2 people scored\n",
            "['Were all the goals scored by different people?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "4-2 \n",
            "Andy Carroll\n",
            "['Who had the most goals?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "yes \n",
            "no\n",
            "['Had he scored for his team before?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "sunday \n",
            "34th minute\n",
            "['When did they double their score?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#help(squad_metric)\n",
        "print(len(predictions))\n",
        "print(len(XQA_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jO5_8be74NE",
        "outputId": "b4ada0c9-2162-487c-f0b9-5d899420cab2"
      },
      "id": "5jO5_8be74NE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21479\n",
            "21479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "squad_metric = load(\"squad\")\n",
        "references = val_ds['references']\n",
        "results = squad_metric.compute(predictions=predictions, references=references)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMscJ7FcSsxF",
        "outputId": "9438178d-bb68-49d0-f583-2b6b6ab9e308"
      },
      "id": "JMscJ7FcSsxF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 11.88137250337539, 'f1': 13.43617693014836}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e83f28",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7311ba86",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ac768c",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c7e98f",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1814004",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a1b2b9",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0967c209",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23929660",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c56a612",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bac4b9",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79e56498c50b4fa29c45109d76ac8d64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3d218feaf24409ab2edb61c73163921",
              "IPY_MODEL_c7c250141d264908a36a6f0fceb14eac",
              "IPY_MODEL_c545aabad16f4065a11a17d2e54be241"
            ],
            "layout": "IPY_MODEL_75111a970d7d40d7bfb8d59a7aab1f1b"
          }
        },
        "b3d218feaf24409ab2edb61c73163921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec92b1f648c54a1db9dff0fefb04f539",
            "placeholder": "​",
            "style": "IPY_MODEL_5161fa5586784bb4a0aae8c8f9bc38b7",
            "value": "100%"
          }
        },
        "c7c250141d264908a36a6f0fceb14eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b2c2981f6a446c8c69a34b664ad5b0",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8364eb00a35e45bd9ed37fe7dc84691e",
            "value": 22
          }
        },
        "c545aabad16f4065a11a17d2e54be241": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9922ec01bacb49b69bec57f1d4d3e53f",
            "placeholder": "​",
            "style": "IPY_MODEL_4f3cfdae388443a790dbc09641a32f25",
            "value": " 22/22 [00:15&lt;00:00,  1.73ba/s]"
          }
        },
        "75111a970d7d40d7bfb8d59a7aab1f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec92b1f648c54a1db9dff0fefb04f539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5161fa5586784bb4a0aae8c8f9bc38b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55b2c2981f6a446c8c69a34b664ad5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8364eb00a35e45bd9ed37fe7dc84691e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9922ec01bacb49b69bec57f1d4d3e53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f3cfdae388443a790dbc09641a32f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b685e7a63f214a2683c998a4909ac42d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a5696e29b9741f7ad96bd1c54e793e8",
              "IPY_MODEL_95c56243b1884e2d9f41a13fd12ca240",
              "IPY_MODEL_30f78e534dce4d0fafffb9dd3898cd63"
            ],
            "layout": "IPY_MODEL_62f1aa6069e54b3dbd62ee71791685a7"
          }
        },
        "0a5696e29b9741f7ad96bd1c54e793e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e88f0d0939341108018a2e3ac6f14b9",
            "placeholder": "​",
            "style": "IPY_MODEL_4b756f72f0ad4328801da86f0be5fb17",
            "value": "100%"
          }
        },
        "95c56243b1884e2d9f41a13fd12ca240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc5bf595aa3d4feaa753dd918b5b183f",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab245fb96472490c8902b3257cbb54ec",
            "value": 21479
          }
        },
        "30f78e534dce4d0fafffb9dd3898cd63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff19bde574314b169e7a766a55ddaede",
            "placeholder": "​",
            "style": "IPY_MODEL_6c534d7a3ffa4e7dbcf968aa93fef5dd",
            "value": " 21479/21479 [00:02&lt;00:00, 8803.18ex/s]"
          }
        },
        "62f1aa6069e54b3dbd62ee71791685a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e88f0d0939341108018a2e3ac6f14b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b756f72f0ad4328801da86f0be5fb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc5bf595aa3d4feaa753dd918b5b183f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab245fb96472490c8902b3257cbb54ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff19bde574314b169e7a766a55ddaede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c534d7a3ffa4e7dbcf968aa93fef5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa148be17340419aad767c033d2cfdf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4722ccaecdc84fdfb54ed6a9bcacc5c1",
              "IPY_MODEL_b35412242af84ef29c0d03f2f63ccdc9",
              "IPY_MODEL_2c899b486a624bca829a481124e138f5"
            ],
            "layout": "IPY_MODEL_0394f0d7aa2647ad806f64ad9b0823e3"
          }
        },
        "4722ccaecdc84fdfb54ed6a9bcacc5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ac2d5ef1f848f984eb5ec7777073ed",
            "placeholder": "​",
            "style": "IPY_MODEL_d1020c9de2174aa1b18a5c9da4668baf",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "b35412242af84ef29c0d03f2f63ccdc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72fa9874e6cf43b7842e46acf2833505",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_477ed81af1bd4c55ab71c4c5a1e0e09e",
            "value": 21479
          }
        },
        "2c899b486a624bca829a481124e138f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_045dd1d214a24659add10aa061052e00",
            "placeholder": "​",
            "style": "IPY_MODEL_fdfc3b263190421ebfc6b649d5e4bba8",
            "value": " 21479/21479 [00:00&lt;00:00, 89998.95 examples/s]"
          }
        },
        "0394f0d7aa2647ad806f64ad9b0823e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "55ac2d5ef1f848f984eb5ec7777073ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1020c9de2174aa1b18a5c9da4668baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72fa9874e6cf43b7842e46acf2833505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "477ed81af1bd4c55ab71c4c5a1e0e09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "045dd1d214a24659add10aa061052e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdfc3b263190421ebfc6b649d5e4bba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13e998d19ca24b21b8e4b44c8aea402b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2c8711ef5a545f28ebe965f133f9eb8",
              "IPY_MODEL_cea36772bdbd46778646c59bbd241ce1",
              "IPY_MODEL_30842d100e5b4c7f9f5d42bba3c91c1f"
            ],
            "layout": "IPY_MODEL_7fd3f0d255cf41b5b20535599a265834"
          }
        },
        "e2c8711ef5a545f28ebe965f133f9eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10bda7aff4d74da28daa4e8d5b9b04ed",
            "placeholder": "​",
            "style": "IPY_MODEL_e498b49a1452430183903deb3a0d85b7",
            "value": "100%"
          }
        },
        "cea36772bdbd46778646c59bbd241ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e9162d13918483ab81e71a186449285",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e750ae84b7424ad9965dd6189026d60c",
            "value": 8
          }
        },
        "30842d100e5b4c7f9f5d42bba3c91c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5ae88aaaca40cb87c3291cc8423b91",
            "placeholder": "​",
            "style": "IPY_MODEL_7a283f8de4f045cab05d4b52f016e5a9",
            "value": " 8/8 [00:05&lt;00:00,  1.44ba/s]"
          }
        },
        "7fd3f0d255cf41b5b20535599a265834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10bda7aff4d74da28daa4e8d5b9b04ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e498b49a1452430183903deb3a0d85b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e9162d13918483ab81e71a186449285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e750ae84b7424ad9965dd6189026d60c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f5ae88aaaca40cb87c3291cc8423b91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a283f8de4f045cab05d4b52f016e5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24dea57d52d43c380fe48dc58533813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94f4478d453a4d439ec274d588cafcc6",
              "IPY_MODEL_432977a4916b433aaeadec78199692ee",
              "IPY_MODEL_582120de0e8c48aeb65cf09610dcdf61"
            ],
            "layout": "IPY_MODEL_7cd1c58b17b8450797aba2a6d726a891"
          }
        },
        "94f4478d453a4d439ec274d588cafcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f7e627e6a9a4df38bf38b4d96644e51",
            "placeholder": "​",
            "style": "IPY_MODEL_d9a30bc48ad34732bbfcf7abaa632b6f",
            "value": "100%"
          }
        },
        "432977a4916b433aaeadec78199692ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb730ea387f44b3f936eb859042da750",
            "max": 7918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65732d03efb841c2a1c9d32898896119",
            "value": 7918
          }
        },
        "582120de0e8c48aeb65cf09610dcdf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f6b1734641a4ee9aad046fee249dfd0",
            "placeholder": "​",
            "style": "IPY_MODEL_2764a0c3cf614be38e04dd31978ceb76",
            "value": " 7918/7918 [00:00&lt;00:00, 9542.76ex/s]"
          }
        },
        "7cd1c58b17b8450797aba2a6d726a891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7e627e6a9a4df38bf38b4d96644e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a30bc48ad34732bbfcf7abaa632b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb730ea387f44b3f936eb859042da750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65732d03efb841c2a1c9d32898896119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f6b1734641a4ee9aad046fee249dfd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2764a0c3cf614be38e04dd31978ceb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f1a45651ea48df8e7d4577682a2549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3df78bbedfd04106adb3ca3b4407e1f3",
              "IPY_MODEL_2d561ddd003b4b22b1a5498b382cdcca",
              "IPY_MODEL_7460c85724fe426ab969d3e099234a62"
            ],
            "layout": "IPY_MODEL_d857ea98afb2410a8c8e51242a572454"
          }
        },
        "3df78bbedfd04106adb3ca3b4407e1f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19fe3d5f477d414889edf0765cb52038",
            "placeholder": "​",
            "style": "IPY_MODEL_b0284ad8f5914a5a824e04bd83ef15b9",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "2d561ddd003b4b22b1a5498b382cdcca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe8d424228494ccd8a320ba1d1eca69d",
            "max": 7918,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f964ce4647bd42d7b2c7e9ed2a3649bd",
            "value": 7918
          }
        },
        "7460c85724fe426ab969d3e099234a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fccde1d913f47d584932a5a77ce083e",
            "placeholder": "​",
            "style": "IPY_MODEL_2c2776bb18b9425b9e03b440a74f75e4",
            "value": " 7918/7918 [00:18&lt;00:00, 48780.62 examples/s]"
          }
        },
        "d857ea98afb2410a8c8e51242a572454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "19fe3d5f477d414889edf0765cb52038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0284ad8f5914a5a824e04bd83ef15b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe8d424228494ccd8a320ba1d1eca69d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f964ce4647bd42d7b2c7e9ed2a3649bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fccde1d913f47d584932a5a77ce083e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c2776bb18b9425b9e03b440a74f75e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2f8d7ff21d4bb6865d370913caa3c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2dafb7889d74944a21b6597f0ef3a90",
              "IPY_MODEL_3eaf0b050f064461a875826c45abb446",
              "IPY_MODEL_12bdb3a67e9a4e738abcced853bbf6e2"
            ],
            "layout": "IPY_MODEL_11ca014ff73b4362a66102892aab69fb"
          }
        },
        "c2dafb7889d74944a21b6597f0ef3a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f82b8f91a8f74e879d67437665af6038",
            "placeholder": "​",
            "style": "IPY_MODEL_5c12546b4fb44d2299292195b219abc7",
            "value": "Downloading builder script: 100%"
          }
        },
        "3eaf0b050f064461a875826c45abb446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcb08e940f4e4c319bb745c29ff62df8",
            "max": 4525,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7631fdd1db3c47698968771f9e99fcda",
            "value": 4525
          }
        },
        "12bdb3a67e9a4e738abcced853bbf6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a11877a1910c4c2ea683d2200833fd11",
            "placeholder": "​",
            "style": "IPY_MODEL_4ac758f3ee1b4affbbcfe17376a912de",
            "value": " 4.53k/4.53k [00:00&lt;00:00, 234kB/s]"
          }
        },
        "11ca014ff73b4362a66102892aab69fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f82b8f91a8f74e879d67437665af6038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c12546b4fb44d2299292195b219abc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcb08e940f4e4c319bb745c29ff62df8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7631fdd1db3c47698968771f9e99fcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a11877a1910c4c2ea683d2200833fd11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ac758f3ee1b4affbbcfe17376a912de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42b1f0dd36444c30bc92e8d896e52da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e39e7686555e4a39afabff1168ddeb69",
              "IPY_MODEL_0e4c03ed739d4dcd9584d3b0acf76ddf",
              "IPY_MODEL_4c53288d0b9542b1aa048c3aa9d2971f"
            ],
            "layout": "IPY_MODEL_f04b6f787f32480cba1d2a4e82037584"
          }
        },
        "e39e7686555e4a39afabff1168ddeb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e0b2587c21488c911455d457a86866",
            "placeholder": "​",
            "style": "IPY_MODEL_89afd73dd4104b95a9d7ee5b313f04d9",
            "value": "Downloading extra modules: 100%"
          }
        },
        "0e4c03ed739d4dcd9584d3b0acf76ddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfd7c1d48cd343b6b081878e95786ec0",
            "max": 3317,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd1ee5bea9dc4ba39f2cde2a9ea9abbb",
            "value": 3317
          }
        },
        "4c53288d0b9542b1aa048c3aa9d2971f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e3e79e02d54d8eabc07f81e1e28632",
            "placeholder": "​",
            "style": "IPY_MODEL_5cbb879682b14d03a4c7f9d05d5e3f47",
            "value": " 3.32k/3.32k [00:00&lt;00:00, 215kB/s]"
          }
        },
        "f04b6f787f32480cba1d2a4e82037584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e0b2587c21488c911455d457a86866": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89afd73dd4104b95a9d7ee5b313f04d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfd7c1d48cd343b6b081878e95786ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1ee5bea9dc4ba39f2cde2a9ea9abbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69e3e79e02d54d8eabc07f81e1e28632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cbb879682b14d03a4c7f9d05d5e3f47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}