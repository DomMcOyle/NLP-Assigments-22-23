{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/NLP-Assigments-22-23/blob/Assignment-2/Assignment2DP(G)R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1d23b6c",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3f451b",
      "metadata": {
        "id": "bd3f451b"
      },
      "source": [
        "## Deadlines\n",
        "\n",
        "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
        "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
        "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ada8c8",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c07553",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4907f8d",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: a question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3760b5",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cfee64",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "## The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996fa650",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3e7d0",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb6c37e",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa786e2",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26d68b7",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c7558c",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01cdad7",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "8aUY2EWyoS0x",
        "outputId": "d603150e-1cf8-4128-9700-e4f6ca8d6999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "8aUY2EWyoS0x",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 25.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 27.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 74.9 MB/s \n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: urllib3, xxhash, responses, multiprocess, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.7.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.25.11 xxhash-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.8.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.25.11)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6643e14",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "358bac70",
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5f6ab3ff",
      "metadata": {
        "id": "5f6ab3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf989c0-65db-4be0-d0b0-cda1f9195495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CoQA train data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-train-v1.0.json: 49.0MB [00:08, 5.59MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n",
            "Downloading CoQA test data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-dev-v1.0.json: 9.09MB [00:03, 2.88MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e42311",
      "metadata": {
        "id": "40e42311"
      },
      "source": [
        "#### Data Inspection\n",
        "\n",
        "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from datasets import Dataset, load_from_disk\n",
        "\n",
        "\n",
        "def set_seed(SEED):\n",
        "  random.seed(SEED) # if you're using random\n",
        "  np.random.seed(SEED) # if you're using numpy\n",
        "  torch.manual_seed(SEED) # torch.cuda.manual_seed_all(SEED) is not required\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  tf.random.set_seed(SEED) # setting the seed for tensorflow too\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "def extract_data(split_dataset):\n",
        "  \"\"\"\n",
        "  function extracting data from the list of dictionaries in the CoQA dataset\n",
        "  :params:\n",
        "    split_dataset: list of dictionaries from where to extract the pairs of question and passage and corresponding the answer\n",
        "  \"\"\"  \n",
        "  XQA = [] # list that will contain pairs (P,Q)\n",
        "  YQA = [] # list that will contain the Answers\n",
        "  for d in split_dataset: # scan each document\n",
        "    for i in range(len(d[\"questions\"])): # scan each question\n",
        "      if d[\"answers\"][i][\"span_end\"]!=-1: # discard unanswerable questions\n",
        "        single_example = [] # prepare the single example...\n",
        "        single_example.append(d[\"questions\"][i][\"input_text\"]) #... with the question ...\n",
        "        single_example.append(d[\"story\"]) # ...and the passage\n",
        "        XQA.append(single_example) # and append it\n",
        "        YQA.append(d[\"answers\"][i][\"input_text\"]) # add the answer\n",
        "  return XQA, YQA"
      ],
      "metadata": {
        "id": "h7_OLYpXkm56"
      },
      "id": "h7_OLYpXkm56",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f57334e0",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42 \n",
        "set_seed(seed)\n",
        "\n",
        "with open('coqa/train.json') as f:\n",
        "  # loading the training json\n",
        "  train_json = json.load(f)\n",
        "\n",
        "with open('coqa/test.json') as f:\n",
        "  # loading the test json\n",
        "  test_json = json.load(f)\n",
        "\n",
        "# splitting training data\n",
        "train_data, val_data = train_test_split(train_json[\"data\"],\n",
        "                                        train_size=0.8,\n",
        "                                        shuffle=True,\n",
        "                                        random_state=seed)\n",
        "# extracting X as list of pairs [Passage,Question] and Y as a list of strings (Answers) \n",
        "XQA_train, YQA_train = extract_data(train_data)\n",
        "XQA_val, YQA_val = extract_data(val_data)\n",
        "XQA_test, YQA_test = extract_data(test_json[\"data\"])\n",
        "del(train_json)\n",
        "del(test_json)\n",
        "\n",
        "print(\"First training example:\")\n",
        "print(XQA_train[0:17])\n",
        "print(YQA_train[0:17])\n",
        "print(\"First validation example:\")\n",
        "print(XQA_val[0])\n",
        "print(YQA_val[0])\n",
        "print(\"First test example:\")\n",
        "print(XQA_test[0])\n",
        "print(YQA_test[0])"
      ],
      "metadata": {
        "id": "0s8Ux69Fq1j-",
        "outputId": "ac25c2f2-3e7d-4ae2-eeb7-56e03ea13b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0s8Ux69Fq1j-",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First training example:\n",
            "[['Where is this taking place?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What is being voted on?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What day of the week did they vote?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['When was the last one held?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What else happened then?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Where are people voting?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['What is something they turned into a place to vote?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Did anyone have to wait?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Who speaks about this?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. '], ['Did Millicent have a sibling?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['What was his name?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is he still alive?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is she planning to get married?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['To who?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Do other people know about this?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is she having cold feet?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"], ['Is Clarence an inconsiderate guy?', \"CHAPTER XXIX \\n\\nA BOLD SCHEME \\n\\nThe sense of security which Millicent experienced on announcing her engagement was not permanent and in a few days the doubts that had troubled her crept back into her mind. She had never entertained any marked illusions about Clarence and although, now that she was irrevocably pledged to him, she endeavored to fix her thoughts on his most likable qualities, even these appeared in a less favorable light than they had formerly done. The growth of the warmer attachment she had expected to feel was strangely slow, and though it was early to indulge in regrets her heart sometimes grew heavy as she looked forward to the future. Clarence was considerate, attentive and deferential in a polished way, but he lacked something one looked for in a lover. Besides, she was anxious about him; he looked worn, his manner suggested that he was bearing a strain, but this was in his favor, for it roused her compassion. She fancied that the cause of it was financial, and this in a sense was encouraging, because this was a trouble from which she could purchase him immunity. \\n\\nIn the meanwhile she was stirred by mournful memories as she followed the last stages of her brother's journey and visited the lonely spot where he had met his end. Somehow the thought of him encouraged her--George had quietly done his duty, regardless of the cost, and even if her burden proved heavy, which it was premature to admit, she must bear it cheerfully. \"]]\n",
            "['Tunisia', 'Representatives  are being chosen', 'Sunday', '1956', 'Country gained its independence', 'Menzah neighborhood', 'Schools', 'Yes', 'Cnn', 'yes', 'George', 'no', 'yes', 'Clarence', 'no', 'yes', 'no']\n",
            "First validation example:\n",
            "['Who was playing in the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "the team from Liverpool\n",
            "First test example:\n",
            "['What color was Cotton?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".']\n",
            "white\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## broken example fix:\n",
        "print(XQA_train[61])\n",
        "print(YQA_train[61])\n",
        "YQA_train[61] = 'October'\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mOxQbmUq0W",
        "outputId": "e9e4620a-5251-467c-ee07-f339157adc41"
      },
      "id": "o4mOxQbmUq0W",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what month?', 'Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features. \\n\\nIn 1981, Microsoft hired Charles Simonyi, the primary developer of Bravo, the first GUI word processor, which was developed at Xerox PARC. Simonyi started work on a word processor called \"Multi-Tool Word\" and soon hired Richard Brodie, a former Xerox intern, who became the primary software engineer. \\n\\nMicrosoft announced Multi-Tool Word for Xenix and MS-DOS in 1983. Its name was soon simplified to \"Microsoft Word\". Free demonstration copies of the application were bundled with the November 1983 issue of \"PC World\", making it the first to be distributed on-disk with a magazine. That year Microsoft demonstrated Word running on Windows.']\n",
            "Microsoft Word is a word processor developed by Microsoft. It was first released on October 25, 1983 under the name \"Multi-Tool Word\" for Xenix systems. Subsequent versions were later written for several other platforms including IBM PCs running DOS (1983), Apple Macintosh running Classic Mac OS (1985), AT&T Unix PC (1985), Atari ST (1988), OS/2 (1989), Microsoft Windows (1989), SCO Unix (1994), and macOS (2001). Commercial versions of Word are licensed as a standalone product or as a component of Microsoft Office, Windows RT or the discontinued Microsoft Works suite. Microsoft Word Viewer and Office Online are freeware editions of Word with limited features.\n",
            "October\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230a21de",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xPPBaBkEa9N3",
        "outputId": "2d27e13d-7172-48b0-8313-6a0f07004660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "xPPBaBkEa9N3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS A SEPARATOR ##########################################################\n",
        "\n",
        "\"\"\"\n",
        "This was tested with:\n",
        "tensorflow==2.6\n",
        "tensorflow-gpu==2.6\n",
        "tensorflow-addons==0.16.1\n",
        "transformers==4.18.0\n",
        "Keras==2.6.0\n",
        "\n",
        "Note 1: Simple adaptation of tf_seq2seq_lstm.py script\n",
        "Note 2: make sure Keras and Tensorflow versions match!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "import time\n",
        "\n",
        "# check if training can be performed on GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included) \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                                reduction='none') # from logits means that it returns values after a \n",
        "                                                                                  # softmax application, thus it is useless to\n",
        "                                                                                  # add a softmax activation layer if this parameter is set to \n",
        "                                                                                  # true (or even dangerous because it squashes the values)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)            # here it is possible to tweak the learning rate\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask # pointwise product\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                'attention_mask': inputs['attention_mask']})\n",
        "            decoder_input = inputs['y_padded'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['y_padded'][:, 1:]  # ignore <start>\n",
        "\n",
        "            # encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs[0][0],\n",
        "            #                                                    'attention_mask': inputs[0][1]})\n",
        "            # decoder_input = inputs[1][:, :-1]\n",
        "            # real_target = inputs[1][:, 1:]\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output) # setup in order to perform attention queries over the \n",
        "                                                           # embedding space\n",
        "\n",
        "            # decoder initialization, check build_initial_state for additional insights\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            # the input is then passed to the initialized decoder and we obtain predictions\n",
        "            # in rnn_output format because the model is BERT-emdedding-sequence-sequence, so the\n",
        "            # last layer is still a sequence of cells (a RNN)\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "            # we compute the losses over the computed predictions\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "        # gradients of the loss computed for this minibatch considering trainable\n",
        "        # parameters of encoder and decoder\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        # applies gradients to the trainable variables using Adam\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, output_tokenizer, input_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask\n",
        "        })\n",
        "\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        # samples the possible answer with greedy technique, we could possibly\n",
        "        # use a variant here such as beam search at inference time \n",
        "        # We could not do this at training time, since the Sampler used at training\n",
        "        # is not designed to project the token in an embedding space before computing\n",
        "        # the next one. The aforementioned embedding space\n",
        "        # is changing at each backpropagation step anyways, thus we stick with\n",
        "        # the computation of the argmax of the logits using TrainingSampler.\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler() \n",
        "        # we have a decoder for training and a decoder for test time, thus\n",
        "        # we need to re-define the training decoder each time we want to\n",
        "        # train a new batch\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # decoder_initial_state is still an output of the encoder, we pass it to\n",
        "        # the decoder_instance in order to get the outputs\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True, trainable=False)\n",
        "        self.model.trainable=False\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        model_output = self.model(inputs)\n",
        "        all_outputs = model_output[0] # output of the last layer of the model\n",
        "        pooled_output = model_output[1] # last layer but processed by a linear \n",
        "                                        # layer and a tanh\n",
        "        pooled_output = self.reducer(pooled_output)\n",
        "        return all_outputs, pooled_output, pooled_output\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "        # Just one type of attention, it could be changed to seek for different\n",
        "        # results\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units) # adds the attention mechanism after a single\n",
        "                                                                                # LSTM cell, because we pass a word at the time\n",
        "        # dense layer needed to generate the distribution values over \n",
        "        # the size of the vocabulary (probability for each word)\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        # Above we describe why this cannot be changed and why it resambles\n",
        "        # the greedysampler\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        # after initializing the tensors within the attention layer to 0 we add\n",
        "        # the designated initialization that allow us to query the embedding space,\n",
        "        # which is passed as encoder_state.\n",
        "        # We load the embedding of a single batch and we actually don't freeze \n",
        "        # the parameters related to BERT, that are modified and can possibly \n",
        "        # overfit. \n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state) \n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        # as shown in calls, inputs is a dictionary with entries: \n",
        "        # \"input_ids\" : _encoder_output_\n",
        "        # \"initial_state\" : _result_of_build_initial_state_\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n",
        "\n",
        "## MODEL NAME\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "# THIS IS A SEPARATOR ##########################################################"
      ],
      "metadata": {
        "id": "tgypImQXgQhh"
      },
      "id": "tgypImQXgQhh",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
        "output_tokenizer.fit_on_texts([\"<start> \" + i + \" <end>\" for i in YQA_train])\n",
        "\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_output_length = max([len(i) for i in YQA_train])\n",
        "print(\"Max input output found: \" + str(max_output_length))\n",
        "max_sequence_length = max(512, max_output_length)\n",
        "print(\"3/4 percentile of training set answer length:\" + str(np.quantile([len(i) for i in YQA_train], 0.9)))\n",
        "max_sequence_length = 30\n",
        "\n",
        "\n",
        "print(np.argmax([len(i) for i in YQA_train]))\n",
        "print(XQA_train[7529])\n",
        "print(YQA_train[7529])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "cc39f3c4f6ae4aa7a69f166ea47e6343",
            "ac226ef40468487aaf72dd4c5a778374",
            "b0a2a0240ca545f0827e6582e0477710",
            "c99a75d7b98743a7aed23a1f01c902df",
            "92d89a9f3ed046d78d3bfca8ed193726",
            "72a495385580408a9c972edc1b1d992a",
            "7ea418273f6b4170a4afa31f1b743213",
            "d4756cacdd6745ddb9c29b055afb0c99",
            "afc32e79aaf24344a33f3b2cbdb79922",
            "0b51239b9cb6458ba5670340ac18cbe8",
            "1872fdb552bb460f973b5393b290acc5",
            "622504ed237c4f61b32fe9f9b715e310",
            "140880bfea4847779a540864da84c928",
            "9710eeb9d18c4f1f95288bc0aa751247",
            "ced734e3715f4a7caaa2e1b431093853",
            "d3db97046ae7481688b8d522db51f171",
            "5554d6faa44d4304bd04c5e431c503ed",
            "826d0b094415467a807fa110e4e470f1",
            "a512f79f83264f849c130c20502ec34e",
            "069bd2a5a5e1468c868d028abb37804e",
            "e1ad8de3f5854d279db93c83d103fff5",
            "014f8160a816427a864eedabf91c8c6b"
          ]
        },
        "id": "bRzqq374GQOC",
        "outputId": "4b7d67a0-3042-4f7c-946e-7f2d8725e666"
      },
      "id": "bRzqq374GQOC",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/285 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc39f3c4f6ae4aa7a69f166ea47e6343"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "622504ed237c4f61b32fe9f9b715e310"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input output found: 539\n",
            "3/4 percentile of training set answer length:32.0\n",
            "7529\n",
            "[\"What symptoms of addiction does Orzack's center list?\", 'Caught in the Web A few months ago, it wasn\\'t unusual for 47-year-old Carla Toebe to spend 15 hours per day online. She\\'d wake up early, turn on her laptop and chat on Internet dating sites and instant-messaging programs - leaving her bed for only brief intervals. Her household bills piled up, along with the dishes and dirty laundry, but it took near-constant complaints from her four daughters before she realized she had a problem. \"I was starting to feel like my whole world was falling apart - kind of slipping into a depression,\" said Carla. \"I knew that if I didn\\'t get off the dating sites, I\\'d just keep going,\" detaching herself further from the outside world. Toebe\\'s conclusion: She felt like she was \"addicted\" to the Internet. She\\'s not alone. Concern about excessive Internet use isn\\'t new. As far back as 1995, articles in medical journals and the establishment of a Pennsylvania treatment center for overusers generated interest in the subject. There\\'s still no consensus on how much time online constitutes too much or whether addiction is possible. But as reliance on the Web grows, there are signs that the question is getting more serious attention: Last month, a study published in CNS Spectrums claimed to be the first large-scale look at excessive Internet use. The American Psychiatric Association may consider listing Internet addiction in the next edition of its diagnostic manual. And scores of online discussion boards have popped up on which people discuss negative experiences tied to too much time on the Web. \"There\\'s no question that there\\'re people who\\'re seriously in trouble because they\\'re overdoing their Internet involvement,\" said psychiatrist Ivan Goldberg. Goldberg calls the problem a disorder rather than a true addiction. Jonathan Bishop, a researcher in Wales specializing in online communities, is more skeptical. \"The Internet is an environment,\" he said. \"You can\\'t be addicted to the environment.\" Bishop describes the problem as simply a matter of priorities, which can be solved by encouraging people to prioritize other life goals and plans in place of time spent online. The new CNS Spectrums study was based on results of a nationwide telephone survey of more than 2,500 adults. Like the 2005 survey, this one was conducted by Stanford University researchers.About 6% of respondents reported that \"their relationships suffered because of excessive Internet use.\" About 9% attempted to conceal \"nonessential Internet use,\" and nearly 4% reported feeling \"preoccupied by the Internet when offline.\" About 8% said they used the Internet as a way to escape problems, and almost 14% reported they \"found it hard to stay away from the Internet for several days at a time.\" \"The Internet problem is still in its infancy,\" said Elias Aboujaoude, a Stanford professor. No single online activity is to blame for excessive use, he said. \"They\\'re online in chat rooms, checking e-mail, or writing blogs. not limited to porn or gambling\" websites. Excessive Internet use should be defined not by the number of hours spent online but \"in terms of losses,\" said Maressa Orzack, a Harvard University professor. \"If it\\'s a loss you\\'re not getting to work, and family relationships are breaking down as a result, then it\\'s too much.\" Since the early 1990s, several clinics have been established in the U. S. to treat heavy Internet users. They include the Center for Internet Addiction Recovery and the Center for Internet Behavior. The website for Orzack\\'s center lists the following among the psychological symptoms of computer addiction: * Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders, Orzack said. When she discusses Internet habits with her patients, they often report that being online offers a \"sense of belonging, and escape, excitement fun,\" she said. \"Some people say relief...because they find themselves so relaxed.\" Some parts of the Internet seem to draw people in more than others. Internet gamers spend countless hours competing in games against people from all over the world. One such game, called World of Warcraft, is cited on many sites by posters complaining of a \"gaming addiction.\" Andrew Heidrich, an education network administrator from Sacramento, plays World of Warcraft for about two to four hours every other night, but that\\'s nothing compared with the 40 to 60 hours a week he spent playing online games when he was in college. He cut back only after a full-scale family intervention , in which s told him he\\'d gained weight. \"There\\'s this whole culture of competition that sucks people in\" with online gaming, said Heidrich, now a father of two. \"People do it at the expense of everything that was a constant in their lives.\" Heidrich now visits websites that discuss gaming addiction regularly \"to remind myself to keep my love for online games in check.\" Toebe also regularly visits a site where posters discuss Internet overuse. In August, when she first realized she had a problem, she posted a message on a Yahoo Internet addiction group with the subject line: \"I have an Internet Addiction.\" \"I\\'m self-employed and need the Internet for my work, but I\\'m failing to accomplish my work,to take care of my home, to give attention to my children,\" she wrote in a message sent to the group.\"I have no money or insurance to get professional help; I can\\'t even pay my mortgage and face losing everything.\" Since then, Toebe said, she has kept her promise to herself to cut back on her Internet use. \"I have a boyfriend now, and I\\'m not interested in online dating,\" she said by phone last week. \"It\\'s a lot better now.\"']\n",
            "Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dataset\n",
        "train_ds = Dataset.from_dict({\"xqa\": XQA_train, \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_train]})\n",
        "train_ds = train_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_token\": output_tokenizer.texts_to_sequences(x[\"yqa\"])}, batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_padded\": tf.keras.preprocessing.sequence.pad_sequences(x[\"y_token\"],\n",
        "                                                                     padding='post',\n",
        "                                                                     maxlen=max_sequence_length)}, batched=True\n",
        ")\n",
        "train_ds = train_ds.remove_columns([\"xqa\", \"yqa\", \"y_token\"])\n",
        "train_ds = train_ds.with_format(type=\"tensorflow\")\n",
        "train_ds.save_to_disk(\"gdrive/MyDrive/NLP_datasets/train_ds\")"
      ],
      "metadata": {
        "id": "nErpyDpLhRV8",
        "outputId": "3525bda0-38a9-4f99-d56c-8f98a57c993a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "82d3f150faaf47ee882b6b4b593ccb99",
            "0be3545aa1204683ac2355e2554d44a9",
            "cd0a4fb337354d82844fd9729f23ef1e",
            "b3740b6e0e7f47fd9a3fa666d7c57ecc",
            "7e1422eb357f418da6cf2b1c5e59f3d3",
            "ee27a385e1e2421c9e7b31d460d0a0c0",
            "2bec7432ab5b4fd38adf3d1163265678",
            "8b957ead9ac5476c91e5b53fd0ee4471",
            "57c73464efb34e23bb88ca2d2165549c",
            "065e5b8c10a24fc6b65ca5b0bb5f419b",
            "a1bb2247de9b484eb72897547c91cc9c",
            "edef201c511f492eb0dd8e87b4b7e2c1",
            "05ba1ccb740d4f38b8a27cc7822b1b3a",
            "596713fff8cc41638175d83906341d55",
            "8eecbfacde26499ea4819e4097fae246",
            "2922463b208944d1b862a94bb2ad884c",
            "7b0bbdfd58874cd79581d192cd450881",
            "b4b78c9767be4d5fb6690c235021cb56",
            "24d46bb0528344c8ba275a06dcebf02c",
            "f0aaa272183d43969eee2dddc85233b2",
            "f50611b0b34e4683a9ec50f91e92103e",
            "345c1dd434c54d958d8917944150d705",
            "67c8cd64374b426e8ee3732ab26a6833",
            "bcdaf0724d7349b791c8f663ef1fe5e8",
            "6c7ef784e3f2434fa612f1df08c62f02",
            "d53af78c14794bdd82727703c6be8422",
            "fe985e7c42d844838f3eaf5064e948c4",
            "af3b52804a004d809df15c2938fb35ae",
            "798891665d2b41d0aad0c60dcfcf2ffc",
            "49791bbc52894a3abc34a0f688b28ee6",
            "46800114d6ed4fda9fc68da03f29d77f",
            "d73fa1bf693d4833a6ae378020e6a368",
            "cc7dad0bf76047b383dc611ad1b076bd"
          ]
        }
      },
      "id": "nErpyDpLhRV8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82d3f150faaf47ee882b6b4b593ccb99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edef201c511f492eb0dd8e87b4b7e2c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67c8cd64374b426e8ee3732ab26a6833"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw7GeAUwW16Q",
        "outputId": "17774119-6f80-4a89-aae4-e3283e7c6809"
      },
      "id": "Zw7GeAUwW16Q",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([  101,  2073,  2003,  2023,  2635,  2173,  1029,   102, 25317,\n",
            "        1010, 13437,  1006, 13229,  1007,  1011,  1011, 14592,  2701,\n",
            "        2397,  4465,  1999, 13437,  1010,  1996, 12723,  4783, 12069,\n",
            "        2099,  1997,  1996,  2061,  1011,  2170,  5424,  3500,  1010,\n",
            "        2021,  7206,  2097,  2025,  2156,  3463,  1997,  2120,  3864,\n",
            "        2127,  9857,  1010,  4584,  2056,  1012,  2006,  4465,  1010,\n",
            "        2146,  3210,  1997,  7206,  7488,  2094,  2105,  2816,  1011,\n",
            "        2357,  1011, 17888,  1011,  3703,  1999, 25317,  1005,  1055,\n",
            "       28276,  2273,  4143,  2232,  5101,  1010,  2070,  3403,  2005,\n",
            "        2847,  2000,  3459,  1037,  3789,  1999,  1996,  3842,  1005,\n",
            "        1055,  2034,  2120,  3864,  2144,  1996,  2406,  1005,  1055,\n",
            "        4336,  1999,  3838,  1012,  1000,  2009,  1005,  1055,  1037,\n",
            "        6919,  2154,  1012,  2009,  1005,  1055,  1996,  2034,  2051,\n",
            "        2057,  2064,  5454,  2256,  2219,  4505,  1010,  1000,  2056,\n",
            "       24547,  3593,  9388, 16555,  5428,  1010,  1037,  2942,  3992,\n",
            "        2040,  4741,  2062,  2084,  2048,  2847,  1010,  1998,  2040,\n",
            "        2716,  2247,  2010,  1017,  1011,  2095,  1011,  2214,  2365,\n",
            "       10208,  2061,  2002,  2071,  1000,  2131,  2109,  2000,  4071,\n",
            "        1998,  7072,  1012,  1000, 13437,  1005,  1055,  2602,  2003,\n",
            "        1996,  2034,  2144,  1037,  2759, 10138,  1999,  2254,  2058,\n",
            "        2705, 15603,  2146,  1011,  2051, 21237,  1062,  3170,  3449,\n",
            "       11113, 28173,  2638,  3841,  4862,  1998, 13330,  1037,  4400,\n",
            "        1997, 25239,  1011,  1011,  3615,  2000,  2004,  1996,  5424,\n",
            "        3500,  1011,  1011,  2408,  1996,  2555,  1012,  2062,  2084,\n",
            "        3438,  2576,  4243,  1998,  5190,  1997,  2981,  5347,  3879,\n",
            "        2005, 20741,  4272,  1999,  1037,  2047,  6543,  3320,  1010,\n",
            "        2029,  2097,  2022,  5338,  2007,  3015,  1037,  2047,  4552,\n",
            "        1998, 10201,  1996,  7705,  2005,  1037,  2231,  2291,  1012,\n",
            "        7206,  2596, 18414, 14454,  4630,  2006,  4465,  1010,  2635,\n",
            "        7760,  1997,  2169,  2060,  2648, 17888,  3703,  1010,  2070,\n",
            "        3173, 22946,  9245,  1012,  1000,  2009,  1005,  1055,  1037,\n",
            "        6209,  1010,  1000,  2056,  2160, 19993, 24404,  5292, 12083,\n",
            "        2072,  1010,  2040,  2018,  2074,  2579,  2014,  2597,  2012,\n",
            "        1996,  2203,  1997,  1996,  2146,  2240,  1997,  2062,  2084,\n",
            "        1015,  1010,  2199,  7206,  3403,  2648,  2019,  4732,  2082,\n",
            "        1999,  2273,  4143,  2232,  1012,  1000,  2077,  2057,  2196,\n",
            "        2130,  2018,  1996,  2157,  2000,  2360,  1005,  2748,  1005,\n",
            "        2030,  1005,  2053,  1012,  1005,  1000,  3518,  1010, 13448,\n",
            "        4681,  6583,  5603,  2863, 11319,  2056,  2016,  2134,  1005,\n",
            "        1056,  2568,  1996,  2146,  3524,  2000,  3789,  1012,   102,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0])>, 'token_type_ids': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0])>, 'attention_mask': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0])>, 'y_padded': <tf.Tensor: shape=(30,), dtype=int64, numpy=\n",
            "array([   2, 6973,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0])>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds\")\n",
        "train_ds = load_from_disk(\"gdrive/MyDrive/ckpt/train_ds\")"
      ],
      "metadata": {
        "id": "q5V3J1qzG3cq"
      },
      "id": "q5V3J1qzG3cq",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 14\n",
        "\n",
        "#model_name = 'distilroberta-base'\n",
        "model_name = 'prajjwal1/bert-tiny'\n",
        "\n",
        "encoder = Encoder(model_name=model_name,\n",
        "                      decoder_units=16)\n",
        "    \n",
        "# Testing the decoder\n",
        "decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                      embedding_dim=50,\n",
        "                      decoder_units=16,\n",
        "                      batch_size=BATCH_SIZE,\n",
        "                      max_sequence_length=max_sequence_length)\n",
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                      decoder=decoder,\n",
        "                      max_length=max_sequence_length)\n",
        "    \n",
        "checkpoint_dir = './gdrive/MyDrive/ckpt'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "aefa1b9b462247ab88e2f2be30feb881",
            "16e28f939e844c73b3bd206d278b4f9a",
            "d2799741face472e92584f18f58f2dd6",
            "9a6782598cd248f4b36edc6cfbefd3f5",
            "256bee9b37e54d479d693f17b3f0146c",
            "a26f6dfb0bfb43bd802b11a582fab40a",
            "e22b0aa6030147f9802b6285c4233542",
            "d1954e9819a14c1aafc93b0be6b080f3",
            "ab133e18ff3a47898f57d4d29f777e13",
            "2879eabb13b6456ba10f905ca848b4b7",
            "f87b5a26b31846afa9ee7ba105fa8952"
          ]
        },
        "id": "PQK8ldAw9SIs",
        "outputId": "2be5059c-d8c4-42f8-9a8d-939eb18e9989"
      },
      "id": "PQK8ldAw9SIs",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aefa1b9b462247ab88e2f2be30feb881"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'bert.embeddings.position_ids', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "steps_per_epoch = len(XQA_train)//BATCH_SIZE\n",
        "print(steps_per_epoch)\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    batch_index = 0\n",
        "    cumulative_loss = 0\n",
        "\n",
        "    tic = time.time()\n",
        "    for batch_index in range(steps_per_epoch):\n",
        "      loss = trainer.batch_fit(train_ds[batch_index*BATCH_SIZE:batch_index*BATCH_SIZE+BATCH_SIZE])\n",
        "      cumulative_loss += loss\n",
        "      if batch_index % 1000 == 0:\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + \"_\" + str(batch_index) + \"_\" + str(epoch))\n",
        "      if batch_index % 10 == 0:\n",
        "        print(f'Processed batch {batch_index}')\n",
        "        print(f'time required: %.2f' % (time.time()-tic))\n",
        "\n",
        "    mean_loss = cumulative_loss / batch_index\n",
        "    print(f\"Current mean {mean_loss}\")\n",
        "\n",
        "checkpoint.save(file_prefix=checkpoint_prefix + \"_final\")"
      ],
      "metadata": {
        "id": "FCJIUPyV4Tdc",
        "outputId": "d3346608-5e17-4a4c-cba2-192461b8fe77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "FCJIUPyV4Tdc",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch 0\n",
            "time required: 15.51\n",
            "Processed batch 10\n",
            "time required: 17.05\n",
            "Processed batch 20\n",
            "time required: 18.52\n",
            "Processed batch 30\n",
            "time required: 19.98\n",
            "Processed batch 40\n",
            "time required: 21.44\n",
            "Processed batch 50\n",
            "time required: 22.91\n",
            "Processed batch 60\n",
            "time required: 24.39\n",
            "Processed batch 70\n",
            "time required: 25.88\n",
            "Processed batch 80\n",
            "time required: 27.40\n",
            "Processed batch 90\n",
            "time required: 28.88\n",
            "Processed batch 100\n",
            "time required: 30.34\n",
            "Processed batch 110\n",
            "time required: 31.81\n",
            "Processed batch 120\n",
            "time required: 33.28\n",
            "Processed batch 130\n",
            "time required: 34.76\n",
            "Processed batch 140\n",
            "time required: 36.23\n",
            "Processed batch 150\n",
            "time required: 37.72\n",
            "Processed batch 160\n",
            "time required: 39.20\n",
            "Processed batch 170\n",
            "time required: 40.68\n",
            "Processed batch 180\n",
            "time required: 42.17\n",
            "Processed batch 190\n",
            "time required: 43.64\n",
            "Processed batch 200\n",
            "time required: 45.12\n",
            "Processed batch 210\n",
            "time required: 46.59\n",
            "Processed batch 220\n",
            "time required: 48.07\n",
            "Processed batch 230\n",
            "time required: 49.56\n",
            "Processed batch 240\n",
            "time required: 51.05\n",
            "Processed batch 250\n",
            "time required: 52.52\n",
            "Processed batch 260\n",
            "time required: 54.00\n",
            "Processed batch 270\n",
            "time required: 55.48\n",
            "Processed batch 280\n",
            "time required: 56.97\n",
            "Processed batch 290\n",
            "time required: 58.44\n",
            "Processed batch 300\n",
            "time required: 59.91\n",
            "Processed batch 310\n",
            "time required: 61.38\n",
            "Processed batch 320\n",
            "time required: 62.87\n",
            "Processed batch 330\n",
            "time required: 64.35\n",
            "Processed batch 340\n",
            "time required: 65.83\n",
            "Processed batch 350\n",
            "time required: 67.32\n",
            "Processed batch 360\n",
            "time required: 68.79\n",
            "Processed batch 370\n",
            "time required: 70.25\n",
            "Processed batch 380\n",
            "time required: 71.73\n",
            "Processed batch 390\n",
            "time required: 73.21\n",
            "Processed batch 400\n",
            "time required: 74.69\n",
            "Processed batch 410\n",
            "time required: 76.16\n",
            "Processed batch 420\n",
            "time required: 77.64\n",
            "Processed batch 430\n",
            "time required: 79.11\n",
            "Processed batch 440\n",
            "time required: 80.59\n",
            "Processed batch 450\n",
            "time required: 82.06\n",
            "Processed batch 460\n",
            "time required: 83.53\n",
            "Processed batch 470\n",
            "time required: 85.02\n",
            "Processed batch 480\n",
            "time required: 86.48\n",
            "Processed batch 490\n",
            "time required: 87.95\n",
            "Processed batch 500\n",
            "time required: 89.44\n",
            "Processed batch 510\n",
            "time required: 90.91\n",
            "Processed batch 520\n",
            "time required: 92.37\n",
            "Processed batch 530\n",
            "time required: 93.87\n",
            "Processed batch 540\n",
            "time required: 95.35\n",
            "Processed batch 550\n",
            "time required: 96.81\n",
            "Processed batch 560\n",
            "time required: 98.29\n",
            "Processed batch 570\n",
            "time required: 99.76\n",
            "Processed batch 580\n",
            "time required: 101.23\n",
            "Processed batch 590\n",
            "time required: 102.70\n",
            "Processed batch 600\n",
            "time required: 104.41\n",
            "Processed batch 610\n",
            "time required: 105.88\n",
            "Processed batch 620\n",
            "time required: 107.35\n",
            "Processed batch 630\n",
            "time required: 108.82\n",
            "Processed batch 640\n",
            "time required: 110.28\n",
            "Processed batch 650\n",
            "time required: 111.75\n",
            "Processed batch 660\n",
            "time required: 113.22\n",
            "Processed batch 670\n",
            "time required: 114.70\n",
            "Processed batch 680\n",
            "time required: 116.17\n",
            "Processed batch 690\n",
            "time required: 117.64\n",
            "Processed batch 700\n",
            "time required: 119.37\n",
            "Processed batch 710\n",
            "time required: 121.14\n",
            "Processed batch 720\n",
            "time required: 122.77\n",
            "Processed batch 730\n",
            "time required: 124.23\n",
            "Processed batch 740\n",
            "time required: 125.70\n",
            "Processed batch 750\n",
            "time required: 127.19\n",
            "Processed batch 760\n",
            "time required: 128.66\n",
            "Processed batch 770\n",
            "time required: 130.13\n",
            "Processed batch 780\n",
            "time required: 131.63\n",
            "Processed batch 790\n",
            "time required: 133.10\n",
            "Processed batch 800\n",
            "time required: 134.58\n",
            "Processed batch 810\n",
            "time required: 136.05\n",
            "Processed batch 820\n",
            "time required: 137.53\n",
            "Processed batch 830\n",
            "time required: 139.01\n",
            "Processed batch 840\n",
            "time required: 140.47\n",
            "Processed batch 850\n",
            "time required: 141.94\n",
            "Processed batch 860\n",
            "time required: 143.42\n",
            "Processed batch 870\n",
            "time required: 144.89\n",
            "Processed batch 880\n",
            "time required: 146.38\n",
            "Processed batch 890\n",
            "time required: 147.86\n",
            "Processed batch 900\n",
            "time required: 149.36\n",
            "Processed batch 910\n",
            "time required: 150.83\n",
            "Processed batch 920\n",
            "time required: 152.32\n",
            "Processed batch 930\n",
            "time required: 153.80\n",
            "Processed batch 940\n",
            "time required: 155.26\n",
            "Processed batch 950\n",
            "time required: 156.72\n",
            "Processed batch 960\n",
            "time required: 158.19\n",
            "Processed batch 970\n",
            "time required: 159.70\n",
            "Processed batch 980\n",
            "time required: 161.18\n",
            "Processed batch 990\n",
            "time required: 162.64\n",
            "Processed batch 1000\n",
            "time required: 164.33\n",
            "Processed batch 1010\n",
            "time required: 165.83\n",
            "Processed batch 1020\n",
            "time required: 167.29\n",
            "Processed batch 1030\n",
            "time required: 168.77\n",
            "Processed batch 1040\n",
            "time required: 170.25\n",
            "Processed batch 1050\n",
            "time required: 171.73\n",
            "Processed batch 1060\n",
            "time required: 173.21\n",
            "Processed batch 1070\n",
            "time required: 174.70\n",
            "Processed batch 1080\n",
            "time required: 176.18\n",
            "Processed batch 1090\n",
            "time required: 177.66\n",
            "Processed batch 1100\n",
            "time required: 179.14\n",
            "Processed batch 1110\n",
            "time required: 180.62\n",
            "Processed batch 1120\n",
            "time required: 182.10\n",
            "Processed batch 1130\n",
            "time required: 183.58\n",
            "Processed batch 1140\n",
            "time required: 185.06\n",
            "Processed batch 1150\n",
            "time required: 186.67\n",
            "Processed batch 1160\n",
            "time required: 188.30\n",
            "Processed batch 1170\n",
            "time required: 189.78\n",
            "Processed batch 1180\n",
            "time required: 191.25\n",
            "Processed batch 1190\n",
            "time required: 192.72\n",
            "Processed batch 1200\n",
            "time required: 194.19\n",
            "Processed batch 1210\n",
            "time required: 195.67\n",
            "Processed batch 1220\n",
            "time required: 197.15\n",
            "Processed batch 1230\n",
            "time required: 198.64\n",
            "Processed batch 1240\n",
            "time required: 200.14\n",
            "Processed batch 1250\n",
            "time required: 201.65\n",
            "Processed batch 1260\n",
            "time required: 203.15\n",
            "Processed batch 1270\n",
            "time required: 204.63\n",
            "Processed batch 1280\n",
            "time required: 206.11\n",
            "Processed batch 1290\n",
            "time required: 207.59\n",
            "Processed batch 1300\n",
            "time required: 209.07\n",
            "Processed batch 1310\n",
            "time required: 210.55\n",
            "Processed batch 1320\n",
            "time required: 212.04\n",
            "Processed batch 1330\n",
            "time required: 213.51\n",
            "Processed batch 1340\n",
            "time required: 214.99\n",
            "Processed batch 1350\n",
            "time required: 216.48\n",
            "Processed batch 1360\n",
            "time required: 217.96\n",
            "Processed batch 1370\n",
            "time required: 219.46\n",
            "Processed batch 1380\n",
            "time required: 220.93\n",
            "Processed batch 1390\n",
            "time required: 222.42\n",
            "Processed batch 1400\n",
            "time required: 223.91\n",
            "Processed batch 1410\n",
            "time required: 225.38\n",
            "Processed batch 1420\n",
            "time required: 226.88\n",
            "Processed batch 1430\n",
            "time required: 228.37\n",
            "Processed batch 1440\n",
            "time required: 229.84\n",
            "Processed batch 1450\n",
            "time required: 231.31\n",
            "Processed batch 1460\n",
            "time required: 232.78\n",
            "Processed batch 1470\n",
            "time required: 234.26\n",
            "Processed batch 1480\n",
            "time required: 235.73\n",
            "Processed batch 1490\n",
            "time required: 237.20\n",
            "Processed batch 1500\n",
            "time required: 238.69\n",
            "Processed batch 1510\n",
            "time required: 240.16\n",
            "Processed batch 1520\n",
            "time required: 241.63\n",
            "Processed batch 1530\n",
            "time required: 243.13\n",
            "Processed batch 1540\n",
            "time required: 244.61\n",
            "Processed batch 1550\n",
            "time required: 246.09\n",
            "Processed batch 1560\n",
            "time required: 247.56\n",
            "Processed batch 1570\n",
            "time required: 249.04\n",
            "Processed batch 1580\n",
            "time required: 250.49\n",
            "Processed batch 1590\n",
            "time required: 251.96\n",
            "Processed batch 1600\n",
            "time required: 253.43\n",
            "Processed batch 1610\n",
            "time required: 254.91\n",
            "Processed batch 1620\n",
            "time required: 256.38\n",
            "Processed batch 1630\n",
            "time required: 257.86\n",
            "Processed batch 1640\n",
            "time required: 259.35\n",
            "Processed batch 1650\n",
            "time required: 260.84\n",
            "Processed batch 1660\n",
            "time required: 262.30\n",
            "Processed batch 1670\n",
            "time required: 263.78\n",
            "Processed batch 1680\n",
            "time required: 265.27\n",
            "Processed batch 1690\n",
            "time required: 266.73\n",
            "Processed batch 1700\n",
            "time required: 268.22\n",
            "Processed batch 1710\n",
            "time required: 269.70\n",
            "Processed batch 1720\n",
            "time required: 271.17\n",
            "Processed batch 1730\n",
            "time required: 272.64\n",
            "Processed batch 1740\n",
            "time required: 274.12\n",
            "Processed batch 1750\n",
            "time required: 275.61\n",
            "Processed batch 1760\n",
            "time required: 277.08\n",
            "Processed batch 1770\n",
            "time required: 278.55\n",
            "Processed batch 1780\n",
            "time required: 280.03\n",
            "Processed batch 1790\n",
            "time required: 281.52\n",
            "Processed batch 1800\n",
            "time required: 282.99\n",
            "Processed batch 1810\n",
            "time required: 284.46\n",
            "Processed batch 1820\n",
            "time required: 285.94\n",
            "Processed batch 1830\n",
            "time required: 287.41\n",
            "Processed batch 1840\n",
            "time required: 288.89\n",
            "Processed batch 1850\n",
            "time required: 290.36\n",
            "Processed batch 1860\n",
            "time required: 291.83\n",
            "Processed batch 1870\n",
            "time required: 293.32\n",
            "Processed batch 1880\n",
            "time required: 294.78\n",
            "Processed batch 1890\n",
            "time required: 296.26\n",
            "Processed batch 1900\n",
            "time required: 297.73\n",
            "Processed batch 1910\n",
            "time required: 299.21\n",
            "Processed batch 1920\n",
            "time required: 300.69\n",
            "Processed batch 1930\n",
            "time required: 302.17\n",
            "Processed batch 1940\n",
            "time required: 303.65\n",
            "Processed batch 1950\n",
            "time required: 305.26\n",
            "Processed batch 1960\n",
            "time required: 307.04\n",
            "Processed batch 1970\n",
            "time required: 308.78\n",
            "Processed batch 1980\n",
            "time required: 310.28\n",
            "Processed batch 1990\n",
            "time required: 311.76\n",
            "Processed batch 2000\n",
            "time required: 313.45\n",
            "Processed batch 2010\n",
            "time required: 314.93\n",
            "Processed batch 2020\n",
            "time required: 316.42\n",
            "Processed batch 2030\n",
            "time required: 317.89\n",
            "Processed batch 2040\n",
            "time required: 319.37\n",
            "Processed batch 2050\n",
            "time required: 320.86\n",
            "Processed batch 2060\n",
            "time required: 322.36\n",
            "Processed batch 2070\n",
            "time required: 323.85\n",
            "Processed batch 2080\n",
            "time required: 325.36\n",
            "Processed batch 2090\n",
            "time required: 326.85\n",
            "Processed batch 2100\n",
            "time required: 328.34\n",
            "Processed batch 2110\n",
            "time required: 329.82\n",
            "Processed batch 2120\n",
            "time required: 331.29\n",
            "Processed batch 2130\n",
            "time required: 332.78\n",
            "Processed batch 2140\n",
            "time required: 334.26\n",
            "Processed batch 2150\n",
            "time required: 335.73\n",
            "Processed batch 2160\n",
            "time required: 337.20\n",
            "Processed batch 2170\n",
            "time required: 338.68\n",
            "Processed batch 2180\n",
            "time required: 340.16\n",
            "Processed batch 2190\n",
            "time required: 341.63\n",
            "Processed batch 2200\n",
            "time required: 343.11\n",
            "Processed batch 2210\n",
            "time required: 344.59\n",
            "Processed batch 2220\n",
            "time required: 346.07\n",
            "Processed batch 2230\n",
            "time required: 347.55\n",
            "Processed batch 2240\n",
            "time required: 349.04\n",
            "Processed batch 2250\n",
            "time required: 350.50\n",
            "Processed batch 2260\n",
            "time required: 351.97\n",
            "Processed batch 2270\n",
            "time required: 353.44\n",
            "Processed batch 2280\n",
            "time required: 354.89\n",
            "Processed batch 2290\n",
            "time required: 356.36\n",
            "Processed batch 2300\n",
            "time required: 357.84\n",
            "Processed batch 2310\n",
            "time required: 359.31\n",
            "Processed batch 2320\n",
            "time required: 360.77\n",
            "Processed batch 2330\n",
            "time required: 362.25\n",
            "Processed batch 2340\n",
            "time required: 363.71\n",
            "Processed batch 2350\n",
            "time required: 365.19\n",
            "Processed batch 2360\n",
            "time required: 366.66\n",
            "Processed batch 2370\n",
            "time required: 368.13\n",
            "Processed batch 2380\n",
            "time required: 369.61\n",
            "Processed batch 2390\n",
            "time required: 371.09\n",
            "Processed batch 2400\n",
            "time required: 372.56\n",
            "Processed batch 2410\n",
            "time required: 374.03\n",
            "Processed batch 2420\n",
            "time required: 375.50\n",
            "Processed batch 2430\n",
            "time required: 376.96\n",
            "Processed batch 2440\n",
            "time required: 378.44\n",
            "Processed batch 2450\n",
            "time required: 379.91\n",
            "Processed batch 2460\n",
            "time required: 381.40\n",
            "Processed batch 2470\n",
            "time required: 382.88\n",
            "Processed batch 2480\n",
            "time required: 384.35\n",
            "Processed batch 2490\n",
            "time required: 385.82\n",
            "Processed batch 2500\n",
            "time required: 387.29\n",
            "Processed batch 2510\n",
            "time required: 388.76\n",
            "Processed batch 2520\n",
            "time required: 390.23\n",
            "Processed batch 2530\n",
            "time required: 391.70\n",
            "Processed batch 2540\n",
            "time required: 393.18\n",
            "Processed batch 2550\n",
            "time required: 394.68\n",
            "Processed batch 2560\n",
            "time required: 396.14\n",
            "Processed batch 2570\n",
            "time required: 397.62\n",
            "Processed batch 2580\n",
            "time required: 399.09\n",
            "Processed batch 2590\n",
            "time required: 400.56\n",
            "Processed batch 2600\n",
            "time required: 402.04\n",
            "Processed batch 2610\n",
            "time required: 403.52\n",
            "Processed batch 2620\n",
            "time required: 404.99\n",
            "Processed batch 2630\n",
            "time required: 406.47\n",
            "Processed batch 2640\n",
            "time required: 407.94\n",
            "Processed batch 2650\n",
            "time required: 409.41\n",
            "Processed batch 2660\n",
            "time required: 410.88\n",
            "Processed batch 2670\n",
            "time required: 412.35\n",
            "Processed batch 2680\n",
            "time required: 413.83\n",
            "Processed batch 2690\n",
            "time required: 415.31\n",
            "Processed batch 2700\n",
            "time required: 416.77\n",
            "Processed batch 2710\n",
            "time required: 418.24\n",
            "Processed batch 2720\n",
            "time required: 419.73\n",
            "Processed batch 2730\n",
            "time required: 421.20\n",
            "Processed batch 2740\n",
            "time required: 422.68\n",
            "Processed batch 2750\n",
            "time required: 424.16\n",
            "Processed batch 2760\n",
            "time required: 425.65\n",
            "Processed batch 2770\n",
            "time required: 427.13\n",
            "Processed batch 2780\n",
            "time required: 428.61\n",
            "Processed batch 2790\n",
            "time required: 430.08\n",
            "Processed batch 2800\n",
            "time required: 431.56\n",
            "Processed batch 2810\n",
            "time required: 433.04\n",
            "Processed batch 2820\n",
            "time required: 434.51\n",
            "Processed batch 2830\n",
            "time required: 435.99\n",
            "Processed batch 2840\n",
            "time required: 437.46\n",
            "Processed batch 2850\n",
            "time required: 438.93\n",
            "Processed batch 2860\n",
            "time required: 440.41\n",
            "Processed batch 2870\n",
            "time required: 441.88\n",
            "Processed batch 2880\n",
            "time required: 443.37\n",
            "Processed batch 2890\n",
            "time required: 444.85\n",
            "Processed batch 2900\n",
            "time required: 446.32\n",
            "Processed batch 2910\n",
            "time required: 447.80\n",
            "Processed batch 2920\n",
            "time required: 449.27\n",
            "Processed batch 2930\n",
            "time required: 450.74\n",
            "Processed batch 2940\n",
            "time required: 452.21\n",
            "Processed batch 2950\n",
            "time required: 453.69\n",
            "Processed batch 2960\n",
            "time required: 455.16\n",
            "Processed batch 2970\n",
            "time required: 456.64\n",
            "Processed batch 2980\n",
            "time required: 458.10\n",
            "Processed batch 2990\n",
            "time required: 459.58\n",
            "Processed batch 3000\n",
            "time required: 461.26\n",
            "Processed batch 3010\n",
            "time required: 462.73\n",
            "Processed batch 3020\n",
            "time required: 464.22\n",
            "Processed batch 3030\n",
            "time required: 465.71\n",
            "Processed batch 3040\n",
            "time required: 467.18\n",
            "Processed batch 3050\n",
            "time required: 468.64\n",
            "Processed batch 3060\n",
            "time required: 470.13\n",
            "Processed batch 3070\n",
            "time required: 471.63\n",
            "Processed batch 3080\n",
            "time required: 473.14\n",
            "Processed batch 3090\n",
            "time required: 474.62\n",
            "Processed batch 3100\n",
            "time required: 476.10\n",
            "Processed batch 3110\n",
            "time required: 477.56\n",
            "Processed batch 3120\n",
            "time required: 479.04\n",
            "Processed batch 3130\n",
            "time required: 480.52\n",
            "Processed batch 3140\n",
            "time required: 482.00\n",
            "Processed batch 3150\n",
            "time required: 483.49\n",
            "Processed batch 3160\n",
            "time required: 484.97\n",
            "Processed batch 3170\n",
            "time required: 486.44\n",
            "Processed batch 3180\n",
            "time required: 487.92\n",
            "Processed batch 3190\n",
            "time required: 489.40\n",
            "Processed batch 3200\n",
            "time required: 491.00\n",
            "Processed batch 3210\n",
            "time required: 492.76\n",
            "Processed batch 3220\n",
            "time required: 494.49\n",
            "Processed batch 3230\n",
            "time required: 495.98\n",
            "Processed batch 3240\n",
            "time required: 497.46\n",
            "Processed batch 3250\n",
            "time required: 498.93\n",
            "Processed batch 3260\n",
            "time required: 500.41\n",
            "Processed batch 3270\n",
            "time required: 501.88\n",
            "Processed batch 3280\n",
            "time required: 503.37\n",
            "Processed batch 3290\n",
            "time required: 504.86\n",
            "Processed batch 3300\n",
            "time required: 506.33\n",
            "Processed batch 3310\n",
            "time required: 507.81\n",
            "Processed batch 3320\n",
            "time required: 509.29\n",
            "Processed batch 3330\n",
            "time required: 510.76\n",
            "Processed batch 3340\n",
            "time required: 512.23\n",
            "Processed batch 3350\n",
            "time required: 513.70\n",
            "Processed batch 3360\n",
            "time required: 515.19\n",
            "Processed batch 3370\n",
            "time required: 516.65\n",
            "Processed batch 3380\n",
            "time required: 518.12\n",
            "Processed batch 3390\n",
            "time required: 519.59\n",
            "Processed batch 3400\n",
            "time required: 521.06\n",
            "Processed batch 3410\n",
            "time required: 522.54\n",
            "Processed batch 3420\n",
            "time required: 524.00\n",
            "Processed batch 3430\n",
            "time required: 525.49\n",
            "Processed batch 3440\n",
            "time required: 526.97\n",
            "Processed batch 3450\n",
            "time required: 528.44\n",
            "Processed batch 3460\n",
            "time required: 529.91\n",
            "Processed batch 3470\n",
            "time required: 531.39\n",
            "Processed batch 3480\n",
            "time required: 532.86\n",
            "Processed batch 3490\n",
            "time required: 534.35\n",
            "Processed batch 3500\n",
            "time required: 535.82\n",
            "Processed batch 3510\n",
            "time required: 537.30\n",
            "Processed batch 3520\n",
            "time required: 538.77\n",
            "Processed batch 3530\n",
            "time required: 540.23\n",
            "Processed batch 3540\n",
            "time required: 541.72\n",
            "Processed batch 3550\n",
            "time required: 543.20\n",
            "Processed batch 3560\n",
            "time required: 544.67\n",
            "Processed batch 3570\n",
            "time required: 546.16\n",
            "Processed batch 3580\n",
            "time required: 547.63\n",
            "Processed batch 3590\n",
            "time required: 549.10\n",
            "Processed batch 3600\n",
            "time required: 550.58\n",
            "Processed batch 3610\n",
            "time required: 552.05\n",
            "Processed batch 3620\n",
            "time required: 553.53\n",
            "Processed batch 3630\n",
            "time required: 555.00\n",
            "Processed batch 3640\n",
            "time required: 556.47\n",
            "Processed batch 3650\n",
            "time required: 557.95\n",
            "Processed batch 3660\n",
            "time required: 559.42\n",
            "Processed batch 3670\n",
            "time required: 560.88\n",
            "Processed batch 3680\n",
            "time required: 562.37\n",
            "Processed batch 3690\n",
            "time required: 563.84\n",
            "Processed batch 3700\n",
            "time required: 565.31\n",
            "Processed batch 3710\n",
            "time required: 566.80\n",
            "Processed batch 3720\n",
            "time required: 568.27\n",
            "Processed batch 3730\n",
            "time required: 569.75\n",
            "Processed batch 3740\n",
            "time required: 571.21\n",
            "Processed batch 3750\n",
            "time required: 572.68\n",
            "Processed batch 3760\n",
            "time required: 574.16\n",
            "Processed batch 3770\n",
            "time required: 575.63\n",
            "Processed batch 3780\n",
            "time required: 577.09\n",
            "Processed batch 3790\n",
            "time required: 578.57\n",
            "Processed batch 3800\n",
            "time required: 580.05\n",
            "Processed batch 3810\n",
            "time required: 581.53\n",
            "Processed batch 3820\n",
            "time required: 583.01\n",
            "Processed batch 3830\n",
            "time required: 584.48\n",
            "Processed batch 3840\n",
            "time required: 585.95\n",
            "Processed batch 3850\n",
            "time required: 587.43\n",
            "Processed batch 3860\n",
            "time required: 588.91\n",
            "Processed batch 3870\n",
            "time required: 590.38\n",
            "Processed batch 3880\n",
            "time required: 591.86\n",
            "Processed batch 3890\n",
            "time required: 593.33\n",
            "Processed batch 3900\n",
            "time required: 594.80\n",
            "Processed batch 3910\n",
            "time required: 596.27\n",
            "Processed batch 3920\n",
            "time required: 597.75\n",
            "Processed batch 3930\n",
            "time required: 599.22\n",
            "Processed batch 3940\n",
            "time required: 600.69\n",
            "Processed batch 3950\n",
            "time required: 602.16\n",
            "Processed batch 3960\n",
            "time required: 603.63\n",
            "Processed batch 3970\n",
            "time required: 605.10\n",
            "Processed batch 3980\n",
            "time required: 606.57\n",
            "Processed batch 3990\n",
            "time required: 608.05\n",
            "Processed batch 4000\n",
            "time required: 609.74\n",
            "Processed batch 4010\n",
            "time required: 611.21\n",
            "Processed batch 4020\n",
            "time required: 612.70\n",
            "Processed batch 4030\n",
            "time required: 614.18\n",
            "Processed batch 4040\n",
            "time required: 615.67\n",
            "Processed batch 4050\n",
            "time required: 617.13\n",
            "Processed batch 4060\n",
            "time required: 618.61\n",
            "Processed batch 4070\n",
            "time required: 620.09\n",
            "Processed batch 4080\n",
            "time required: 621.60\n",
            "Processed batch 4090\n",
            "time required: 623.07\n",
            "Processed batch 4100\n",
            "time required: 624.55\n",
            "Processed batch 4110\n",
            "time required: 626.04\n",
            "Processed batch 4120\n",
            "time required: 627.53\n",
            "Processed batch 4130\n",
            "time required: 629.01\n",
            "Processed batch 4140\n",
            "time required: 630.51\n",
            "Processed batch 4150\n",
            "time required: 631.99\n",
            "Processed batch 4160\n",
            "time required: 633.46\n",
            "Processed batch 4170\n",
            "time required: 634.94\n",
            "Processed batch 4180\n",
            "time required: 636.42\n",
            "Processed batch 4190\n",
            "time required: 637.89\n",
            "Processed batch 4200\n",
            "time required: 639.35\n",
            "Processed batch 4210\n",
            "time required: 640.83\n",
            "Processed batch 4220\n",
            "time required: 642.32\n",
            "Processed batch 4230\n",
            "time required: 643.79\n",
            "Processed batch 4240\n",
            "time required: 645.26\n",
            "Processed batch 4250\n",
            "time required: 646.73\n",
            "Processed batch 4260\n",
            "time required: 648.21\n",
            "Processed batch 4270\n",
            "time required: 649.68\n",
            "Processed batch 4280\n",
            "time required: 651.15\n",
            "Processed batch 4290\n",
            "time required: 652.61\n",
            "Processed batch 4300\n",
            "time required: 654.09\n",
            "Processed batch 4310\n",
            "time required: 655.57\n",
            "Processed batch 4320\n",
            "time required: 657.04\n",
            "Processed batch 4330\n",
            "time required: 658.51\n",
            "Processed batch 4340\n",
            "time required: 659.99\n",
            "Processed batch 4350\n",
            "time required: 661.45\n",
            "Processed batch 4360\n",
            "time required: 662.93\n",
            "Processed batch 4370\n",
            "time required: 664.41\n",
            "Processed batch 4380\n",
            "time required: 665.89\n",
            "Processed batch 4390\n",
            "time required: 667.37\n",
            "Processed batch 4400\n",
            "time required: 668.85\n",
            "Processed batch 4410\n",
            "time required: 670.33\n",
            "Processed batch 4420\n",
            "time required: 671.80\n",
            "Processed batch 4430\n",
            "time required: 673.28\n",
            "Processed batch 4440\n",
            "time required: 674.75\n",
            "Processed batch 4450\n",
            "time required: 676.24\n",
            "Processed batch 4460\n",
            "time required: 678.01\n",
            "Processed batch 4470\n",
            "time required: 679.76\n",
            "Processed batch 4480\n",
            "time required: 681.34\n",
            "Processed batch 4490\n",
            "time required: 682.84\n",
            "Processed batch 4500\n",
            "time required: 684.32\n",
            "Processed batch 4510\n",
            "time required: 685.77\n",
            "Processed batch 4520\n",
            "time required: 687.25\n",
            "Processed batch 4530\n",
            "time required: 688.72\n",
            "Processed batch 4540\n",
            "time required: 690.19\n",
            "Processed batch 4550\n",
            "time required: 691.66\n",
            "Processed batch 4560\n",
            "time required: 693.12\n",
            "Processed batch 4570\n",
            "time required: 694.58\n",
            "Processed batch 4580\n",
            "time required: 696.06\n",
            "Processed batch 4590\n",
            "time required: 697.56\n",
            "Processed batch 4600\n",
            "time required: 699.05\n",
            "Processed batch 4610\n",
            "time required: 700.53\n",
            "Processed batch 4620\n",
            "time required: 702.01\n",
            "Processed batch 4630\n",
            "time required: 703.48\n",
            "Processed batch 4640\n",
            "time required: 704.96\n",
            "Processed batch 4650\n",
            "time required: 706.42\n",
            "Processed batch 4660\n",
            "time required: 707.90\n",
            "Processed batch 4670\n",
            "time required: 709.38\n",
            "Processed batch 4680\n",
            "time required: 710.85\n",
            "Processed batch 4690\n",
            "time required: 712.32\n",
            "Processed batch 4700\n",
            "time required: 713.79\n",
            "Processed batch 4710\n",
            "time required: 715.26\n",
            "Processed batch 4720\n",
            "time required: 716.75\n",
            "Processed batch 4730\n",
            "time required: 718.22\n",
            "Processed batch 4740\n",
            "time required: 719.69\n",
            "Processed batch 4750\n",
            "time required: 721.16\n",
            "Processed batch 4760\n",
            "time required: 722.62\n",
            "Processed batch 4770\n",
            "time required: 724.09\n",
            "Processed batch 4780\n",
            "time required: 725.55\n",
            "Processed batch 4790\n",
            "time required: 727.01\n",
            "Processed batch 4800\n",
            "time required: 728.50\n",
            "Processed batch 4810\n",
            "time required: 729.97\n",
            "Processed batch 4820\n",
            "time required: 731.44\n",
            "Processed batch 4830\n",
            "time required: 732.91\n",
            "Processed batch 4840\n",
            "time required: 734.39\n",
            "Processed batch 4850\n",
            "time required: 735.86\n",
            "Processed batch 4860\n",
            "time required: 737.32\n",
            "Processed batch 4870\n",
            "time required: 738.79\n",
            "Processed batch 4880\n",
            "time required: 740.26\n",
            "Processed batch 4890\n",
            "time required: 741.73\n",
            "Processed batch 4900\n",
            "time required: 743.21\n",
            "Processed batch 4910\n",
            "time required: 744.70\n",
            "Processed batch 4920\n",
            "time required: 746.18\n",
            "Processed batch 4930\n",
            "time required: 747.65\n",
            "Processed batch 4940\n",
            "time required: 749.13\n",
            "Processed batch 4950\n",
            "time required: 750.61\n",
            "Processed batch 4960\n",
            "time required: 752.08\n",
            "Processed batch 4970\n",
            "time required: 753.55\n",
            "Processed batch 4980\n",
            "time required: 755.01\n",
            "Processed batch 4990\n",
            "time required: 756.49\n",
            "Processed batch 5000\n",
            "time required: 758.17\n",
            "Processed batch 5010\n",
            "time required: 759.65\n",
            "Processed batch 5020\n",
            "time required: 761.13\n",
            "Processed batch 5030\n",
            "time required: 762.61\n",
            "Processed batch 5040\n",
            "time required: 764.08\n",
            "Processed batch 5050\n",
            "time required: 765.54\n",
            "Processed batch 5060\n",
            "time required: 767.00\n",
            "Processed batch 5070\n",
            "time required: 768.51\n",
            "Processed batch 5080\n",
            "time required: 770.01\n",
            "Processed batch 5090\n",
            "time required: 771.48\n",
            "Processed batch 5100\n",
            "time required: 772.94\n",
            "Processed batch 5110\n",
            "time required: 774.42\n",
            "Processed batch 5120\n",
            "time required: 775.88\n",
            "Processed batch 5130\n",
            "time required: 777.36\n",
            "Processed batch 5140\n",
            "time required: 778.83\n",
            "Processed batch 5150\n",
            "time required: 780.31\n",
            "Processed batch 5160\n",
            "time required: 781.79\n",
            "Processed batch 5170\n",
            "time required: 783.27\n",
            "Processed batch 5180\n",
            "time required: 784.75\n",
            "Processed batch 5190\n",
            "time required: 786.23\n",
            "Processed batch 5200\n",
            "time required: 787.70\n",
            "Processed batch 5210\n",
            "time required: 789.18\n",
            "Processed batch 5220\n",
            "time required: 790.65\n",
            "Processed batch 5230\n",
            "time required: 792.13\n",
            "Processed batch 5240\n",
            "time required: 793.59\n",
            "Processed batch 5250\n",
            "time required: 795.06\n",
            "Processed batch 5260\n",
            "time required: 796.54\n",
            "Processed batch 5270\n",
            "time required: 798.01\n",
            "Processed batch 5280\n",
            "time required: 799.48\n",
            "Processed batch 5290\n",
            "time required: 800.95\n",
            "Processed batch 5300\n",
            "time required: 802.43\n",
            "Processed batch 5310\n",
            "time required: 803.91\n",
            "Processed batch 5320\n",
            "time required: 805.38\n",
            "Processed batch 5330\n",
            "time required: 806.86\n",
            "Processed batch 5340\n",
            "time required: 808.35\n",
            "Processed batch 5350\n",
            "time required: 809.82\n",
            "Processed batch 5360\n",
            "time required: 811.29\n",
            "Processed batch 5370\n",
            "time required: 812.77\n",
            "Processed batch 5380\n",
            "time required: 814.25\n",
            "Processed batch 5390\n",
            "time required: 815.72\n",
            "Processed batch 5400\n",
            "time required: 817.18\n",
            "Processed batch 5410\n",
            "time required: 818.66\n",
            "Processed batch 5420\n",
            "time required: 820.13\n",
            "Processed batch 5430\n",
            "time required: 821.60\n",
            "Processed batch 5440\n",
            "time required: 823.07\n",
            "Processed batch 5450\n",
            "time required: 824.56\n",
            "Processed batch 5460\n",
            "time required: 826.03\n",
            "Processed batch 5470\n",
            "time required: 827.50\n",
            "Processed batch 5480\n",
            "time required: 828.99\n",
            "Processed batch 5490\n",
            "time required: 830.47\n",
            "Processed batch 5500\n",
            "time required: 831.96\n",
            "Processed batch 5510\n",
            "time required: 833.42\n",
            "Processed batch 5520\n",
            "time required: 834.90\n",
            "Processed batch 5530\n",
            "time required: 836.38\n",
            "Processed batch 5540\n",
            "time required: 837.86\n",
            "Processed batch 5550\n",
            "time required: 839.34\n",
            "Processed batch 5560\n",
            "time required: 840.81\n",
            "Processed batch 5570\n",
            "time required: 842.28\n",
            "Processed batch 5580\n",
            "time required: 843.75\n",
            "Processed batch 5590\n",
            "time required: 845.22\n",
            "Processed batch 5600\n",
            "time required: 846.68\n",
            "Processed batch 5610\n",
            "time required: 848.15\n",
            "Processed batch 5620\n",
            "time required: 849.63\n",
            "Processed batch 5630\n",
            "time required: 851.10\n",
            "Processed batch 5640\n",
            "time required: 852.58\n",
            "Processed batch 5650\n",
            "time required: 854.07\n",
            "Processed batch 5660\n",
            "time required: 855.55\n",
            "Processed batch 5670\n",
            "time required: 857.03\n",
            "Processed batch 5680\n",
            "time required: 858.49\n",
            "Processed batch 5690\n",
            "time required: 859.96\n",
            "Processed batch 5700\n",
            "time required: 861.55\n",
            "Processed batch 5710\n",
            "time required: 863.34\n",
            "Processed batch 5720\n",
            "time required: 865.14\n",
            "Processed batch 5730\n",
            "time required: 866.64\n",
            "Processed batch 5740\n",
            "time required: 868.10\n",
            "Processed batch 5750\n",
            "time required: 869.60\n",
            "Processed batch 5760\n",
            "time required: 871.09\n",
            "Processed batch 5770\n",
            "time required: 872.56\n",
            "Processed batch 5780\n",
            "time required: 874.02\n",
            "Processed batch 5790\n",
            "time required: 875.50\n",
            "Processed batch 5800\n",
            "time required: 876.97\n",
            "Processed batch 5810\n",
            "time required: 878.46\n",
            "Processed batch 5820\n",
            "time required: 879.93\n",
            "Processed batch 5830\n",
            "time required: 881.41\n",
            "Processed batch 5840\n",
            "time required: 882.91\n",
            "Processed batch 5850\n",
            "time required: 884.38\n",
            "Processed batch 5860\n",
            "time required: 885.86\n",
            "Processed batch 5870\n",
            "time required: 887.33\n",
            "Processed batch 5880\n",
            "time required: 888.79\n",
            "Processed batch 5890\n",
            "time required: 890.26\n",
            "Processed batch 5900\n",
            "time required: 891.72\n",
            "Processed batch 5910\n",
            "time required: 893.20\n",
            "Processed batch 5920\n",
            "time required: 894.68\n",
            "Processed batch 5930\n",
            "time required: 896.16\n",
            "Processed batch 5940\n",
            "time required: 897.63\n",
            "Processed batch 5950\n",
            "time required: 899.11\n",
            "Processed batch 5960\n",
            "time required: 900.58\n",
            "Processed batch 5970\n",
            "time required: 902.05\n",
            "Processed batch 5980\n",
            "time required: 903.52\n",
            "Processed batch 5990\n",
            "time required: 905.01\n",
            "Processed batch 6000\n",
            "time required: 906.69\n",
            "Processed batch 6010\n",
            "time required: 908.18\n",
            "Processed batch 6020\n",
            "time required: 909.63\n",
            "Processed batch 6030\n",
            "time required: 911.13\n",
            "Processed batch 6040\n",
            "time required: 912.61\n",
            "Processed batch 6050\n",
            "time required: 914.09\n",
            "Processed batch 6060\n",
            "time required: 915.55\n",
            "Processed batch 6070\n",
            "time required: 917.03\n",
            "Processed batch 6080\n",
            "time required: 918.53\n",
            "Processed batch 6090\n",
            "time required: 920.02\n",
            "Processed batch 6100\n",
            "time required: 921.49\n",
            "Processed batch 6110\n",
            "time required: 922.97\n",
            "Processed batch 6120\n",
            "time required: 924.44\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 1/3 [15:25<30:51, 925.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.7874961495399475\n",
            "Processed batch 0\n",
            "time required: 0.37\n",
            "Processed batch 10\n",
            "time required: 1.85\n",
            "Processed batch 20\n",
            "time required: 3.32\n",
            "Processed batch 30\n",
            "time required: 4.80\n",
            "Processed batch 40\n",
            "time required: 6.28\n",
            "Processed batch 50\n",
            "time required: 7.75\n",
            "Processed batch 60\n",
            "time required: 9.24\n",
            "Processed batch 70\n",
            "time required: 10.74\n",
            "Processed batch 80\n",
            "time required: 12.23\n",
            "Processed batch 90\n",
            "time required: 13.72\n",
            "Processed batch 100\n",
            "time required: 15.21\n",
            "Processed batch 110\n",
            "time required: 16.69\n",
            "Processed batch 120\n",
            "time required: 18.16\n",
            "Processed batch 130\n",
            "time required: 19.62\n",
            "Processed batch 140\n",
            "time required: 21.10\n",
            "Processed batch 150\n",
            "time required: 22.57\n",
            "Processed batch 160\n",
            "time required: 24.05\n",
            "Processed batch 170\n",
            "time required: 25.52\n",
            "Processed batch 180\n",
            "time required: 26.99\n",
            "Processed batch 190\n",
            "time required: 28.47\n",
            "Processed batch 200\n",
            "time required: 29.93\n",
            "Processed batch 210\n",
            "time required: 31.41\n",
            "Processed batch 220\n",
            "time required: 32.88\n",
            "Processed batch 230\n",
            "time required: 34.35\n",
            "Processed batch 240\n",
            "time required: 35.83\n",
            "Processed batch 250\n",
            "time required: 37.30\n",
            "Processed batch 260\n",
            "time required: 38.77\n",
            "Processed batch 270\n",
            "time required: 40.24\n",
            "Processed batch 280\n",
            "time required: 41.70\n",
            "Processed batch 290\n",
            "time required: 43.17\n",
            "Processed batch 300\n",
            "time required: 44.63\n",
            "Processed batch 310\n",
            "time required: 46.11\n",
            "Processed batch 320\n",
            "time required: 47.59\n",
            "Processed batch 330\n",
            "time required: 49.07\n",
            "Processed batch 340\n",
            "time required: 50.54\n",
            "Processed batch 350\n",
            "time required: 52.03\n",
            "Processed batch 360\n",
            "time required: 53.49\n",
            "Processed batch 370\n",
            "time required: 54.96\n",
            "Processed batch 380\n",
            "time required: 56.43\n",
            "Processed batch 390\n",
            "time required: 57.91\n",
            "Processed batch 400\n",
            "time required: 59.40\n",
            "Processed batch 410\n",
            "time required: 60.88\n",
            "Processed batch 420\n",
            "time required: 62.35\n",
            "Processed batch 430\n",
            "time required: 63.82\n",
            "Processed batch 440\n",
            "time required: 65.29\n",
            "Processed batch 450\n",
            "time required: 66.77\n",
            "Processed batch 460\n",
            "time required: 68.24\n",
            "Processed batch 470\n",
            "time required: 69.71\n",
            "Processed batch 480\n",
            "time required: 71.18\n",
            "Processed batch 490\n",
            "time required: 72.64\n",
            "Processed batch 500\n",
            "time required: 74.11\n",
            "Processed batch 510\n",
            "time required: 75.57\n",
            "Processed batch 520\n",
            "time required: 77.04\n",
            "Processed batch 530\n",
            "time required: 78.50\n",
            "Processed batch 540\n",
            "time required: 79.96\n",
            "Processed batch 550\n",
            "time required: 81.43\n",
            "Processed batch 560\n",
            "time required: 82.90\n",
            "Processed batch 570\n",
            "time required: 84.36\n",
            "Processed batch 580\n",
            "time required: 85.84\n",
            "Processed batch 590\n",
            "time required: 87.31\n",
            "Processed batch 600\n",
            "time required: 88.78\n",
            "Processed batch 610\n",
            "time required: 90.24\n",
            "Processed batch 620\n",
            "time required: 91.73\n",
            "Processed batch 630\n",
            "time required: 93.20\n",
            "Processed batch 640\n",
            "time required: 94.69\n",
            "Processed batch 650\n",
            "time required: 96.16\n",
            "Processed batch 660\n",
            "time required: 97.64\n",
            "Processed batch 670\n",
            "time required: 99.11\n",
            "Processed batch 680\n",
            "time required: 100.59\n",
            "Processed batch 690\n",
            "time required: 102.07\n",
            "Processed batch 700\n",
            "time required: 103.53\n",
            "Processed batch 710\n",
            "time required: 105.00\n",
            "Processed batch 720\n",
            "time required: 106.48\n",
            "Processed batch 730\n",
            "time required: 107.95\n",
            "Processed batch 740\n",
            "time required: 109.43\n",
            "Processed batch 750\n",
            "time required: 110.90\n",
            "Processed batch 760\n",
            "time required: 112.37\n",
            "Processed batch 770\n",
            "time required: 113.86\n",
            "Processed batch 780\n",
            "time required: 115.34\n",
            "Processed batch 790\n",
            "time required: 116.83\n",
            "Processed batch 800\n",
            "time required: 118.31\n",
            "Processed batch 810\n",
            "time required: 120.04\n",
            "Processed batch 820\n",
            "time required: 121.84\n",
            "Processed batch 830\n",
            "time required: 123.59\n",
            "Processed batch 840\n",
            "time required: 125.08\n",
            "Processed batch 850\n",
            "time required: 126.55\n",
            "Processed batch 860\n",
            "time required: 128.03\n",
            "Processed batch 870\n",
            "time required: 129.49\n",
            "Processed batch 880\n",
            "time required: 130.98\n",
            "Processed batch 890\n",
            "time required: 132.44\n",
            "Processed batch 900\n",
            "time required: 133.93\n",
            "Processed batch 910\n",
            "time required: 135.41\n",
            "Processed batch 920\n",
            "time required: 136.88\n",
            "Processed batch 930\n",
            "time required: 138.37\n",
            "Processed batch 940\n",
            "time required: 139.86\n",
            "Processed batch 950\n",
            "time required: 141.33\n",
            "Processed batch 960\n",
            "time required: 142.80\n",
            "Processed batch 970\n",
            "time required: 144.29\n",
            "Processed batch 980\n",
            "time required: 145.77\n",
            "Processed batch 990\n",
            "time required: 147.26\n",
            "Processed batch 1000\n",
            "time required: 148.97\n",
            "Processed batch 1010\n",
            "time required: 150.44\n",
            "Processed batch 1020\n",
            "time required: 151.93\n",
            "Processed batch 1030\n",
            "time required: 153.39\n",
            "Processed batch 1040\n",
            "time required: 154.86\n",
            "Processed batch 1050\n",
            "time required: 156.34\n",
            "Processed batch 1060\n",
            "time required: 157.81\n",
            "Processed batch 1070\n",
            "time required: 159.31\n",
            "Processed batch 1080\n",
            "time required: 160.81\n",
            "Processed batch 1090\n",
            "time required: 162.27\n",
            "Processed batch 1100\n",
            "time required: 163.75\n",
            "Processed batch 1110\n",
            "time required: 165.22\n",
            "Processed batch 1120\n",
            "time required: 166.69\n",
            "Processed batch 1130\n",
            "time required: 168.17\n",
            "Processed batch 1140\n",
            "time required: 169.65\n",
            "Processed batch 1150\n",
            "time required: 171.12\n",
            "Processed batch 1160\n",
            "time required: 172.59\n",
            "Processed batch 1170\n",
            "time required: 174.06\n",
            "Processed batch 1180\n",
            "time required: 175.53\n",
            "Processed batch 1190\n",
            "time required: 176.99\n",
            "Processed batch 1200\n",
            "time required: 178.45\n",
            "Processed batch 1210\n",
            "time required: 179.93\n",
            "Processed batch 1220\n",
            "time required: 181.41\n",
            "Processed batch 1230\n",
            "time required: 182.90\n",
            "Processed batch 1240\n",
            "time required: 184.37\n",
            "Processed batch 1250\n",
            "time required: 185.84\n",
            "Processed batch 1260\n",
            "time required: 187.32\n",
            "Processed batch 1270\n",
            "time required: 188.79\n",
            "Processed batch 1280\n",
            "time required: 190.32\n",
            "Processed batch 1290\n",
            "time required: 192.06\n",
            "Processed batch 1300\n",
            "time required: 193.84\n",
            "Processed batch 1310\n",
            "time required: 195.70\n",
            "Processed batch 1320\n",
            "time required: 197.17\n",
            "Processed batch 1330\n",
            "time required: 198.65\n",
            "Processed batch 1340\n",
            "time required: 200.12\n",
            "Processed batch 1350\n",
            "time required: 201.59\n",
            "Processed batch 1360\n",
            "time required: 203.05\n",
            "Processed batch 1370\n",
            "time required: 204.52\n",
            "Processed batch 1380\n",
            "time required: 205.99\n",
            "Processed batch 1390\n",
            "time required: 207.44\n",
            "Processed batch 1400\n",
            "time required: 208.92\n",
            "Processed batch 1410\n",
            "time required: 210.39\n",
            "Processed batch 1420\n",
            "time required: 211.84\n",
            "Processed batch 1430\n",
            "time required: 213.32\n",
            "Processed batch 1440\n",
            "time required: 214.80\n",
            "Processed batch 1450\n",
            "time required: 216.28\n",
            "Processed batch 1460\n",
            "time required: 217.77\n",
            "Processed batch 1470\n",
            "time required: 219.24\n",
            "Processed batch 1480\n",
            "time required: 220.71\n",
            "Processed batch 1490\n",
            "time required: 222.19\n",
            "Processed batch 1500\n",
            "time required: 223.67\n",
            "Processed batch 1510\n",
            "time required: 225.15\n",
            "Processed batch 1520\n",
            "time required: 226.63\n",
            "Processed batch 1530\n",
            "time required: 228.13\n",
            "Processed batch 1540\n",
            "time required: 229.62\n",
            "Processed batch 1550\n",
            "time required: 231.21\n",
            "Processed batch 1560\n",
            "time required: 232.93\n",
            "Processed batch 1570\n",
            "time required: 234.66\n",
            "Processed batch 1580\n",
            "time required: 236.32\n",
            "Processed batch 1590\n",
            "time required: 238.05\n",
            "Processed batch 1600\n",
            "time required: 239.87\n",
            "Processed batch 1610\n",
            "time required: 241.74\n",
            "Processed batch 1620\n",
            "time required: 243.28\n",
            "Processed batch 1630\n",
            "time required: 244.76\n",
            "Processed batch 1640\n",
            "time required: 246.24\n",
            "Processed batch 1650\n",
            "time required: 247.72\n",
            "Processed batch 1660\n",
            "time required: 249.18\n",
            "Processed batch 1670\n",
            "time required: 250.65\n",
            "Processed batch 1680\n",
            "time required: 252.11\n",
            "Processed batch 1690\n",
            "time required: 253.57\n",
            "Processed batch 1700\n",
            "time required: 255.04\n",
            "Processed batch 1710\n",
            "time required: 256.50\n",
            "Processed batch 1720\n",
            "time required: 257.98\n",
            "Processed batch 1730\n",
            "time required: 259.44\n",
            "Processed batch 1740\n",
            "time required: 260.92\n",
            "Processed batch 1750\n",
            "time required: 262.38\n",
            "Processed batch 1760\n",
            "time required: 263.85\n",
            "Processed batch 1770\n",
            "time required: 265.31\n",
            "Processed batch 1780\n",
            "time required: 266.81\n",
            "Processed batch 1790\n",
            "time required: 268.28\n",
            "Processed batch 1800\n",
            "time required: 269.75\n",
            "Processed batch 1810\n",
            "time required: 271.21\n",
            "Processed batch 1820\n",
            "time required: 272.68\n",
            "Processed batch 1830\n",
            "time required: 274.14\n",
            "Processed batch 1840\n",
            "time required: 275.61\n",
            "Processed batch 1850\n",
            "time required: 277.07\n",
            "Processed batch 1860\n",
            "time required: 278.55\n",
            "Processed batch 1870\n",
            "time required: 280.01\n",
            "Processed batch 1880\n",
            "time required: 281.49\n",
            "Processed batch 1890\n",
            "time required: 282.97\n",
            "Processed batch 1900\n",
            "time required: 284.45\n",
            "Processed batch 1910\n",
            "time required: 285.90\n",
            "Processed batch 1920\n",
            "time required: 287.37\n",
            "Processed batch 1930\n",
            "time required: 288.83\n",
            "Processed batch 1940\n",
            "time required: 290.29\n",
            "Processed batch 1950\n",
            "time required: 291.76\n",
            "Processed batch 1960\n",
            "time required: 293.23\n",
            "Processed batch 1970\n",
            "time required: 294.70\n",
            "Processed batch 1980\n",
            "time required: 296.17\n",
            "Processed batch 1990\n",
            "time required: 297.64\n",
            "Processed batch 2000\n",
            "time required: 299.36\n",
            "Processed batch 2010\n",
            "time required: 300.84\n",
            "Processed batch 2020\n",
            "time required: 302.33\n",
            "Processed batch 2030\n",
            "time required: 303.95\n",
            "Processed batch 2040\n",
            "time required: 305.71\n",
            "Processed batch 2050\n",
            "time required: 307.46\n",
            "Processed batch 2060\n",
            "time required: 308.96\n",
            "Processed batch 2070\n",
            "time required: 310.48\n",
            "Processed batch 2080\n",
            "time required: 311.95\n",
            "Processed batch 2090\n",
            "time required: 313.43\n",
            "Processed batch 2100\n",
            "time required: 314.89\n",
            "Processed batch 2110\n",
            "time required: 316.37\n",
            "Processed batch 2120\n",
            "time required: 317.85\n",
            "Processed batch 2130\n",
            "time required: 319.33\n",
            "Processed batch 2140\n",
            "time required: 320.80\n",
            "Processed batch 2150\n",
            "time required: 322.28\n",
            "Processed batch 2160\n",
            "time required: 323.76\n",
            "Processed batch 2170\n",
            "time required: 325.26\n",
            "Processed batch 2180\n",
            "time required: 326.74\n",
            "Processed batch 2190\n",
            "time required: 328.22\n",
            "Processed batch 2200\n",
            "time required: 329.70\n",
            "Processed batch 2210\n",
            "time required: 331.18\n",
            "Processed batch 2220\n",
            "time required: 332.66\n",
            "Processed batch 2230\n",
            "time required: 334.12\n",
            "Processed batch 2240\n",
            "time required: 335.60\n",
            "Processed batch 2250\n",
            "time required: 337.08\n",
            "Processed batch 2260\n",
            "time required: 338.56\n",
            "Processed batch 2270\n",
            "time required: 340.19\n",
            "Processed batch 2280\n",
            "time required: 341.79\n",
            "Processed batch 2290\n",
            "time required: 343.25\n",
            "Processed batch 2300\n",
            "time required: 344.72\n",
            "Processed batch 2310\n",
            "time required: 346.18\n",
            "Processed batch 2320\n",
            "time required: 347.65\n",
            "Processed batch 2330\n",
            "time required: 349.13\n",
            "Processed batch 2340\n",
            "time required: 350.73\n",
            "Processed batch 2350\n",
            "time required: 352.48\n",
            "Processed batch 2360\n",
            "time required: 354.24\n",
            "Processed batch 2370\n",
            "time required: 356.06\n",
            "Processed batch 2380\n",
            "time required: 357.94\n",
            "Processed batch 2390\n",
            "time required: 359.49\n",
            "Processed batch 2400\n",
            "time required: 360.96\n",
            "Processed batch 2410\n",
            "time required: 362.44\n",
            "Processed batch 2420\n",
            "time required: 363.91\n",
            "Processed batch 2430\n",
            "time required: 365.39\n",
            "Processed batch 2440\n",
            "time required: 366.86\n",
            "Processed batch 2450\n",
            "time required: 368.32\n",
            "Processed batch 2460\n",
            "time required: 369.81\n",
            "Processed batch 2470\n",
            "time required: 371.30\n",
            "Processed batch 2480\n",
            "time required: 372.78\n",
            "Processed batch 2490\n",
            "time required: 374.25\n",
            "Processed batch 2500\n",
            "time required: 375.73\n",
            "Processed batch 2510\n",
            "time required: 377.20\n",
            "Processed batch 2520\n",
            "time required: 378.67\n",
            "Processed batch 2530\n",
            "time required: 380.14\n",
            "Processed batch 2540\n",
            "time required: 381.59\n",
            "Processed batch 2550\n",
            "time required: 383.06\n",
            "Processed batch 2560\n",
            "time required: 384.53\n",
            "Processed batch 2570\n",
            "time required: 385.99\n",
            "Processed batch 2580\n",
            "time required: 387.47\n",
            "Processed batch 2590\n",
            "time required: 388.93\n",
            "Processed batch 2600\n",
            "time required: 390.43\n",
            "Processed batch 2610\n",
            "time required: 391.90\n",
            "Processed batch 2620\n",
            "time required: 393.37\n",
            "Processed batch 2630\n",
            "time required: 394.84\n",
            "Processed batch 2640\n",
            "time required: 396.32\n",
            "Processed batch 2650\n",
            "time required: 397.79\n",
            "Processed batch 2660\n",
            "time required: 399.26\n",
            "Processed batch 2670\n",
            "time required: 400.72\n",
            "Processed batch 2680\n",
            "time required: 402.18\n",
            "Processed batch 2690\n",
            "time required: 403.64\n",
            "Processed batch 2700\n",
            "time required: 405.10\n",
            "Processed batch 2710\n",
            "time required: 406.60\n",
            "Processed batch 2720\n",
            "time required: 408.07\n",
            "Processed batch 2730\n",
            "time required: 409.55\n",
            "Processed batch 2740\n",
            "time required: 411.03\n",
            "Processed batch 2750\n",
            "time required: 412.48\n",
            "Processed batch 2760\n",
            "time required: 413.96\n",
            "Processed batch 2770\n",
            "time required: 415.43\n",
            "Processed batch 2780\n",
            "time required: 416.92\n",
            "Processed batch 2790\n",
            "time required: 418.39\n",
            "Processed batch 2800\n",
            "time required: 419.86\n",
            "Processed batch 2810\n",
            "time required: 421.35\n",
            "Processed batch 2820\n",
            "time required: 422.82\n",
            "Processed batch 2830\n",
            "time required: 424.30\n",
            "Processed batch 2840\n",
            "time required: 425.77\n",
            "Processed batch 2850\n",
            "time required: 427.25\n",
            "Processed batch 2860\n",
            "time required: 428.74\n",
            "Processed batch 2870\n",
            "time required: 430.22\n",
            "Processed batch 2880\n",
            "time required: 431.71\n",
            "Processed batch 2890\n",
            "time required: 433.19\n",
            "Processed batch 2900\n",
            "time required: 434.67\n",
            "Processed batch 2910\n",
            "time required: 436.13\n",
            "Processed batch 2920\n",
            "time required: 437.61\n",
            "Processed batch 2930\n",
            "time required: 439.08\n",
            "Processed batch 2940\n",
            "time required: 440.56\n",
            "Processed batch 2950\n",
            "time required: 442.04\n",
            "Processed batch 2960\n",
            "time required: 443.51\n",
            "Processed batch 2970\n",
            "time required: 444.97\n",
            "Processed batch 2980\n",
            "time required: 446.44\n",
            "Processed batch 2990\n",
            "time required: 447.91\n",
            "Processed batch 3000\n",
            "time required: 449.59\n",
            "Processed batch 3010\n",
            "time required: 451.06\n",
            "Processed batch 3020\n",
            "time required: 452.54\n",
            "Processed batch 3030\n",
            "time required: 454.01\n",
            "Processed batch 3040\n",
            "time required: 455.48\n",
            "Processed batch 3050\n",
            "time required: 456.95\n",
            "Processed batch 3060\n",
            "time required: 458.43\n",
            "Processed batch 3070\n",
            "time required: 459.92\n",
            "Processed batch 3080\n",
            "time required: 461.41\n",
            "Processed batch 3090\n",
            "time required: 462.88\n",
            "Processed batch 3100\n",
            "time required: 464.34\n",
            "Processed batch 3110\n",
            "time required: 465.80\n",
            "Processed batch 3120\n",
            "time required: 467.28\n",
            "Processed batch 3130\n",
            "time required: 468.75\n",
            "Processed batch 3140\n",
            "time required: 470.22\n",
            "Processed batch 3150\n",
            "time required: 471.69\n",
            "Processed batch 3160\n",
            "time required: 473.17\n",
            "Processed batch 3170\n",
            "time required: 474.65\n",
            "Processed batch 3180\n",
            "time required: 476.13\n",
            "Processed batch 3190\n",
            "time required: 477.60\n",
            "Processed batch 3200\n",
            "time required: 479.08\n",
            "Processed batch 3210\n",
            "time required: 480.54\n",
            "Processed batch 3220\n",
            "time required: 482.03\n",
            "Processed batch 3230\n",
            "time required: 483.48\n",
            "Processed batch 3240\n",
            "time required: 484.97\n",
            "Processed batch 3250\n",
            "time required: 486.59\n",
            "Processed batch 3260\n",
            "time required: 488.37\n",
            "Processed batch 3270\n",
            "time required: 490.14\n",
            "Processed batch 3280\n",
            "time required: 491.59\n",
            "Processed batch 3290\n",
            "time required: 493.05\n",
            "Processed batch 3300\n",
            "time required: 494.54\n",
            "Processed batch 3310\n",
            "time required: 496.00\n",
            "Processed batch 3320\n",
            "time required: 497.46\n",
            "Processed batch 3330\n",
            "time required: 498.91\n",
            "Processed batch 3340\n",
            "time required: 500.36\n",
            "Processed batch 3350\n",
            "time required: 501.82\n",
            "Processed batch 3360\n",
            "time required: 503.29\n",
            "Processed batch 3370\n",
            "time required: 504.76\n",
            "Processed batch 3380\n",
            "time required: 506.22\n",
            "Processed batch 3390\n",
            "time required: 507.69\n",
            "Processed batch 3400\n",
            "time required: 509.16\n",
            "Processed batch 3410\n",
            "time required: 510.63\n",
            "Processed batch 3420\n",
            "time required: 512.11\n",
            "Processed batch 3430\n",
            "time required: 513.58\n",
            "Processed batch 3440\n",
            "time required: 515.05\n",
            "Processed batch 3450\n",
            "time required: 516.53\n",
            "Processed batch 3460\n",
            "time required: 518.00\n",
            "Processed batch 3470\n",
            "time required: 519.46\n",
            "Processed batch 3480\n",
            "time required: 520.93\n",
            "Processed batch 3490\n",
            "time required: 522.41\n",
            "Processed batch 3500\n",
            "time required: 523.87\n",
            "Processed batch 3510\n",
            "time required: 525.33\n",
            "Processed batch 3520\n",
            "time required: 526.81\n",
            "Processed batch 3530\n",
            "time required: 528.26\n",
            "Processed batch 3540\n",
            "time required: 529.73\n",
            "Processed batch 3550\n",
            "time required: 531.19\n",
            "Processed batch 3560\n",
            "time required: 532.65\n",
            "Processed batch 3570\n",
            "time required: 534.11\n",
            "Processed batch 3580\n",
            "time required: 535.58\n",
            "Processed batch 3590\n",
            "time required: 537.05\n",
            "Processed batch 3600\n",
            "time required: 538.53\n",
            "Processed batch 3610\n",
            "time required: 540.01\n",
            "Processed batch 3620\n",
            "time required: 541.49\n",
            "Processed batch 3630\n",
            "time required: 542.96\n",
            "Processed batch 3640\n",
            "time required: 544.43\n",
            "Processed batch 3650\n",
            "time required: 545.89\n",
            "Processed batch 3660\n",
            "time required: 547.37\n",
            "Processed batch 3670\n",
            "time required: 548.84\n",
            "Processed batch 3680\n",
            "time required: 550.32\n",
            "Processed batch 3690\n",
            "time required: 551.79\n",
            "Processed batch 3700\n",
            "time required: 553.26\n",
            "Processed batch 3710\n",
            "time required: 554.72\n",
            "Processed batch 3720\n",
            "time required: 556.20\n",
            "Processed batch 3730\n",
            "time required: 557.66\n",
            "Processed batch 3740\n",
            "time required: 559.12\n",
            "Processed batch 3750\n",
            "time required: 560.59\n",
            "Processed batch 3760\n",
            "time required: 562.04\n",
            "Processed batch 3770\n",
            "time required: 563.49\n",
            "Processed batch 3780\n",
            "time required: 564.95\n",
            "Processed batch 3790\n",
            "time required: 566.42\n",
            "Processed batch 3800\n",
            "time required: 567.89\n",
            "Processed batch 3810\n",
            "time required: 569.35\n",
            "Processed batch 3820\n",
            "time required: 570.82\n",
            "Processed batch 3830\n",
            "time required: 572.28\n",
            "Processed batch 3840\n",
            "time required: 573.73\n",
            "Processed batch 3850\n",
            "time required: 575.20\n",
            "Processed batch 3860\n",
            "time required: 576.67\n",
            "Processed batch 3870\n",
            "time required: 578.14\n",
            "Processed batch 3880\n",
            "time required: 579.61\n",
            "Processed batch 3890\n",
            "time required: 581.08\n",
            "Processed batch 3900\n",
            "time required: 582.55\n",
            "Processed batch 3910\n",
            "time required: 584.01\n",
            "Processed batch 3920\n",
            "time required: 585.49\n",
            "Processed batch 3930\n",
            "time required: 586.96\n",
            "Processed batch 3940\n",
            "time required: 588.43\n",
            "Processed batch 3950\n",
            "time required: 589.91\n",
            "Processed batch 3960\n",
            "time required: 591.36\n",
            "Processed batch 3970\n",
            "time required: 592.84\n",
            "Processed batch 3980\n",
            "time required: 594.32\n",
            "Processed batch 3990\n",
            "time required: 595.79\n",
            "Processed batch 4000\n",
            "time required: 597.47\n",
            "Processed batch 4010\n",
            "time required: 598.93\n",
            "Processed batch 4020\n",
            "time required: 600.40\n",
            "Processed batch 4030\n",
            "time required: 601.87\n",
            "Processed batch 4040\n",
            "time required: 603.36\n",
            "Processed batch 4050\n",
            "time required: 604.85\n",
            "Processed batch 4060\n",
            "time required: 606.33\n",
            "Processed batch 4070\n",
            "time required: 607.81\n",
            "Processed batch 4080\n",
            "time required: 609.29\n",
            "Processed batch 4090\n",
            "time required: 610.77\n",
            "Processed batch 4100\n",
            "time required: 612.23\n",
            "Processed batch 4110\n",
            "time required: 613.68\n",
            "Processed batch 4120\n",
            "time required: 615.16\n",
            "Processed batch 4130\n",
            "time required: 616.63\n",
            "Processed batch 4140\n",
            "time required: 618.10\n",
            "Processed batch 4150\n",
            "time required: 619.58\n",
            "Processed batch 4160\n",
            "time required: 621.03\n",
            "Processed batch 4170\n",
            "time required: 622.50\n",
            "Processed batch 4180\n",
            "time required: 623.95\n",
            "Processed batch 4190\n",
            "time required: 625.43\n",
            "Processed batch 4200\n",
            "time required: 626.90\n",
            "Processed batch 4210\n",
            "time required: 628.37\n",
            "Processed batch 4220\n",
            "time required: 629.84\n",
            "Processed batch 4230\n",
            "time required: 631.31\n",
            "Processed batch 4240\n",
            "time required: 632.77\n",
            "Processed batch 4250\n",
            "time required: 634.25\n",
            "Processed batch 4260\n",
            "time required: 635.72\n",
            "Processed batch 4270\n",
            "time required: 637.19\n",
            "Processed batch 4280\n",
            "time required: 638.67\n",
            "Processed batch 4290\n",
            "time required: 640.14\n",
            "Processed batch 4300\n",
            "time required: 641.59\n",
            "Processed batch 4310\n",
            "time required: 643.06\n",
            "Processed batch 4320\n",
            "time required: 644.51\n",
            "Processed batch 4330\n",
            "time required: 645.99\n",
            "Processed batch 4340\n",
            "time required: 647.45\n",
            "Processed batch 4350\n",
            "time required: 648.93\n",
            "Processed batch 4360\n",
            "time required: 650.38\n",
            "Processed batch 4370\n",
            "time required: 651.84\n",
            "Processed batch 4380\n",
            "time required: 653.30\n",
            "Processed batch 4390\n",
            "time required: 654.77\n",
            "Processed batch 4400\n",
            "time required: 656.24\n",
            "Processed batch 4410\n",
            "time required: 657.70\n",
            "Processed batch 4420\n",
            "time required: 659.16\n",
            "Processed batch 4430\n",
            "time required: 660.63\n",
            "Processed batch 4440\n",
            "time required: 662.09\n",
            "Processed batch 4450\n",
            "time required: 663.58\n",
            "Processed batch 4460\n",
            "time required: 665.04\n",
            "Processed batch 4470\n",
            "time required: 666.50\n",
            "Processed batch 4480\n",
            "time required: 668.00\n",
            "Processed batch 4490\n",
            "time required: 669.50\n",
            "Processed batch 4500\n",
            "time required: 671.34\n",
            "Processed batch 4510\n",
            "time required: 673.11\n",
            "Processed batch 4520\n",
            "time required: 674.73\n",
            "Processed batch 4530\n",
            "time required: 676.21\n",
            "Processed batch 4540\n",
            "time required: 677.68\n",
            "Processed batch 4550\n",
            "time required: 679.16\n",
            "Processed batch 4560\n",
            "time required: 680.63\n",
            "Processed batch 4570\n",
            "time required: 682.10\n",
            "Processed batch 4580\n",
            "time required: 683.57\n",
            "Processed batch 4590\n",
            "time required: 685.04\n",
            "Processed batch 4600\n",
            "time required: 686.52\n",
            "Processed batch 4610\n",
            "time required: 688.00\n",
            "Processed batch 4620\n",
            "time required: 689.47\n",
            "Processed batch 4630\n",
            "time required: 690.95\n",
            "Processed batch 4640\n",
            "time required: 692.42\n",
            "Processed batch 4650\n",
            "time required: 693.90\n",
            "Processed batch 4660\n",
            "time required: 695.37\n",
            "Processed batch 4670\n",
            "time required: 696.85\n",
            "Processed batch 4680\n",
            "time required: 698.34\n",
            "Processed batch 4690\n",
            "time required: 699.81\n",
            "Processed batch 4700\n",
            "time required: 701.29\n",
            "Processed batch 4710\n",
            "time required: 702.76\n",
            "Processed batch 4720\n",
            "time required: 704.21\n",
            "Processed batch 4730\n",
            "time required: 705.67\n",
            "Processed batch 4740\n",
            "time required: 707.16\n",
            "Processed batch 4750\n",
            "time required: 708.63\n",
            "Processed batch 4760\n",
            "time required: 710.09\n",
            "Processed batch 4770\n",
            "time required: 711.56\n",
            "Processed batch 4780\n",
            "time required: 713.03\n",
            "Processed batch 4790\n",
            "time required: 714.51\n",
            "Processed batch 4800\n",
            "time required: 715.98\n",
            "Processed batch 4810\n",
            "time required: 717.44\n",
            "Processed batch 4820\n",
            "time required: 718.91\n",
            "Processed batch 4830\n",
            "time required: 720.38\n",
            "Processed batch 4840\n",
            "time required: 721.85\n",
            "Processed batch 4850\n",
            "time required: 723.32\n",
            "Processed batch 4860\n",
            "time required: 724.79\n",
            "Processed batch 4870\n",
            "time required: 726.27\n",
            "Processed batch 4880\n",
            "time required: 727.74\n",
            "Processed batch 4890\n",
            "time required: 729.20\n",
            "Processed batch 4900\n",
            "time required: 730.67\n",
            "Processed batch 4910\n",
            "time required: 732.13\n",
            "Processed batch 4920\n",
            "time required: 733.59\n",
            "Processed batch 4930\n",
            "time required: 735.06\n",
            "Processed batch 4940\n",
            "time required: 736.52\n",
            "Processed batch 4950\n",
            "time required: 737.97\n",
            "Processed batch 4960\n",
            "time required: 739.46\n",
            "Processed batch 4970\n",
            "time required: 740.92\n",
            "Processed batch 4980\n",
            "time required: 742.38\n",
            "Processed batch 4990\n",
            "time required: 743.83\n",
            "Processed batch 5000\n",
            "time required: 745.54\n",
            "Processed batch 5010\n",
            "time required: 747.01\n",
            "Processed batch 5020\n",
            "time required: 748.49\n",
            "Processed batch 5030\n",
            "time required: 749.95\n",
            "Processed batch 5040\n",
            "time required: 751.40\n",
            "Processed batch 5050\n",
            "time required: 752.88\n",
            "Processed batch 5060\n",
            "time required: 754.39\n",
            "Processed batch 5070\n",
            "time required: 755.87\n",
            "Processed batch 5080\n",
            "time required: 757.34\n",
            "Processed batch 5090\n",
            "time required: 758.80\n",
            "Processed batch 5100\n",
            "time required: 760.26\n",
            "Processed batch 5110\n",
            "time required: 761.73\n",
            "Processed batch 5120\n",
            "time required: 763.19\n",
            "Processed batch 5130\n",
            "time required: 764.65\n",
            "Processed batch 5140\n",
            "time required: 766.10\n",
            "Processed batch 5150\n",
            "time required: 767.58\n",
            "Processed batch 5160\n",
            "time required: 769.04\n",
            "Processed batch 5170\n",
            "time required: 770.52\n",
            "Processed batch 5180\n",
            "time required: 772.00\n",
            "Processed batch 5190\n",
            "time required: 773.47\n",
            "Processed batch 5200\n",
            "time required: 774.96\n",
            "Processed batch 5210\n",
            "time required: 776.42\n",
            "Processed batch 5220\n",
            "time required: 777.89\n",
            "Processed batch 5230\n",
            "time required: 779.36\n",
            "Processed batch 5240\n",
            "time required: 780.84\n",
            "Processed batch 5250\n",
            "time required: 782.31\n",
            "Processed batch 5260\n",
            "time required: 783.78\n",
            "Processed batch 5270\n",
            "time required: 785.24\n",
            "Processed batch 5280\n",
            "time required: 786.70\n",
            "Processed batch 5290\n",
            "time required: 788.17\n",
            "Processed batch 5300\n",
            "time required: 789.64\n",
            "Processed batch 5310\n",
            "time required: 791.11\n",
            "Processed batch 5320\n",
            "time required: 792.58\n",
            "Processed batch 5330\n",
            "time required: 794.05\n",
            "Processed batch 5340\n",
            "time required: 795.53\n",
            "Processed batch 5350\n",
            "time required: 797.01\n",
            "Processed batch 5360\n",
            "time required: 798.50\n",
            "Processed batch 5370\n",
            "time required: 799.97\n",
            "Processed batch 5380\n",
            "time required: 801.42\n",
            "Processed batch 5390\n",
            "time required: 802.89\n",
            "Processed batch 5400\n",
            "time required: 804.35\n",
            "Processed batch 5410\n",
            "time required: 805.82\n",
            "Processed batch 5420\n",
            "time required: 807.28\n",
            "Processed batch 5430\n",
            "time required: 808.76\n",
            "Processed batch 5440\n",
            "time required: 810.24\n",
            "Processed batch 5450\n",
            "time required: 811.72\n",
            "Processed batch 5460\n",
            "time required: 813.17\n",
            "Processed batch 5470\n",
            "time required: 814.64\n",
            "Processed batch 5480\n",
            "time required: 816.12\n",
            "Processed batch 5490\n",
            "time required: 817.59\n",
            "Processed batch 5500\n",
            "time required: 819.07\n",
            "Processed batch 5510\n",
            "time required: 820.54\n",
            "Processed batch 5520\n",
            "time required: 822.02\n",
            "Processed batch 5530\n",
            "time required: 823.49\n",
            "Processed batch 5540\n",
            "time required: 824.96\n",
            "Processed batch 5550\n",
            "time required: 826.43\n",
            "Processed batch 5560\n",
            "time required: 827.91\n",
            "Processed batch 5570\n",
            "time required: 829.39\n",
            "Processed batch 5580\n",
            "time required: 830.87\n",
            "Processed batch 5590\n",
            "time required: 832.34\n",
            "Processed batch 5600\n",
            "time required: 833.81\n",
            "Processed batch 5610\n",
            "time required: 835.28\n",
            "Processed batch 5620\n",
            "time required: 836.76\n",
            "Processed batch 5630\n",
            "time required: 838.23\n",
            "Processed batch 5640\n",
            "time required: 839.71\n",
            "Processed batch 5650\n",
            "time required: 841.17\n",
            "Processed batch 5660\n",
            "time required: 842.66\n",
            "Processed batch 5670\n",
            "time required: 844.13\n",
            "Processed batch 5680\n",
            "time required: 845.60\n",
            "Processed batch 5690\n",
            "time required: 847.07\n",
            "Processed batch 5700\n",
            "time required: 848.54\n",
            "Processed batch 5710\n",
            "time required: 850.00\n",
            "Processed batch 5720\n",
            "time required: 851.46\n",
            "Processed batch 5730\n",
            "time required: 852.96\n",
            "Processed batch 5740\n",
            "time required: 854.75\n",
            "Processed batch 5750\n",
            "time required: 856.55\n",
            "Processed batch 5760\n",
            "time required: 858.14\n",
            "Processed batch 5770\n",
            "time required: 859.63\n",
            "Processed batch 5780\n",
            "time required: 861.11\n",
            "Processed batch 5790\n",
            "time required: 862.58\n",
            "Processed batch 5800\n",
            "time required: 864.05\n",
            "Processed batch 5810\n",
            "time required: 865.51\n",
            "Processed batch 5820\n",
            "time required: 866.98\n",
            "Processed batch 5830\n",
            "time required: 868.45\n",
            "Processed batch 5840\n",
            "time required: 869.92\n",
            "Processed batch 5850\n",
            "time required: 871.39\n",
            "Processed batch 5860\n",
            "time required: 872.86\n",
            "Processed batch 5870\n",
            "time required: 874.32\n",
            "Processed batch 5880\n",
            "time required: 875.79\n",
            "Processed batch 5890\n",
            "time required: 877.26\n",
            "Processed batch 5900\n",
            "time required: 878.71\n",
            "Processed batch 5910\n",
            "time required: 880.17\n",
            "Processed batch 5920\n",
            "time required: 881.64\n",
            "Processed batch 5930\n",
            "time required: 883.12\n",
            "Processed batch 5940\n",
            "time required: 884.59\n",
            "Processed batch 5950\n",
            "time required: 886.05\n",
            "Processed batch 5960\n",
            "time required: 887.53\n",
            "Processed batch 5970\n",
            "time required: 889.00\n",
            "Processed batch 5980\n",
            "time required: 890.46\n",
            "Processed batch 5990\n",
            "time required: 891.93\n",
            "Processed batch 6000\n",
            "time required: 893.60\n",
            "Processed batch 6010\n",
            "time required: 895.06\n",
            "Processed batch 6020\n",
            "time required: 896.54\n",
            "Processed batch 6030\n",
            "time required: 898.00\n",
            "Processed batch 6040\n",
            "time required: 899.45\n",
            "Processed batch 6050\n",
            "time required: 900.92\n",
            "Processed batch 6060\n",
            "time required: 902.40\n",
            "Processed batch 6070\n",
            "time required: 903.92\n",
            "Processed batch 6080\n",
            "time required: 905.40\n",
            "Processed batch 6090\n",
            "time required: 906.87\n",
            "Processed batch 6100\n",
            "time required: 908.34\n",
            "Processed batch 6110\n",
            "time required: 909.81\n",
            "Processed batch 6120\n",
            "time required: 911.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 2/3 [30:38<15:17, 917.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.6896721124649048\n",
            "Processed batch 0\n",
            "time required: 0.37\n",
            "Processed batch 10\n",
            "time required: 1.85\n",
            "Processed batch 20\n",
            "time required: 3.33\n",
            "Processed batch 30\n",
            "time required: 4.81\n",
            "Processed batch 40\n",
            "time required: 6.28\n",
            "Processed batch 50\n",
            "time required: 7.75\n",
            "Processed batch 60\n",
            "time required: 9.24\n",
            "Processed batch 70\n",
            "time required: 10.74\n",
            "Processed batch 80\n",
            "time required: 12.23\n",
            "Processed batch 90\n",
            "time required: 13.69\n",
            "Processed batch 100\n",
            "time required: 15.15\n",
            "Processed batch 110\n",
            "time required: 16.60\n",
            "Processed batch 120\n",
            "time required: 18.08\n",
            "Processed batch 130\n",
            "time required: 19.53\n",
            "Processed batch 140\n",
            "time required: 21.01\n",
            "Processed batch 150\n",
            "time required: 22.47\n",
            "Processed batch 160\n",
            "time required: 23.95\n",
            "Processed batch 170\n",
            "time required: 25.43\n",
            "Processed batch 180\n",
            "time required: 26.89\n",
            "Processed batch 190\n",
            "time required: 28.36\n",
            "Processed batch 200\n",
            "time required: 29.84\n",
            "Processed batch 210\n",
            "time required: 31.31\n",
            "Processed batch 220\n",
            "time required: 32.77\n",
            "Processed batch 230\n",
            "time required: 34.24\n",
            "Processed batch 240\n",
            "time required: 35.72\n",
            "Processed batch 250\n",
            "time required: 37.20\n",
            "Processed batch 260\n",
            "time required: 38.68\n",
            "Processed batch 270\n",
            "time required: 40.15\n",
            "Processed batch 280\n",
            "time required: 41.62\n",
            "Processed batch 290\n",
            "time required: 43.08\n",
            "Processed batch 300\n",
            "time required: 44.56\n",
            "Processed batch 310\n",
            "time required: 46.03\n",
            "Processed batch 320\n",
            "time required: 47.50\n",
            "Processed batch 330\n",
            "time required: 48.97\n",
            "Processed batch 340\n",
            "time required: 50.43\n",
            "Processed batch 350\n",
            "time required: 51.90\n",
            "Processed batch 360\n",
            "time required: 53.37\n",
            "Processed batch 370\n",
            "time required: 54.85\n",
            "Processed batch 380\n",
            "time required: 56.31\n",
            "Processed batch 390\n",
            "time required: 57.78\n",
            "Processed batch 400\n",
            "time required: 59.24\n",
            "Processed batch 410\n",
            "time required: 60.71\n",
            "Processed batch 420\n",
            "time required: 62.17\n",
            "Processed batch 430\n",
            "time required: 63.63\n",
            "Processed batch 440\n",
            "time required: 65.10\n",
            "Processed batch 450\n",
            "time required: 66.57\n",
            "Processed batch 460\n",
            "time required: 68.05\n",
            "Processed batch 470\n",
            "time required: 69.52\n",
            "Processed batch 480\n",
            "time required: 71.01\n",
            "Processed batch 490\n",
            "time required: 72.47\n",
            "Processed batch 500\n",
            "time required: 73.94\n",
            "Processed batch 510\n",
            "time required: 75.40\n",
            "Processed batch 520\n",
            "time required: 76.87\n",
            "Processed batch 530\n",
            "time required: 78.34\n",
            "Processed batch 540\n",
            "time required: 79.82\n",
            "Processed batch 550\n",
            "time required: 81.31\n",
            "Processed batch 560\n",
            "time required: 82.78\n",
            "Processed batch 570\n",
            "time required: 84.25\n",
            "Processed batch 580\n",
            "time required: 85.73\n",
            "Processed batch 590\n",
            "time required: 87.19\n",
            "Processed batch 600\n",
            "time required: 88.67\n",
            "Processed batch 610\n",
            "time required: 90.14\n",
            "Processed batch 620\n",
            "time required: 91.59\n",
            "Processed batch 630\n",
            "time required: 93.05\n",
            "Processed batch 640\n",
            "time required: 94.53\n",
            "Processed batch 650\n",
            "time required: 95.99\n",
            "Processed batch 660\n",
            "time required: 97.47\n",
            "Processed batch 670\n",
            "time required: 98.94\n",
            "Processed batch 680\n",
            "time required: 100.41\n",
            "Processed batch 690\n",
            "time required: 101.88\n",
            "Processed batch 700\n",
            "time required: 103.36\n",
            "Processed batch 710\n",
            "time required: 104.82\n",
            "Processed batch 720\n",
            "time required: 106.29\n",
            "Processed batch 730\n",
            "time required: 107.75\n",
            "Processed batch 740\n",
            "time required: 109.22\n",
            "Processed batch 750\n",
            "time required: 110.69\n",
            "Processed batch 760\n",
            "time required: 112.17\n",
            "Processed batch 770\n",
            "time required: 113.63\n",
            "Processed batch 780\n",
            "time required: 115.12\n",
            "Processed batch 790\n",
            "time required: 116.59\n",
            "Processed batch 800\n",
            "time required: 118.06\n",
            "Processed batch 810\n",
            "time required: 119.53\n",
            "Processed batch 820\n",
            "time required: 120.99\n",
            "Processed batch 830\n",
            "time required: 122.46\n",
            "Processed batch 840\n",
            "time required: 124.07\n",
            "Processed batch 850\n",
            "time required: 125.83\n",
            "Processed batch 860\n",
            "time required: 127.64\n",
            "Processed batch 870\n",
            "time required: 129.13\n",
            "Processed batch 880\n",
            "time required: 130.58\n",
            "Processed batch 890\n",
            "time required: 132.05\n",
            "Processed batch 900\n",
            "time required: 133.50\n",
            "Processed batch 910\n",
            "time required: 134.96\n",
            "Processed batch 920\n",
            "time required: 136.43\n",
            "Processed batch 930\n",
            "time required: 137.91\n",
            "Processed batch 940\n",
            "time required: 139.38\n",
            "Processed batch 950\n",
            "time required: 140.85\n",
            "Processed batch 960\n",
            "time required: 142.33\n",
            "Processed batch 970\n",
            "time required: 143.80\n",
            "Processed batch 980\n",
            "time required: 145.30\n",
            "Processed batch 990\n",
            "time required: 146.76\n",
            "Processed batch 1000\n",
            "time required: 148.46\n",
            "Processed batch 1010\n",
            "time required: 149.95\n",
            "Processed batch 1020\n",
            "time required: 151.43\n",
            "Processed batch 1030\n",
            "time required: 152.90\n",
            "Processed batch 1040\n",
            "time required: 154.38\n",
            "Processed batch 1050\n",
            "time required: 155.84\n",
            "Processed batch 1060\n",
            "time required: 157.31\n",
            "Processed batch 1070\n",
            "time required: 158.79\n",
            "Processed batch 1080\n",
            "time required: 160.30\n",
            "Processed batch 1090\n",
            "time required: 161.77\n",
            "Processed batch 1100\n",
            "time required: 163.24\n",
            "Processed batch 1110\n",
            "time required: 164.71\n",
            "Processed batch 1120\n",
            "time required: 166.19\n",
            "Processed batch 1130\n",
            "time required: 167.67\n",
            "Processed batch 1140\n",
            "time required: 169.14\n",
            "Processed batch 1150\n",
            "time required: 170.61\n",
            "Processed batch 1160\n",
            "time required: 172.09\n",
            "Processed batch 1170\n",
            "time required: 173.57\n",
            "Processed batch 1180\n",
            "time required: 175.04\n",
            "Processed batch 1190\n",
            "time required: 176.52\n",
            "Processed batch 1200\n",
            "time required: 177.99\n",
            "Processed batch 1210\n",
            "time required: 179.45\n",
            "Processed batch 1220\n",
            "time required: 180.93\n",
            "Processed batch 1230\n",
            "time required: 182.40\n",
            "Processed batch 1240\n",
            "time required: 183.87\n",
            "Processed batch 1250\n",
            "time required: 185.35\n",
            "Processed batch 1260\n",
            "time required: 186.82\n",
            "Processed batch 1270\n",
            "time required: 188.29\n",
            "Processed batch 1280\n",
            "time required: 189.75\n",
            "Processed batch 1290\n",
            "time required: 191.23\n",
            "Processed batch 1300\n",
            "time required: 192.70\n",
            "Processed batch 1310\n",
            "time required: 194.19\n",
            "Processed batch 1320\n",
            "time required: 195.64\n",
            "Processed batch 1330\n",
            "time required: 197.10\n",
            "Processed batch 1340\n",
            "time required: 198.59\n",
            "Processed batch 1350\n",
            "time required: 200.06\n",
            "Processed batch 1360\n",
            "time required: 201.53\n",
            "Processed batch 1370\n",
            "time required: 203.01\n",
            "Processed batch 1380\n",
            "time required: 204.49\n",
            "Processed batch 1390\n",
            "time required: 205.97\n",
            "Processed batch 1400\n",
            "time required: 207.44\n",
            "Processed batch 1410\n",
            "time required: 208.90\n",
            "Processed batch 1420\n",
            "time required: 210.37\n",
            "Processed batch 1430\n",
            "time required: 211.84\n",
            "Processed batch 1440\n",
            "time required: 213.31\n",
            "Processed batch 1450\n",
            "time required: 214.78\n",
            "Processed batch 1460\n",
            "time required: 216.25\n",
            "Processed batch 1470\n",
            "time required: 217.75\n",
            "Processed batch 1480\n",
            "time required: 219.23\n",
            "Processed batch 1490\n",
            "time required: 220.71\n",
            "Processed batch 1500\n",
            "time required: 222.21\n",
            "Processed batch 1510\n",
            "time required: 223.70\n",
            "Processed batch 1520\n",
            "time required: 225.17\n",
            "Processed batch 1530\n",
            "time required: 226.63\n",
            "Processed batch 1540\n",
            "time required: 228.34\n",
            "Processed batch 1550\n",
            "time required: 230.11\n",
            "Processed batch 1560\n",
            "time required: 231.94\n",
            "Processed batch 1570\n",
            "time required: 233.72\n",
            "Processed batch 1580\n",
            "time required: 235.20\n",
            "Processed batch 1590\n",
            "time required: 236.68\n",
            "Processed batch 1600\n",
            "time required: 238.14\n",
            "Processed batch 1610\n",
            "time required: 239.61\n",
            "Processed batch 1620\n",
            "time required: 241.08\n",
            "Processed batch 1630\n",
            "time required: 242.54\n",
            "Processed batch 1640\n",
            "time required: 244.01\n",
            "Processed batch 1650\n",
            "time required: 245.48\n",
            "Processed batch 1660\n",
            "time required: 246.95\n",
            "Processed batch 1670\n",
            "time required: 248.42\n",
            "Processed batch 1680\n",
            "time required: 249.91\n",
            "Processed batch 1690\n",
            "time required: 251.38\n",
            "Processed batch 1700\n",
            "time required: 252.86\n",
            "Processed batch 1710\n",
            "time required: 254.34\n",
            "Processed batch 1720\n",
            "time required: 255.80\n",
            "Processed batch 1730\n",
            "time required: 257.27\n",
            "Processed batch 1740\n",
            "time required: 258.74\n",
            "Processed batch 1750\n",
            "time required: 260.21\n",
            "Processed batch 1760\n",
            "time required: 261.68\n",
            "Processed batch 1770\n",
            "time required: 263.14\n",
            "Processed batch 1780\n",
            "time required: 264.61\n",
            "Processed batch 1790\n",
            "time required: 266.08\n",
            "Processed batch 1800\n",
            "time required: 267.55\n",
            "Processed batch 1810\n",
            "time required: 269.02\n",
            "Processed batch 1820\n",
            "time required: 270.49\n",
            "Processed batch 1830\n",
            "time required: 271.96\n",
            "Processed batch 1840\n",
            "time required: 273.42\n",
            "Processed batch 1850\n",
            "time required: 274.88\n",
            "Processed batch 1860\n",
            "time required: 276.34\n",
            "Processed batch 1870\n",
            "time required: 277.82\n",
            "Processed batch 1880\n",
            "time required: 279.29\n",
            "Processed batch 1890\n",
            "time required: 280.78\n",
            "Processed batch 1900\n",
            "time required: 282.25\n",
            "Processed batch 1910\n",
            "time required: 283.72\n",
            "Processed batch 1920\n",
            "time required: 285.18\n",
            "Processed batch 1930\n",
            "time required: 286.65\n",
            "Processed batch 1940\n",
            "time required: 288.12\n",
            "Processed batch 1950\n",
            "time required: 289.59\n",
            "Processed batch 1960\n",
            "time required: 291.05\n",
            "Processed batch 1970\n",
            "time required: 292.52\n",
            "Processed batch 1980\n",
            "time required: 293.99\n",
            "Processed batch 1990\n",
            "time required: 295.45\n",
            "Processed batch 2000\n",
            "time required: 297.14\n",
            "Processed batch 2010\n",
            "time required: 298.60\n",
            "Processed batch 2020\n",
            "time required: 300.06\n",
            "Processed batch 2030\n",
            "time required: 301.54\n",
            "Processed batch 2040\n",
            "time required: 303.03\n",
            "Processed batch 2050\n",
            "time required: 304.55\n",
            "Processed batch 2060\n",
            "time required: 306.31\n",
            "Processed batch 2070\n",
            "time required: 308.20\n",
            "Processed batch 2080\n",
            "time required: 309.74\n",
            "Processed batch 2090\n",
            "time required: 311.21\n",
            "Processed batch 2100\n",
            "time required: 312.67\n",
            "Processed batch 2110\n",
            "time required: 314.15\n",
            "Processed batch 2120\n",
            "time required: 315.62\n",
            "Processed batch 2130\n",
            "time required: 317.08\n",
            "Processed batch 2140\n",
            "time required: 318.54\n",
            "Processed batch 2150\n",
            "time required: 320.00\n",
            "Processed batch 2160\n",
            "time required: 321.47\n",
            "Processed batch 2170\n",
            "time required: 322.93\n",
            "Processed batch 2180\n",
            "time required: 324.40\n",
            "Processed batch 2190\n",
            "time required: 325.88\n",
            "Processed batch 2200\n",
            "time required: 327.34\n",
            "Processed batch 2210\n",
            "time required: 328.80\n",
            "Processed batch 2220\n",
            "time required: 330.26\n",
            "Processed batch 2230\n",
            "time required: 331.74\n",
            "Processed batch 2240\n",
            "time required: 333.19\n",
            "Processed batch 2250\n",
            "time required: 334.67\n",
            "Processed batch 2260\n",
            "time required: 336.14\n",
            "Processed batch 2270\n",
            "time required: 337.60\n",
            "Processed batch 2280\n",
            "time required: 339.07\n",
            "Processed batch 2290\n",
            "time required: 340.52\n",
            "Processed batch 2300\n",
            "time required: 341.98\n",
            "Processed batch 2310\n",
            "time required: 343.46\n",
            "Processed batch 2320\n",
            "time required: 344.95\n",
            "Processed batch 2330\n",
            "time required: 346.42\n",
            "Processed batch 2340\n",
            "time required: 347.88\n",
            "Processed batch 2350\n",
            "time required: 349.35\n",
            "Processed batch 2360\n",
            "time required: 350.82\n",
            "Processed batch 2370\n",
            "time required: 352.29\n",
            "Processed batch 2380\n",
            "time required: 353.75\n",
            "Processed batch 2390\n",
            "time required: 355.23\n",
            "Processed batch 2400\n",
            "time required: 356.69\n",
            "Processed batch 2410\n",
            "time required: 358.17\n",
            "Processed batch 2420\n",
            "time required: 359.63\n",
            "Processed batch 2430\n",
            "time required: 361.10\n",
            "Processed batch 2440\n",
            "time required: 362.57\n",
            "Processed batch 2450\n",
            "time required: 364.04\n",
            "Processed batch 2460\n",
            "time required: 365.50\n",
            "Processed batch 2470\n",
            "time required: 366.95\n",
            "Processed batch 2480\n",
            "time required: 368.42\n",
            "Processed batch 2490\n",
            "time required: 369.88\n",
            "Processed batch 2500\n",
            "time required: 371.35\n",
            "Processed batch 2510\n",
            "time required: 372.80\n",
            "Processed batch 2520\n",
            "time required: 374.28\n",
            "Processed batch 2530\n",
            "time required: 375.75\n",
            "Processed batch 2540\n",
            "time required: 377.22\n",
            "Processed batch 2550\n",
            "time required: 378.69\n",
            "Processed batch 2560\n",
            "time required: 380.16\n",
            "Processed batch 2570\n",
            "time required: 381.64\n",
            "Processed batch 2580\n",
            "time required: 383.11\n",
            "Processed batch 2590\n",
            "time required: 384.58\n",
            "Processed batch 2600\n",
            "time required: 386.04\n",
            "Processed batch 2610\n",
            "time required: 387.50\n",
            "Processed batch 2620\n",
            "time required: 388.97\n",
            "Processed batch 2630\n",
            "time required: 390.43\n",
            "Processed batch 2640\n",
            "time required: 391.89\n",
            "Processed batch 2650\n",
            "time required: 393.35\n",
            "Processed batch 2660\n",
            "time required: 394.82\n",
            "Processed batch 2670\n",
            "time required: 396.29\n",
            "Processed batch 2680\n",
            "time required: 397.76\n",
            "Processed batch 2690\n",
            "time required: 399.22\n",
            "Processed batch 2700\n",
            "time required: 400.69\n",
            "Processed batch 2710\n",
            "time required: 402.17\n",
            "Processed batch 2720\n",
            "time required: 403.63\n",
            "Processed batch 2730\n",
            "time required: 405.10\n",
            "Processed batch 2740\n",
            "time required: 406.56\n",
            "Processed batch 2750\n",
            "time required: 408.02\n",
            "Processed batch 2760\n",
            "time required: 409.48\n",
            "Processed batch 2770\n",
            "time required: 410.95\n",
            "Processed batch 2780\n",
            "time required: 412.42\n",
            "Processed batch 2790\n",
            "time required: 413.88\n",
            "Processed batch 2800\n",
            "time required: 415.35\n",
            "Processed batch 2810\n",
            "time required: 416.83\n",
            "Processed batch 2820\n",
            "time required: 418.30\n",
            "Processed batch 2830\n",
            "time required: 419.77\n",
            "Processed batch 2840\n",
            "time required: 421.23\n",
            "Processed batch 2850\n",
            "time required: 422.69\n",
            "Processed batch 2860\n",
            "time required: 424.16\n",
            "Processed batch 2870\n",
            "time required: 425.60\n",
            "Processed batch 2880\n",
            "time required: 427.06\n",
            "Processed batch 2890\n",
            "time required: 428.54\n",
            "Processed batch 2900\n",
            "time required: 430.01\n",
            "Processed batch 2910\n",
            "time required: 431.47\n",
            "Processed batch 2920\n",
            "time required: 432.93\n",
            "Processed batch 2930\n",
            "time required: 434.38\n",
            "Processed batch 2940\n",
            "time required: 435.87\n",
            "Processed batch 2950\n",
            "time required: 437.31\n",
            "Processed batch 2960\n",
            "time required: 438.77\n",
            "Processed batch 2970\n",
            "time required: 440.23\n",
            "Processed batch 2980\n",
            "time required: 441.69\n",
            "Processed batch 2990\n",
            "time required: 443.18\n",
            "Processed batch 3000\n",
            "time required: 444.85\n",
            "Processed batch 3010\n",
            "time required: 446.33\n",
            "Processed batch 3020\n",
            "time required: 447.80\n",
            "Processed batch 3030\n",
            "time required: 449.28\n",
            "Processed batch 3040\n",
            "time required: 450.73\n",
            "Processed batch 3050\n",
            "time required: 452.20\n",
            "Processed batch 3060\n",
            "time required: 453.66\n",
            "Processed batch 3070\n",
            "time required: 455.15\n",
            "Processed batch 3080\n",
            "time required: 456.65\n",
            "Processed batch 3090\n",
            "time required: 458.14\n",
            "Processed batch 3100\n",
            "time required: 459.61\n",
            "Processed batch 3110\n",
            "time required: 461.07\n",
            "Processed batch 3120\n",
            "time required: 462.53\n",
            "Processed batch 3130\n",
            "time required: 463.99\n",
            "Processed batch 3140\n",
            "time required: 465.47\n",
            "Processed batch 3150\n",
            "time required: 466.93\n",
            "Processed batch 3160\n",
            "time required: 468.40\n",
            "Processed batch 3170\n",
            "time required: 469.86\n",
            "Processed batch 3180\n",
            "time required: 471.33\n",
            "Processed batch 3190\n",
            "time required: 472.78\n",
            "Processed batch 3200\n",
            "time required: 474.24\n",
            "Processed batch 3210\n",
            "time required: 475.72\n",
            "Processed batch 3220\n",
            "time required: 477.21\n",
            "Processed batch 3230\n",
            "time required: 478.69\n",
            "Processed batch 3240\n",
            "time required: 480.13\n",
            "Processed batch 3250\n",
            "time required: 481.60\n",
            "Processed batch 3260\n",
            "time required: 483.07\n",
            "Processed batch 3270\n",
            "time required: 484.54\n",
            "Processed batch 3280\n",
            "time required: 486.27\n",
            "Processed batch 3290\n",
            "time required: 488.01\n",
            "Processed batch 3300\n",
            "time required: 489.65\n",
            "Processed batch 3310\n",
            "time required: 491.12\n",
            "Processed batch 3320\n",
            "time required: 492.58\n",
            "Processed batch 3330\n",
            "time required: 494.03\n",
            "Processed batch 3340\n",
            "time required: 495.50\n",
            "Processed batch 3350\n",
            "time required: 496.99\n",
            "Processed batch 3360\n",
            "time required: 498.46\n",
            "Processed batch 3370\n",
            "time required: 499.93\n",
            "Processed batch 3380\n",
            "time required: 501.39\n",
            "Processed batch 3390\n",
            "time required: 502.87\n",
            "Processed batch 3400\n",
            "time required: 504.34\n",
            "Processed batch 3410\n",
            "time required: 505.79\n",
            "Processed batch 3420\n",
            "time required: 507.26\n",
            "Processed batch 3430\n",
            "time required: 508.73\n",
            "Processed batch 3440\n",
            "time required: 510.18\n",
            "Processed batch 3450\n",
            "time required: 511.63\n",
            "Processed batch 3460\n",
            "time required: 513.10\n",
            "Processed batch 3470\n",
            "time required: 514.55\n",
            "Processed batch 3480\n",
            "time required: 516.03\n",
            "Processed batch 3490\n",
            "time required: 517.48\n",
            "Processed batch 3500\n",
            "time required: 518.95\n",
            "Processed batch 3510\n",
            "time required: 520.41\n",
            "Processed batch 3520\n",
            "time required: 521.88\n",
            "Processed batch 3530\n",
            "time required: 523.35\n",
            "Processed batch 3540\n",
            "time required: 524.81\n",
            "Processed batch 3550\n",
            "time required: 526.30\n",
            "Processed batch 3560\n",
            "time required: 527.77\n",
            "Processed batch 3570\n",
            "time required: 529.23\n",
            "Processed batch 3580\n",
            "time required: 530.70\n",
            "Processed batch 3590\n",
            "time required: 532.13\n",
            "Processed batch 3600\n",
            "time required: 533.58\n",
            "Processed batch 3610\n",
            "time required: 535.04\n",
            "Processed batch 3620\n",
            "time required: 536.50\n",
            "Processed batch 3630\n",
            "time required: 537.97\n",
            "Processed batch 3640\n",
            "time required: 539.46\n",
            "Processed batch 3650\n",
            "time required: 540.93\n",
            "Processed batch 3660\n",
            "time required: 542.39\n",
            "Processed batch 3670\n",
            "time required: 543.85\n",
            "Processed batch 3680\n",
            "time required: 545.32\n",
            "Processed batch 3690\n",
            "time required: 546.78\n",
            "Processed batch 3700\n",
            "time required: 548.26\n",
            "Processed batch 3710\n",
            "time required: 549.72\n",
            "Processed batch 3720\n",
            "time required: 551.17\n",
            "Processed batch 3730\n",
            "time required: 552.64\n",
            "Processed batch 3740\n",
            "time required: 554.08\n",
            "Processed batch 3750\n",
            "time required: 555.55\n",
            "Processed batch 3760\n",
            "time required: 557.01\n",
            "Processed batch 3770\n",
            "time required: 558.48\n",
            "Processed batch 3780\n",
            "time required: 559.94\n",
            "Processed batch 3790\n",
            "time required: 561.41\n",
            "Processed batch 3800\n",
            "time required: 562.88\n",
            "Processed batch 3810\n",
            "time required: 564.34\n",
            "Processed batch 3820\n",
            "time required: 565.82\n",
            "Processed batch 3830\n",
            "time required: 567.28\n",
            "Processed batch 3840\n",
            "time required: 568.73\n",
            "Processed batch 3850\n",
            "time required: 570.20\n",
            "Processed batch 3860\n",
            "time required: 571.66\n",
            "Processed batch 3870\n",
            "time required: 573.13\n",
            "Processed batch 3880\n",
            "time required: 574.59\n",
            "Processed batch 3890\n",
            "time required: 576.05\n",
            "Processed batch 3900\n",
            "time required: 577.52\n",
            "Processed batch 3910\n",
            "time required: 578.98\n",
            "Processed batch 3920\n",
            "time required: 580.44\n",
            "Processed batch 3930\n",
            "time required: 581.89\n",
            "Processed batch 3940\n",
            "time required: 583.36\n",
            "Processed batch 3950\n",
            "time required: 584.83\n",
            "Processed batch 3960\n",
            "time required: 586.31\n",
            "Processed batch 3970\n",
            "time required: 587.77\n",
            "Processed batch 3980\n",
            "time required: 589.25\n",
            "Processed batch 3990\n",
            "time required: 590.73\n",
            "Processed batch 4000\n",
            "time required: 592.40\n",
            "Processed batch 4010\n",
            "time required: 593.85\n",
            "Processed batch 4020\n",
            "time required: 595.33\n",
            "Processed batch 4030\n",
            "time required: 596.82\n",
            "Processed batch 4040\n",
            "time required: 598.28\n",
            "Processed batch 4050\n",
            "time required: 599.76\n",
            "Processed batch 4060\n",
            "time required: 601.22\n",
            "Processed batch 4070\n",
            "time required: 602.71\n",
            "Processed batch 4080\n",
            "time required: 604.20\n",
            "Processed batch 4090\n",
            "time required: 605.69\n",
            "Processed batch 4100\n",
            "time required: 607.17\n",
            "Processed batch 4110\n",
            "time required: 608.64\n",
            "Processed batch 4120\n",
            "time required: 610.12\n",
            "Processed batch 4130\n",
            "time required: 611.58\n",
            "Processed batch 4140\n",
            "time required: 613.05\n",
            "Processed batch 4150\n",
            "time required: 614.52\n",
            "Processed batch 4160\n",
            "time required: 616.00\n",
            "Processed batch 4170\n",
            "time required: 617.47\n",
            "Processed batch 4180\n",
            "time required: 618.95\n",
            "Processed batch 4190\n",
            "time required: 620.40\n",
            "Processed batch 4200\n",
            "time required: 621.87\n",
            "Processed batch 4210\n",
            "time required: 623.32\n",
            "Processed batch 4220\n",
            "time required: 624.78\n",
            "Processed batch 4230\n",
            "time required: 626.24\n",
            "Processed batch 4240\n",
            "time required: 627.71\n",
            "Processed batch 4250\n",
            "time required: 629.17\n",
            "Processed batch 4260\n",
            "time required: 630.64\n",
            "Processed batch 4270\n",
            "time required: 632.11\n",
            "Processed batch 4280\n",
            "time required: 633.57\n",
            "Processed batch 4290\n",
            "time required: 635.05\n",
            "Processed batch 4300\n",
            "time required: 636.51\n",
            "Processed batch 4310\n",
            "time required: 637.99\n",
            "Processed batch 4320\n",
            "time required: 639.44\n",
            "Processed batch 4330\n",
            "time required: 640.92\n",
            "Processed batch 4340\n",
            "time required: 642.38\n",
            "Processed batch 4350\n",
            "time required: 643.85\n",
            "Processed batch 4360\n",
            "time required: 645.32\n",
            "Processed batch 4370\n",
            "time required: 646.79\n",
            "Processed batch 4380\n",
            "time required: 648.26\n",
            "Processed batch 4390\n",
            "time required: 649.74\n",
            "Processed batch 4400\n",
            "time required: 651.22\n",
            "Processed batch 4410\n",
            "time required: 652.68\n",
            "Processed batch 4420\n",
            "time required: 654.15\n",
            "Processed batch 4430\n",
            "time required: 655.62\n",
            "Processed batch 4440\n",
            "time required: 657.07\n",
            "Processed batch 4450\n",
            "time required: 658.54\n",
            "Processed batch 4460\n",
            "time required: 660.03\n",
            "Processed batch 4470\n",
            "time required: 661.53\n",
            "Processed batch 4480\n",
            "time required: 663.27\n",
            "Processed batch 4490\n",
            "time required: 665.04\n",
            "Processed batch 4500\n",
            "time required: 666.61\n",
            "Processed batch 4510\n",
            "time required: 668.08\n",
            "Processed batch 4520\n",
            "time required: 669.53\n",
            "Processed batch 4530\n",
            "time required: 671.00\n",
            "Processed batch 4540\n",
            "time required: 672.45\n",
            "Processed batch 4550\n",
            "time required: 673.92\n",
            "Processed batch 4560\n",
            "time required: 675.38\n",
            "Processed batch 4570\n",
            "time required: 676.83\n",
            "Processed batch 4580\n",
            "time required: 678.28\n",
            "Processed batch 4590\n",
            "time required: 679.74\n",
            "Processed batch 4600\n",
            "time required: 681.19\n",
            "Processed batch 4610\n",
            "time required: 682.66\n",
            "Processed batch 4620\n",
            "time required: 684.14\n",
            "Processed batch 4630\n",
            "time required: 685.61\n",
            "Processed batch 4640\n",
            "time required: 687.08\n",
            "Processed batch 4650\n",
            "time required: 688.55\n",
            "Processed batch 4660\n",
            "time required: 690.02\n",
            "Processed batch 4670\n",
            "time required: 691.48\n",
            "Processed batch 4680\n",
            "time required: 692.96\n",
            "Processed batch 4690\n",
            "time required: 694.43\n",
            "Processed batch 4700\n",
            "time required: 695.88\n",
            "Processed batch 4710\n",
            "time required: 697.34\n",
            "Processed batch 4720\n",
            "time required: 698.79\n",
            "Processed batch 4730\n",
            "time required: 700.25\n",
            "Processed batch 4740\n",
            "time required: 701.72\n",
            "Processed batch 4750\n",
            "time required: 703.18\n",
            "Processed batch 4760\n",
            "time required: 704.64\n",
            "Processed batch 4770\n",
            "time required: 706.10\n",
            "Processed batch 4780\n",
            "time required: 707.55\n",
            "Processed batch 4790\n",
            "time required: 709.03\n",
            "Processed batch 4800\n",
            "time required: 710.50\n",
            "Processed batch 4810\n",
            "time required: 711.98\n",
            "Processed batch 4820\n",
            "time required: 713.45\n",
            "Processed batch 4830\n",
            "time required: 714.91\n",
            "Processed batch 4840\n",
            "time required: 716.37\n",
            "Processed batch 4850\n",
            "time required: 717.83\n",
            "Processed batch 4860\n",
            "time required: 719.31\n",
            "Processed batch 4870\n",
            "time required: 720.78\n",
            "Processed batch 4880\n",
            "time required: 722.25\n",
            "Processed batch 4890\n",
            "time required: 723.73\n",
            "Processed batch 4900\n",
            "time required: 725.20\n",
            "Processed batch 4910\n",
            "time required: 726.66\n",
            "Processed batch 4920\n",
            "time required: 728.12\n",
            "Processed batch 4930\n",
            "time required: 729.59\n",
            "Processed batch 4940\n",
            "time required: 731.06\n",
            "Processed batch 4950\n",
            "time required: 732.53\n",
            "Processed batch 4960\n",
            "time required: 733.99\n",
            "Processed batch 4970\n",
            "time required: 735.46\n",
            "Processed batch 4980\n",
            "time required: 736.91\n",
            "Processed batch 4990\n",
            "time required: 738.37\n",
            "Processed batch 5000\n",
            "time required: 740.02\n",
            "Processed batch 5010\n",
            "time required: 741.48\n",
            "Processed batch 5020\n",
            "time required: 742.96\n",
            "Processed batch 5030\n",
            "time required: 744.43\n",
            "Processed batch 5040\n",
            "time required: 745.90\n",
            "Processed batch 5050\n",
            "time required: 747.37\n",
            "Processed batch 5060\n",
            "time required: 748.86\n",
            "Processed batch 5070\n",
            "time required: 750.35\n",
            "Processed batch 5080\n",
            "time required: 751.85\n",
            "Processed batch 5090\n",
            "time required: 753.30\n",
            "Processed batch 5100\n",
            "time required: 754.75\n",
            "Processed batch 5110\n",
            "time required: 756.20\n",
            "Processed batch 5120\n",
            "time required: 757.67\n",
            "Processed batch 5130\n",
            "time required: 759.14\n",
            "Processed batch 5140\n",
            "time required: 760.60\n",
            "Processed batch 5150\n",
            "time required: 762.05\n",
            "Processed batch 5160\n",
            "time required: 763.50\n",
            "Processed batch 5170\n",
            "time required: 764.97\n",
            "Processed batch 5180\n",
            "time required: 766.43\n",
            "Processed batch 5190\n",
            "time required: 767.90\n",
            "Processed batch 5200\n",
            "time required: 769.37\n",
            "Processed batch 5210\n",
            "time required: 770.86\n",
            "Processed batch 5220\n",
            "time required: 772.34\n",
            "Processed batch 5230\n",
            "time required: 773.80\n",
            "Processed batch 5240\n",
            "time required: 775.26\n",
            "Processed batch 5250\n",
            "time required: 776.73\n",
            "Processed batch 5260\n",
            "time required: 778.19\n",
            "Processed batch 5270\n",
            "time required: 779.65\n",
            "Processed batch 5280\n",
            "time required: 781.10\n",
            "Processed batch 5290\n",
            "time required: 782.57\n",
            "Processed batch 5300\n",
            "time required: 784.02\n",
            "Processed batch 5310\n",
            "time required: 785.48\n",
            "Processed batch 5320\n",
            "time required: 786.95\n",
            "Processed batch 5330\n",
            "time required: 788.41\n",
            "Processed batch 5340\n",
            "time required: 789.87\n",
            "Processed batch 5350\n",
            "time required: 791.33\n",
            "Processed batch 5360\n",
            "time required: 792.78\n",
            "Processed batch 5370\n",
            "time required: 794.26\n",
            "Processed batch 5380\n",
            "time required: 795.71\n",
            "Processed batch 5390\n",
            "time required: 797.19\n",
            "Processed batch 5400\n",
            "time required: 798.67\n",
            "Processed batch 5410\n",
            "time required: 800.16\n",
            "Processed batch 5420\n",
            "time required: 801.65\n",
            "Processed batch 5430\n",
            "time required: 803.14\n",
            "Processed batch 5440\n",
            "time required: 804.61\n",
            "Processed batch 5450\n",
            "time required: 806.09\n",
            "Processed batch 5460\n",
            "time required: 807.55\n",
            "Processed batch 5470\n",
            "time required: 809.02\n",
            "Processed batch 5480\n",
            "time required: 810.49\n",
            "Processed batch 5490\n",
            "time required: 811.96\n",
            "Processed batch 5500\n",
            "time required: 813.41\n",
            "Processed batch 5510\n",
            "time required: 814.89\n",
            "Processed batch 5520\n",
            "time required: 816.36\n",
            "Processed batch 5530\n",
            "time required: 817.86\n",
            "Processed batch 5540\n",
            "time required: 819.33\n",
            "Processed batch 5550\n",
            "time required: 820.84\n",
            "Processed batch 5560\n",
            "time required: 822.34\n",
            "Processed batch 5570\n",
            "time required: 823.83\n",
            "Processed batch 5580\n",
            "time required: 825.32\n",
            "Processed batch 5590\n",
            "time required: 826.81\n",
            "Processed batch 5600\n",
            "time required: 828.31\n",
            "Processed batch 5610\n",
            "time required: 829.82\n",
            "Processed batch 5620\n",
            "time required: 831.28\n",
            "Processed batch 5630\n",
            "time required: 832.78\n",
            "Processed batch 5640\n",
            "time required: 834.24\n",
            "Processed batch 5650\n",
            "time required: 835.72\n",
            "Processed batch 5660\n",
            "time required: 837.20\n",
            "Processed batch 5670\n",
            "time required: 838.69\n",
            "Processed batch 5680\n",
            "time required: 840.25\n",
            "Processed batch 5690\n",
            "time required: 841.97\n",
            "Processed batch 5700\n",
            "time required: 843.74\n",
            "Processed batch 5710\n",
            "time required: 845.26\n",
            "Processed batch 5720\n",
            "time required: 846.72\n",
            "Processed batch 5730\n",
            "time required: 848.20\n",
            "Processed batch 5750\n",
            "time required: 851.12\n",
            "Processed batch 5760\n",
            "time required: 852.58\n",
            "Processed batch 5770\n",
            "time required: 854.05\n",
            "Processed batch 5780\n",
            "time required: 855.52\n",
            "Processed batch 5790\n",
            "time required: 856.99\n",
            "Processed batch 5800\n",
            "time required: 858.44\n",
            "Processed batch 5810\n",
            "time required: 859.90\n",
            "Processed batch 5820\n",
            "time required: 861.37\n",
            "Processed batch 5830\n",
            "time required: 862.86\n",
            "Processed batch 5840\n",
            "time required: 864.33\n",
            "Processed batch 5850\n",
            "time required: 865.80\n",
            "Processed batch 5860\n",
            "time required: 867.26\n",
            "Processed batch 5870\n",
            "time required: 868.73\n",
            "Processed batch 5880\n",
            "time required: 870.19\n",
            "Processed batch 5890\n",
            "time required: 871.67\n",
            "Processed batch 5900\n",
            "time required: 873.14\n",
            "Processed batch 5910\n",
            "time required: 874.61\n",
            "Processed batch 5920\n",
            "time required: 876.06\n",
            "Processed batch 5930\n",
            "time required: 877.51\n",
            "Processed batch 5940\n",
            "time required: 878.96\n",
            "Processed batch 5950\n",
            "time required: 880.43\n",
            "Processed batch 5960\n",
            "time required: 881.90\n",
            "Processed batch 5970\n",
            "time required: 883.34\n",
            "Processed batch 5980\n",
            "time required: 884.81\n",
            "Processed batch 5990\n",
            "time required: 886.27\n",
            "Processed batch 6000\n",
            "time required: 887.96\n",
            "Processed batch 6010\n",
            "time required: 889.43\n",
            "Processed batch 6020\n",
            "time required: 890.89\n",
            "Processed batch 6030\n",
            "time required: 892.37\n",
            "Processed batch 6040\n",
            "time required: 893.84\n",
            "Processed batch 6050\n",
            "time required: 895.31\n",
            "Processed batch 6060\n",
            "time required: 896.77\n",
            "Processed batch 6070\n",
            "time required: 898.26\n",
            "Processed batch 6080\n",
            "time required: 899.74\n",
            "Processed batch 6090\n",
            "time required: 901.21\n",
            "Processed batch 6100\n",
            "time required: 902.66\n",
            "Processed batch 6110\n",
            "time required: 904.13\n",
            "Processed batch 6120\n",
            "time required: 905.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [45:44<00:00, 914.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current mean 0.6424106359481812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./gdrive/MyDrive/ckpt/ckpt_final-22'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checkpoint.restore(checkpoint_prefix + \"_final-23\")"
      ],
      "metadata": {
        "id": "1oNmAxBvSVuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a471d9e2-f34c-4388-88c1-c57d74d7ebba"
      },
      "id": "1oNmAxBvSVuH",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f348daf62e0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = Dataset.from_dict({\"xqa\": XQA_val, \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_val], \"id_placeholder\": list(range(len(YQA_val)))})\n",
        "\n",
        "\n",
        "val_ds = val_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "\n",
        "val_ds = val_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "val_ds = val_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "print(val_ds[0])\n",
        "train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6ccb93966e704a42a33c7789296685b6",
            "0351181e985d4815ba00f0566a9caa15",
            "087b8237bf42460db350fde7628911c7",
            "cd1d98b150e84567bff96cbae651bbb9",
            "f6ca08e1a4554f4e8e2c1e732c7f6be2",
            "df7bd931f7db4562b44ffcc2933bcdaa",
            "2b15a18be6b742428012d27b99bf08fd",
            "2a9dc4ceda9249c88118cbbbdc87509c",
            "8d7a469364834edc88d3dde4f66a0a14",
            "4a5cde1f19f54bde975e5ad7ef84b268",
            "ca90863b168a406a83b8adafa994a182",
            "96f69d601b8347f0984dea8632933dee",
            "5a1c04b36c4b4d24bb0bdb06e872769e",
            "22afdb08ecd042b29c85da73da896642",
            "23a1a4722eae45b3b3cec17de375a579",
            "adaaefa8ea284bc6906a79128530323c",
            "c60bf46d3a8a4ee5ba776de49387adc9",
            "d7d9fc2d5a0444f0a83b0462beb3eb11",
            "26dc561bf9f9475a9d5f876834033bed",
            "95c7cfad4b6f4b9fb39089ad2d52f0d6",
            "400475daa1224c719387431c0799a1cd",
            "f2d4f9f7012b40d59f7fa44e80825a18"
          ]
        },
        "id": "b9VyzKdnAuKz",
        "outputId": "f98a79fb-5a69-423b-9a05-19364cf476ea"
      },
      "id": "b9VyzKdnAuKz",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ccb93966e704a42a33c7789296685b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/21479 [00:00<?, ?ex/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96f69d601b8347f0984dea8632933dee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([  101,  2040,  2001,  2652,  1999,  1996,  2208,  1029,   102,\n",
            "        1006, 13229,  1007,  1011,  1011,  5557, 10767,  3195,  3807,\n",
            "        1010,  2010,  2034,  3289,  2005,  6220,  1010,  2000,  2393,\n",
            "        2010,  2252, 18579,  4154,  5087,  2103,  1017,  1011,  1014,\n",
            "        1999,  6928,  1005,  1055,  4239,  2223,  8087,  2012,  2019,\n",
            "        3790,  1012,  2103,  1010,  2040,  2734,  1037,  3377,  2000,\n",
            "        2693,  2682,  9295,  2046,  2353,  2173,  1999,  1996,  2795,\n",
            "        1010,  2020, 10676,  2185,  2011,  1037, 14886,  2034,  2431,\n",
            "        2836,  2013,  6220,  1010,  2040,  2031, 10495,  4369,  2597,\n",
            "        2007,  2023,  2765,  1012,  6220,  2211, 14224,  1998,  3053,\n",
            "        2165,  1037,  5066,  1011,  3371,  2599,  2043,  6446, 22551,\n",
            "        1005,  1055,  2986,  4894,  2001, 11182,  3031,  1996,  2695,\n",
            "        2011,  2103,  1005,  1055,  2563,  9653,  3533,  7530,  1012,\n",
            "        2021,  1996,  5873,  3639,  2001,  8084,  2000, 11997,  2007,\n",
            "        6220,  1005,  1055,  4400,  1997,  4491,  1998,  1996,  6184,\n",
            "        2165,  1037, 10849,  2599,  2416,  2781,  2101,  2043, 10767,\n",
            "        1005,  1055, 21688,  2135,  4930,  2187,  1011, 28856,  4894,\n",
            "        1010,  2013,  2074,  2648,  1996,  2181,  1010, 25430, 25944,\n",
            "        2627,  7530,  2005,  2010,  2034,  3125,  2144,  5241,  1996,\n",
            "        2252,  2005,  1037,  2329,  2501,  4651,  7408,  1999,  2254,\n",
            "        1012,  6220, 11515,  2037,  2599,  1999,  1996, 20460,  3371,\n",
            "        2043,  2103,  3478,  2000,  3154,  1037,  8338,  1997,  7821,\n",
            "        1998,  8534,  7171,  1010,  1996,  3608,  2776,  4634,  2000,\n",
            "        1996,  2519,  1997, 17594, 13970, 22123,  2040,  5045,  2083,\n",
            "        1996,  3456,  1997,  8291,  3656, 12849,  8017,  4492,  1998,\n",
            "        2627,  7530,  1012,  6220,  2081,  2009,  1017,  1011,  1014,\n",
            "        1037,  3371,  2101,  2043, 16720, 19734, 16570,  2229,  8188,\n",
            "        1999,  2019, 15085,  2892,  2013,  1996,  2187,  2005, 10767,\n",
            "        2000,  2041,  9103,  8737, 12849,  8017,  4492,  1998,  2393,\n",
            "        1996,  3608,  2046,  1996,  2521,  3420,  1997,  1996,  5658,\n",
            "        1012,  6220,  2018,  9592,  2000,  3623,  2037,  2599,  2044,\n",
            "        1996,  3338,  2021,  7530,  2106,  2092,  2000,  2562,  2041,\n",
            "        4073,  2013, 19734, 16570,  2229,  1998, 13970, 22123,  1010,\n",
            "        2096, 22551,  5045,  2898,  2013,  2019, 11325,  6466,  1998,\n",
            "       10767,  3753,  2058,  1996,  2892,  8237,  2013,  1037,  2204,\n",
            "        2597,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "           0,     0,     0,     0,     0,     0,     0,     0])>, 'token_type_ids': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0])>, 'attention_mask': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0])>, 'references': {'answers': {'answer_start': [42], 'text': ['<start> the team from Liverpool <end>']}, 'id': '0'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "\n",
        "generated = trainer.generate(output_tokenizer=output_tokenizer, \n",
        "                                input_ids=val_ds[\"input_ids\"][128:256],\n",
        "                                attention_mask=val_ds[\"attention_mask\"][128:256])\n",
        "translated = trainer.translate(generated, output_tokenizer=output_tokenizer)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Cs1G8M-VIjFF"
      },
      "id": "Cs1G8M-VIjFF",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [{'prediction_text': translated[i], 'id':str(i)} for i in range(128)]\n",
        "for i in translated:\n",
        "  if i != '<end>': \n",
        "    print(translated)"
      ],
      "metadata": {
        "id": "g_Q4mJbLSuPm"
      },
      "id": "g_Q4mJbLSuPm",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "squad_metric = load(\"squad\")\n",
        "#predictions = [{'prediction_text': \"<start> porco dio <end>\", 'id': '0'}]\n",
        "references = val_ds[0:128]['references']\n",
        "results = squad_metric.compute(predictions=predictions, references=references)\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMscJ7FcSsxF",
        "outputId": "d45edff2-0d98-4e67-d799-2d41989630cc"
      },
      "id": "JMscJ7FcSsxF",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 0.0, 'f1': 39.30943108883074}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This was tested with:\n",
        "tensorflow==2.6\n",
        "tensorflow-gpu==2.6\n",
        "tensorflow-addons==0.16.1\n",
        "transformers==4.18.0\n",
        "Keras==2.6.0\n",
        "\n",
        "Note 1: Simple adaptation of tf_seq2seq_lstm.py script\n",
        "Note 2: make sure Keras and Tensorflow versions match!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "class ModelTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_output_length = max_output_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['encoder_input_ids'],\n",
        "                                                                 'attention_mask': inputs['encoder_attention_mask']})\n",
        "\n",
        "            decoder_input = inputs['decoder_target'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['decoder_target'][:, 1:]  # ignore <start>\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, input_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0]\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask\n",
        "        })\n",
        "\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler()\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_output_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True)\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        model_output = self.model(inputs)\n",
        "        all_outputs = model_output[0]\n",
        "        pooled_output = model_output[1]\n",
        "        pooled_output = self.reducer(pooled_output)\n",
        "        return all_outputs, pooled_output, pooled_output\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units)\n",
        "\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state)\n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #model_name = 'distilroberta-base'\n",
        "    model_name = 'prajjwal1/bert-tiny'\n",
        "\n",
        "    # tf.config.run_functions_eagerly(True)\n",
        "\n",
        "    # Sample\n",
        "    batch_size = 16\n",
        "    input_sample = XQA_train[:33]\n",
        "    output_sample = [ \"<start> \" + ans + \" <end>\" for ans in YQA_train[:33]]\n",
        "    print(output_sample)\n",
        "#     [\n",
        "#        \"hello there how is it going\",\n",
        "#        \"this assignment is hellish\",\n",
        "#        \"how are you\",\n",
        "#        \"what's your name Antonio?\"\n",
        "#    ]\n",
        "#    [\n",
        "#        \"<start> it is going well <end>\",\n",
        "#        \"<start> I agree <end>\",\n",
        "#        \"<start> I'm fine, thanks <end>\",\n",
        "#        \"<start> gnome <end>\"\n",
        "#    ]\n",
        "\n",
        "    # batch_size = len(input_sample)\n",
        "\n",
        "    # Input\n",
        "    input_tokenizer = AutoTokenizer.from_pretrained(model_name)#, model_max_length=256)\n",
        "    encoded_inputs = input_tokenizer(input_sample, return_tensors='tf', padding=True)#, truncation=True)\n",
        "    input_ids, attention_mask = encoded_inputs.input_ids, encoded_inputs.attention_mask\n",
        "    max_input_length = input_ids.shape[-1]\n",
        "\n",
        "    # Output\n",
        "    output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token='<UNK>')\n",
        "    output_tokenizer.fit_on_texts(output_sample)\n",
        "\n",
        "    output_vocab_size = len(output_tokenizer.word_index) + 1\n",
        "\n",
        "    encoded_output_sample = output_tokenizer.texts_to_sequences(output_sample)\n",
        "    max_output_length = max([len(item) for item in encoded_output_sample])\n",
        "\n",
        "    max_sequence_length = max(max_input_length, max_output_length)\n",
        "\n",
        "    encoded_output_sample = tf.keras.preprocessing.sequence.pad_sequences(encoded_output_sample,\n",
        "                                                                          padding='post',\n",
        "                                                                          maxlen=max_sequence_length)\n",
        "\n",
        "    # Test encoder\n",
        "    encoder = Encoder(model_name=model_name,\n",
        "                      decoder_units=16)\n",
        "    encoder_output, encoder_h, encoder_s = encoder({'input_ids': input_ids,\n",
        "                                                    'attention_mask': attention_mask})\n",
        "    print(f'{encoder_output.shape} - {encoder_h.shape} - {encoder_s.shape}')\n",
        "\n",
        "    # Test decoder\n",
        "    decoder = Decoder(vocab_size=output_vocab_size,\n",
        "                      embedding_dim=50,\n",
        "                      decoder_units=16,\n",
        "                      batch_size=batch_size,\n",
        "                      max_sequence_length=max_sequence_length)\n",
        "    \n",
        "\n",
        "    # Training\n",
        "    trainer = ModelTrainer(encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        max_length=max_sequence_length)\n",
        "    epochs = 100\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "      for minibatch in range(int(len(input_sample)/batch_size)):\n",
        "        batch = {\n",
        "            'encoder_input_ids': input_ids[minibatch*batch_size:minibatch*batch_size+batch_size],\n",
        "            'encoder_attention_mask': attention_mask[minibatch*batch_size:minibatch*batch_size+batch_size],\n",
        "            'decoder_target': encoded_output_sample[minibatch*batch_size:minibatch*batch_size+batch_size]\n",
        "        }\n",
        "        decoder.attention.setup_memory(encoder_output[minibatch*batch_size:minibatch*batch_size+batch_size])\n",
        "        initial_state = decoder.build_initial_state(batch_size,\n",
        "                                                    [encoder_h[minibatch*batch_size:minibatch*batch_size+batch_size],\n",
        "                                                     encoder_s[minibatch*batch_size:minibatch*batch_size+batch_size]])\n",
        "        decoder_sample_batch = {\n",
        "          'input_ids': tf.convert_to_tensor(encoded_output_sample[minibatch*batch_size:minibatch*batch_size+batch_size], tf.int32),\n",
        "          'initial_state': initial_state\n",
        "        }\n",
        "\n",
        "        loss = trainer.batch_fit(batch)\n",
        "        print(f'Loss - {loss}')\n",
        "\n",
        "        generated = trainer.generate(input_ids=input_ids,\n",
        "                                     attention_mask=attention_mask)\n",
        "        translated = trainer.translate(generated)\n",
        "        print(f'Translated - {translated}')\n",
        "\n"
      ],
      "metadata": {
        "id": "Ud0RAu03aZYT"
      },
      "id": "Ud0RAu03aZYT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qf8lnS6L8qLR"
      },
      "id": "qf8lnS6L8qLR"
    },
    {
      "cell_type": "markdown",
      "id": "f1e83f28",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7311ba86",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ac768c",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c7e98f",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1814004",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a1b2b9",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0967c209",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23929660",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c56a612",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bac4b9",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cc39f3c4f6ae4aa7a69f166ea47e6343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac226ef40468487aaf72dd4c5a778374",
              "IPY_MODEL_b0a2a0240ca545f0827e6582e0477710",
              "IPY_MODEL_c99a75d7b98743a7aed23a1f01c902df"
            ],
            "layout": "IPY_MODEL_92d89a9f3ed046d78d3bfca8ed193726"
          }
        },
        "ac226ef40468487aaf72dd4c5a778374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72a495385580408a9c972edc1b1d992a",
            "placeholder": "​",
            "style": "IPY_MODEL_7ea418273f6b4170a4afa31f1b743213",
            "value": "Downloading: 100%"
          }
        },
        "b0a2a0240ca545f0827e6582e0477710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4756cacdd6745ddb9c29b055afb0c99",
            "max": 285,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc32e79aaf24344a33f3b2cbdb79922",
            "value": 285
          }
        },
        "c99a75d7b98743a7aed23a1f01c902df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b51239b9cb6458ba5670340ac18cbe8",
            "placeholder": "​",
            "style": "IPY_MODEL_1872fdb552bb460f973b5393b290acc5",
            "value": " 285/285 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "92d89a9f3ed046d78d3bfca8ed193726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a495385580408a9c972edc1b1d992a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea418273f6b4170a4afa31f1b743213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4756cacdd6745ddb9c29b055afb0c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc32e79aaf24344a33f3b2cbdb79922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b51239b9cb6458ba5670340ac18cbe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1872fdb552bb460f973b5393b290acc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "622504ed237c4f61b32fe9f9b715e310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_140880bfea4847779a540864da84c928",
              "IPY_MODEL_9710eeb9d18c4f1f95288bc0aa751247",
              "IPY_MODEL_ced734e3715f4a7caaa2e1b431093853"
            ],
            "layout": "IPY_MODEL_d3db97046ae7481688b8d522db51f171"
          }
        },
        "140880bfea4847779a540864da84c928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5554d6faa44d4304bd04c5e431c503ed",
            "placeholder": "​",
            "style": "IPY_MODEL_826d0b094415467a807fa110e4e470f1",
            "value": "Downloading: 100%"
          }
        },
        "9710eeb9d18c4f1f95288bc0aa751247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a512f79f83264f849c130c20502ec34e",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_069bd2a5a5e1468c868d028abb37804e",
            "value": 231508
          }
        },
        "ced734e3715f4a7caaa2e1b431093853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1ad8de3f5854d279db93c83d103fff5",
            "placeholder": "​",
            "style": "IPY_MODEL_014f8160a816427a864eedabf91c8c6b",
            "value": " 232k/232k [00:00&lt;00:00, 291kB/s]"
          }
        },
        "d3db97046ae7481688b8d522db51f171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5554d6faa44d4304bd04c5e431c503ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826d0b094415467a807fa110e4e470f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a512f79f83264f849c130c20502ec34e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "069bd2a5a5e1468c868d028abb37804e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1ad8de3f5854d279db93c83d103fff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014f8160a816427a864eedabf91c8c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82d3f150faaf47ee882b6b4b593ccb99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0be3545aa1204683ac2355e2554d44a9",
              "IPY_MODEL_cd0a4fb337354d82844fd9729f23ef1e",
              "IPY_MODEL_b3740b6e0e7f47fd9a3fa666d7c57ecc"
            ],
            "layout": "IPY_MODEL_7e1422eb357f418da6cf2b1c5e59f3d3"
          }
        },
        "0be3545aa1204683ac2355e2554d44a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee27a385e1e2421c9e7b31d460d0a0c0",
            "placeholder": "​",
            "style": "IPY_MODEL_2bec7432ab5b4fd38adf3d1163265678",
            "value": "100%"
          }
        },
        "cd0a4fb337354d82844fd9729f23ef1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b957ead9ac5476c91e5b53fd0ee4471",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57c73464efb34e23bb88ca2d2165549c",
            "value": 86
          }
        },
        "b3740b6e0e7f47fd9a3fa666d7c57ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065e5b8c10a24fc6b65ca5b0bb5f419b",
            "placeholder": "​",
            "style": "IPY_MODEL_a1bb2247de9b484eb72897547c91cc9c",
            "value": " 86/86 [01:13&lt;00:00,  1.53ba/s]"
          }
        },
        "7e1422eb357f418da6cf2b1c5e59f3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee27a385e1e2421c9e7b31d460d0a0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bec7432ab5b4fd38adf3d1163265678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b957ead9ac5476c91e5b53fd0ee4471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57c73464efb34e23bb88ca2d2165549c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "065e5b8c10a24fc6b65ca5b0bb5f419b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1bb2247de9b484eb72897547c91cc9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edef201c511f492eb0dd8e87b4b7e2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05ba1ccb740d4f38b8a27cc7822b1b3a",
              "IPY_MODEL_596713fff8cc41638175d83906341d55",
              "IPY_MODEL_8eecbfacde26499ea4819e4097fae246"
            ],
            "layout": "IPY_MODEL_2922463b208944d1b862a94bb2ad884c"
          }
        },
        "05ba1ccb740d4f38b8a27cc7822b1b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0bbdfd58874cd79581d192cd450881",
            "placeholder": "​",
            "style": "IPY_MODEL_b4b78c9767be4d5fb6690c235021cb56",
            "value": "100%"
          }
        },
        "596713fff8cc41638175d83906341d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d46bb0528344c8ba275a06dcebf02c",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0aaa272183d43969eee2dddc85233b2",
            "value": 86
          }
        },
        "8eecbfacde26499ea4819e4097fae246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f50611b0b34e4683a9ec50f91e92103e",
            "placeholder": "​",
            "style": "IPY_MODEL_345c1dd434c54d958d8917944150d705",
            "value": " 86/86 [01:08&lt;00:00,  1.41ba/s]"
          }
        },
        "2922463b208944d1b862a94bb2ad884c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b0bbdfd58874cd79581d192cd450881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4b78c9767be4d5fb6690c235021cb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24d46bb0528344c8ba275a06dcebf02c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0aaa272183d43969eee2dddc85233b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f50611b0b34e4683a9ec50f91e92103e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345c1dd434c54d958d8917944150d705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67c8cd64374b426e8ee3732ab26a6833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcdaf0724d7349b791c8f663ef1fe5e8",
              "IPY_MODEL_6c7ef784e3f2434fa612f1df08c62f02",
              "IPY_MODEL_d53af78c14794bdd82727703c6be8422"
            ],
            "layout": "IPY_MODEL_fe985e7c42d844838f3eaf5064e948c4"
          }
        },
        "bcdaf0724d7349b791c8f663ef1fe5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af3b52804a004d809df15c2938fb35ae",
            "placeholder": "​",
            "style": "IPY_MODEL_798891665d2b41d0aad0c60dcfcf2ffc",
            "value": "100%"
          }
        },
        "6c7ef784e3f2434fa612f1df08c62f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49791bbc52894a3abc34a0f688b28ee6",
            "max": 86,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46800114d6ed4fda9fc68da03f29d77f",
            "value": 86
          }
        },
        "d53af78c14794bdd82727703c6be8422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d73fa1bf693d4833a6ae378020e6a368",
            "placeholder": "​",
            "style": "IPY_MODEL_cc7dad0bf76047b383dc611ad1b076bd",
            "value": " 86/86 [01:24&lt;00:00,  1.39ba/s]"
          }
        },
        "fe985e7c42d844838f3eaf5064e948c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3b52804a004d809df15c2938fb35ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798891665d2b41d0aad0c60dcfcf2ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49791bbc52894a3abc34a0f688b28ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46800114d6ed4fda9fc68da03f29d77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d73fa1bf693d4833a6ae378020e6a368": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc7dad0bf76047b383dc611ad1b076bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aefa1b9b462247ab88e2f2be30feb881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16e28f939e844c73b3bd206d278b4f9a",
              "IPY_MODEL_d2799741face472e92584f18f58f2dd6",
              "IPY_MODEL_9a6782598cd248f4b36edc6cfbefd3f5"
            ],
            "layout": "IPY_MODEL_256bee9b37e54d479d693f17b3f0146c"
          }
        },
        "16e28f939e844c73b3bd206d278b4f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a26f6dfb0bfb43bd802b11a582fab40a",
            "placeholder": "​",
            "style": "IPY_MODEL_e22b0aa6030147f9802b6285c4233542",
            "value": "Downloading: 100%"
          }
        },
        "d2799741face472e92584f18f58f2dd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1954e9819a14c1aafc93b0be6b080f3",
            "max": 17756393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab133e18ff3a47898f57d4d29f777e13",
            "value": 17756393
          }
        },
        "9a6782598cd248f4b36edc6cfbefd3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2879eabb13b6456ba10f905ca848b4b7",
            "placeholder": "​",
            "style": "IPY_MODEL_f87b5a26b31846afa9ee7ba105fa8952",
            "value": " 17.8M/17.8M [00:00&lt;00:00, 40.8MB/s]"
          }
        },
        "256bee9b37e54d479d693f17b3f0146c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26f6dfb0bfb43bd802b11a582fab40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22b0aa6030147f9802b6285c4233542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1954e9819a14c1aafc93b0be6b080f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab133e18ff3a47898f57d4d29f777e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2879eabb13b6456ba10f905ca848b4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87b5a26b31846afa9ee7ba105fa8952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ccb93966e704a42a33c7789296685b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0351181e985d4815ba00f0566a9caa15",
              "IPY_MODEL_087b8237bf42460db350fde7628911c7",
              "IPY_MODEL_cd1d98b150e84567bff96cbae651bbb9"
            ],
            "layout": "IPY_MODEL_f6ca08e1a4554f4e8e2c1e732c7f6be2"
          }
        },
        "0351181e985d4815ba00f0566a9caa15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df7bd931f7db4562b44ffcc2933bcdaa",
            "placeholder": "​",
            "style": "IPY_MODEL_2b15a18be6b742428012d27b99bf08fd",
            "value": "100%"
          }
        },
        "087b8237bf42460db350fde7628911c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9dc4ceda9249c88118cbbbdc87509c",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d7a469364834edc88d3dde4f66a0a14",
            "value": 22
          }
        },
        "cd1d98b150e84567bff96cbae651bbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5cde1f19f54bde975e5ad7ef84b268",
            "placeholder": "​",
            "style": "IPY_MODEL_ca90863b168a406a83b8adafa994a182",
            "value": " 22/22 [00:22&lt;00:00,  1.59ba/s]"
          }
        },
        "f6ca08e1a4554f4e8e2c1e732c7f6be2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df7bd931f7db4562b44ffcc2933bcdaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b15a18be6b742428012d27b99bf08fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a9dc4ceda9249c88118cbbbdc87509c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7a469364834edc88d3dde4f66a0a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a5cde1f19f54bde975e5ad7ef84b268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca90863b168a406a83b8adafa994a182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f69d601b8347f0984dea8632933dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a1c04b36c4b4d24bb0bdb06e872769e",
              "IPY_MODEL_22afdb08ecd042b29c85da73da896642",
              "IPY_MODEL_23a1a4722eae45b3b3cec17de375a579"
            ],
            "layout": "IPY_MODEL_adaaefa8ea284bc6906a79128530323c"
          }
        },
        "5a1c04b36c4b4d24bb0bdb06e872769e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60bf46d3a8a4ee5ba776de49387adc9",
            "placeholder": "​",
            "style": "IPY_MODEL_d7d9fc2d5a0444f0a83b0462beb3eb11",
            "value": "100%"
          }
        },
        "22afdb08ecd042b29c85da73da896642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26dc561bf9f9475a9d5f876834033bed",
            "max": 21479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95c7cfad4b6f4b9fb39089ad2d52f0d6",
            "value": 21479
          }
        },
        "23a1a4722eae45b3b3cec17de375a579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400475daa1224c719387431c0799a1cd",
            "placeholder": "​",
            "style": "IPY_MODEL_f2d4f9f7012b40d59f7fa44e80825a18",
            "value": " 21479/21479 [00:18&lt;00:00, 1207.51ex/s]"
          }
        },
        "adaaefa8ea284bc6906a79128530323c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c60bf46d3a8a4ee5ba776de49387adc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7d9fc2d5a0444f0a83b0462beb3eb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26dc561bf9f9475a9d5f876834033bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c7cfad4b6f4b9fb39089ad2d52f0d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "400475daa1224c719387431c0799a1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d4f9f7012b40d59f7fa44e80825a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}