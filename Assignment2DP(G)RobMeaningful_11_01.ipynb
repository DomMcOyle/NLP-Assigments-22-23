{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1d23b6c",
      "metadata": {
        "id": "d1d23b6c"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Keywords**: Transformers, Question Answering, CoQA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3f451b",
      "metadata": {
        "id": "bd3f451b"
      },
      "source": [
        "## Deadlines\n",
        "\n",
        "* **December 11**, 2022: deadline for having assignments graded by January 11, 2023\n",
        "* **January 11**, 2023: deadline for half-point speed bonus per assignment\n",
        "* **After January 11**, 2023: assignments are still accepted, but there will be no speed bonus"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11ada8c8",
      "metadata": {
        "id": "11ada8c8"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47c07553",
      "metadata": {
        "id": "47c07553"
      },
      "source": [
        "### Problem\n",
        "\n",
        "Question Answering (QA) on [CoQA](https://stanfordnlp.github.io/coqa/) dataset: a conversational QA dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4907f8d",
      "metadata": {
        "id": "b4907f8d"
      },
      "source": [
        "### Task\n",
        "\n",
        "Given a question $Q$, a text passage $P$, the task is to generate the answer $A$.<br>\n",
        "$\\rightarrow A$ can be: (i) a free-form text or (ii) unanswerable;\n",
        "\n",
        "**Note**: a question $Q$ can refer to previous dialogue turns. <br>\n",
        "$\\rightarrow$ dialogue history $H$ may be a valuable input to provide the correct answer $A$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b3760b5",
      "metadata": {
        "id": "9b3760b5"
      },
      "source": [
        "### Models\n",
        "\n",
        "We are going to experiment with transformer-based models to define the following models:\n",
        "\n",
        "1.  $A = f_\\theta(Q, P)$\n",
        "\n",
        "2. $A = f_\\theta(Q, P, H)$\n",
        "\n",
        "where $f_\\theta$ is the transformer-based model we have to define with $\\theta$ parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66cfee64",
      "metadata": {
        "id": "66cfee64"
      },
      "source": [
        "## The CoQA dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996fa650",
      "metadata": {
        "id": "996fa650"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://drive.google.com/uc?export=view&id=16vrgyfoV42Z2AQX0QY7LHTfrgektEKKh\" width=\"750\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e3e7d0",
      "metadata": {
        "id": "f6e3e7d0"
      },
      "source": [
        "For detailed information about the dataset, feel free to check the original [paper](https://arxiv.org/pdf/1808.07042.pdf).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfb6c37e",
      "metadata": {
        "id": "bfb6c37e"
      },
      "source": [
        "## Rationales\n",
        "\n",
        "Each QA pair is paired with a rationale $R$: it is a text span extracted from the given text passage $P$. <br>\n",
        "$\\rightarrow$ $R$ is not a requested output, but it can be used as an additional information at training time!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa786e2",
      "metadata": {
        "id": "daa786e2"
      },
      "source": [
        "## Dataset Statistics\n",
        "\n",
        "* **127k** QA pairs.\n",
        "* **8k** conversations.\n",
        "* **7** diverse domains: Children's Stories, Literature, Mid/High School Exams, News, Wikipedia, Reddit, Science.\n",
        "* Average conversation length: **15 turns** (i.e., QA pairs).\n",
        "* Almost **half** of CoQA questions refer back to **conversational history**.\n",
        "* Only **train** and **validation** sets are available."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d26d68b7",
      "metadata": {
        "id": "d26d68b7"
      },
      "source": [
        "## Dataset snippet\n",
        "\n",
        "The dataset is stored in JSON format. Each dialogue is represented as follows:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"source\": \"mctest\",\n",
        "    \"id\": \"3dr23u6we5exclen4th8uq9rb42tel\",\n",
        "    \"filename\": \"mc160.test.41\",\n",
        "    \"story\": \"Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. \n",
        "    Cotton lived high up in a nice warm place above the barn where all of the farmer's horses slept. [...]\" % <-- $P$\n",
        "    \"questions\": [\n",
        "        {\n",
        "            \"input_text\": \"What color was Cotton?\",   % <-- $Q_1$\n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        {\n",
        "            \"input_text\": \"Where did she live?\",\n",
        "            \"turn_id\": 2\n",
        "        },\n",
        "        [...]\n",
        "    ],\n",
        "    \"answers\": [\n",
        "        {\n",
        "            \"span_start\": 59,   % <-- $R_1$ start index\n",
        "            \"spand_end\": 93,    % <-- $R_1$ end index\n",
        "            \"span_text\": \"a little white kitten named Cotton\",   % <-- $R_1$\n",
        "            \"input_text\" \"white\",   % <-- $A_1$      \n",
        "            \"turn_id\": 1\n",
        "        },\n",
        "        [...]\n",
        "    ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72c7558c",
      "metadata": {
        "id": "72c7558c"
      },
      "source": [
        "### Simplifications\n",
        "\n",
        "Each dialogue also contains an additional field ```additional_answers```. For simplicity, we **ignore** this field and only consider one groundtruth answer $A$ and text rationale $R$.\n",
        "\n",
        "CoQA only contains 1.3% of unanswerable questions. For simplicity, we **ignore** those QA pairs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e01cdad7",
      "metadata": {
        "id": "e01cdad7"
      },
      "source": [
        "## [Task 1] Remove unaswerable QA pairs\n",
        "\n",
        "Write your own script to remove unaswerable QA pairs from both train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow-addons\n",
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "8aUY2EWyoS0x",
        "outputId": "856a8569-aaf2-46cf-8ab2-a10cd7808edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8aUY2EWyoS0x",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, urllib3, multiprocess, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed datasets-2.8.0 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.14 xxhash-3.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.11.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2022.11.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from evaluate) (2.25.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from evaluate) (1.3.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->evaluate) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2022.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.1.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->evaluate) (1.15.0)\n",
            "Installing collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6643e14",
      "metadata": {
        "id": "f6643e14"
      },
      "source": [
        "## Dataset Download\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "358bac70",
      "metadata": {
        "id": "358bac70"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DownloadProgressBar(tqdm):\n",
        "    def update_to(self, b=1, bsize=1, tsize=None):\n",
        "        if tsize is not None:\n",
        "            self.total = tsize\n",
        "        self.update(b * bsize - self.n)\n",
        "        \n",
        "def download_url(url, output_path):\n",
        "    with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                             miniters=1, desc=url.split('/')[-1]) as t:\n",
        "        urllib.request.urlretrieve(url, filename=output_path, reporthook=t.update_to)\n",
        "\n",
        "def download_data(data_path, url_path, suffix):    \n",
        "    if not os.path.exists(data_path):\n",
        "        os.makedirs(data_path)\n",
        "        \n",
        "    data_path = os.path.join(data_path, f'{suffix}.json')\n",
        "\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Downloading CoQA {suffix} data split... (it may take a while)\")\n",
        "        download_url(url=url_path, output_path=data_path)\n",
        "        print(\"Download completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6ab3ff",
      "metadata": {
        "id": "5f6ab3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b1c267b-16e3-4830-82ac-c2e2de0a40f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CoQA train data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-train-v1.0.json: 49.0MB [00:07, 6.21MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n",
            "Downloading CoQA test data split... (it may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "coqa-dev-v1.0.json: 9.09MB [00:02, 3.37MB/s]                            "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download completed!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Train data\n",
        "train_url = \"https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=train_url, suffix='train')\n",
        "\n",
        "# Test data\n",
        "test_url = \"https://nlp.stanford.edu/data/coqa/coqa-dev-v1.0.json\"\n",
        "download_data(data_path='coqa', url_path=test_url, suffix='test')  # <-- Why test? See next slides for an answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40e42311",
      "metadata": {
        "id": "40e42311"
      },
      "source": [
        "#### Data Inspection\n",
        "\n",
        "Spend some time in checking accurately the dataset format and how to retrieve the tasks' inputs and outputs!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from datasets import Dataset, load_from_disk\n",
        "import pickle\n",
        "import re\n",
        "from evaluate import load\n",
        "\n",
        "\n",
        "def set_seed(SEED):\n",
        "  random.seed(SEED) # if you're using random\n",
        "  np.random.seed(SEED) # if you're using numpy\n",
        "  torch.manual_seed(SEED) # torch.cuda.manual_seed_all(SEED) is not required\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  tf.random.set_seed(SEED) # setting the seed for tensorflow too\n",
        "  os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "def extract_data(split_dataset,add_history=False,sep_char=\"[SEP]\"):\n",
        "  \"\"\"\n",
        "  function extracting data from the list of dictionaries in the CoQA dataset\n",
        "  :params:\n",
        "    split_dataset: list of dictionaries from where to extract the pairs of question and passage and corresponding the answer\n",
        "  \"\"\"  \n",
        "  XQA = [] # list that will contain pairs (P,Q)\n",
        "  YQA = [] # list that will contain the Answers\n",
        "  for d in split_dataset: # scan each document\n",
        "    for i in range(len(d[\"questions\"])): # scan each question\n",
        "      if d[\"answers\"][i][\"span_end\"]!=-1: # discard unanswerable questions\n",
        "        single_example = [] # prepare the single example...\n",
        "        single_example.append(d[\"questions\"][i][\"input_text\"]) #... with the question ...\n",
        "        single_example.append(d[\"story\"]) # ...and the passage\n",
        "        if add_history:\n",
        "          for j in range(i-1,-1,-1):\n",
        "            if d[\"answers\"][j][\"span_end\"]!=-1:\n",
        "              single_example[1] = single_example[1] + sep_char + d[\"questions\"][j][\"input_text\"]+ sep_char + d[\"answers\"][j][\"input_text\"]\n",
        "              \n",
        "        XQA.append(single_example) # and append it\n",
        "        YQA.append(d[\"answers\"][i][\"input_text\"]) # add the answer\n",
        "  return XQA, YQA"
      ],
      "metadata": {
        "id": "h7_OLYpXkm56"
      },
      "id": "h7_OLYpXkm56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f57334e0",
      "metadata": {
        "id": "f57334e0"
      },
      "source": [
        "## [Task 2] Train, Validation and Test splits\n",
        "\n",
        "CoQA only provides a train and validation set since the test set is hidden for evaluation purposes.\n",
        "\n",
        "We'll consider the provided validation set as a test set. <br>\n",
        "$\\rightarrow$ Write your own script to:\n",
        "* Split the train data in train and validation splits (80% train and 20% val)\n",
        "* Perform splits such that a dialogue appears in one split only! (i.e., split at dialogue level)\n",
        "* Perform splitting using the following seed for reproducibility: 42\n",
        "\n",
        "#### Reproducibility Memo\n",
        "\n",
        "Check back tutorial 2 on how to fix a specific random seed for reproducibility!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42 \n",
        "set_seed(seed)"
      ],
      "metadata": {
        "id": "4Q6YfLkhyFXZ"
      },
      "id": "4Q6YfLkhyFXZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## MODEL NAME\n",
        "model_name = 'distilroberta-base'\n",
        "#model_name = 'prajjwal1/bert-tiny'\n",
        "add_history=True\n",
        "\n",
        "with open('coqa/train.json') as f:\n",
        "  # loading the training json\n",
        "  train_json = json.load(f)\n",
        "\n",
        "with open('coqa/test.json') as f:\n",
        "  # loading the test json\n",
        "  test_json = json.load(f)\n",
        "\n",
        "# splitting training data\n",
        "train_data, val_data = train_test_split(train_json[\"data\"],\n",
        "                                        train_size=0.8,\n",
        "                                        shuffle=True,\n",
        "                                        random_state=seed)\n",
        "# extracting X as list of pairs [Question, Passage] and Y as a list of strings (Answers) \n",
        "XQA_train, YQA_train = extract_data(train_data, add_history)\n",
        "XQA_val, YQA_val = extract_data(val_data, add_history)\n",
        "XQA_test, YQA_test = extract_data(test_json[\"data\"], add_history)\n",
        "del(train_json)\n",
        "del(test_json)\n",
        "\n",
        "print(\"First training example:\")\n",
        "print(XQA_train[3])\n",
        "print(YQA_train[3])\n",
        "print(\"First validation example:\")\n",
        "print(XQA_val[3])\n",
        "print(YQA_val[3])\n",
        "print(\"First test example:\")\n",
        "print(XQA_test[3])\n",
        "print(YQA_test[3])"
      ],
      "metadata": {
        "id": "0s8Ux69Fq1j-",
        "outputId": "953e549f-4676-4936-cd48-9d37398a5a62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0s8Ux69Fq1j-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First training example:\n",
            "['When was the last one held?', 'TUNIS, Tunisia (CNN) -- Polls closed late Sunday in Tunisia, the torchbearer of the so-called Arab Spring, but voters will not see results of national elections until Tuesday, officials said. \\n\\nOn Sunday, long lines of voters snaked around schools-turned-polling-stations in Tunis\\'s upscale Menzah neighborhood, some waiting for hours to cast a vote in the nation\\'s first national elections since the country\\'s independence in 1956. \\n\\n\"It\\'s a wonderful day. It\\'s the first time we can choose our own representatives,\" said Walid Marrakchi, a civil engineer who waited more than two hours, and who brought along his 3-year-old son Ahmed so he could \"get used to freedom and democracy.\" \\n\\nTunisia\\'s election is the first since a popular uprising in January overthrew long-time dictator Zine El Abidine Ben Ali and triggered a wave of revolutions -- referred to as the Arab Spring -- across the region. \\n\\nMore than 60 political parties and thousands of independent candidates competed for 218 seats in a new Constitutional Assembly, which will be charged with writing a new constitution and laying the framework for a government system. \\n\\nVoters appeared jubilant on Sunday, taking photos of each other outside polling stations, some holding Tunisian flags. \\n\\n\"It\\'s a holiday,\" said housewife Maha Haubi, who had just taken her position at the end of the long line of more than 1,000 voters waiting outside an elementary school in Menzah. \\n\\n\"Before we never even had the right to say \\'yes\\' or \\'no.\\'\" \\n\\nNearby, banker Aid Naghmaichi said she didn\\'t mind the long wait to vote. [SEP]What day of the week did they vote?[SEP]Sunday[SEP]What is being voted on?[SEP]Representatives  are being chosen[SEP]Where is this taking place?[SEP]Tunisia']\n",
            "1956\n",
            "First validation example:\n",
            "['When was the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. [SEP]What was the score?[SEP]3-0[SEP]who was playing against them?[SEP]Manchester City[SEP]Who was playing in the game?[SEP]the team from Liverpool\"]\n",
            "Monday\n",
            "First test example:\n",
            "['Who did she live with?', 'Once upon a time, in a barn near a farm house, there lived a little white kitten named Cotton. Cotton lived high up in a nice warm place above the barn where all of the farmer\\'s horses slept. But Cotton wasn\\'t alone in her little home above the barn, oh no. She shared her hay bed with her mommy and 5 other sisters. All of her sisters were cute and fluffy, like Cotton. But she was the only white one in the bunch. The rest of her sisters were all orange with beautiful white tiger stripes like Cotton\\'s mommy. Being different made Cotton quite sad. She often wished she looked like the rest of her family. So one day, when Cotton found a can of the old farmer\\'s orange paint, she used it to paint herself like them. When her mommy and sisters found her they started laughing. \\n\\n\"What are you doing, Cotton?!\" \\n\\n\"I only wanted to be more like you\". \\n\\nCotton\\'s mommy rubbed her face on Cotton\\'s and said \"Oh Cotton, but your fur is so pretty and special, like you. We would never want you to be any other way\". And with that, Cotton\\'s mommy picked her up and dropped her into a big bucket of water. When Cotton came out she was herself again. Her sisters licked her face until Cotton\\'s fur was all all dry. \\n\\n\"Don\\'t ever do that again, Cotton!\" they all cried. \"Next time you might mess up that pretty white fur of yours and we wouldn\\'t want that!\" \\n\\nThen Cotton thought, \"I change my mind. I like being special\".[SEP]Did she live alone?[SEP]no[SEP]Where did she live?[SEP]in a barn[SEP]What color was Cotton?[SEP]white']\n",
            "with her mommy and 5 sisters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## broken example fix:\n",
        "print(XQA_train[61])\n",
        "print(YQA_train[61])\n",
        "YQA_train[61] = 'October'\n",
        "print(YQA_train[61])"
      ],
      "metadata": {
        "id": "o4mOxQbmUq0W"
      },
      "id": "o4mOxQbmUq0W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "def filter_string(x):\n",
        "  return re.sub('[!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n]',\"\",x)\n",
        "  \n",
        "# this tokenizer doen't filter anything, so a word and the concatenation of the\n",
        "# same word with a punctuation will have different embeddings\n",
        "output_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$%&()*+,./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<UNK>')#, analyzer = custom_analyzer) # here we use a custom analyzer\n",
        "output_tokenizer.fit_on_texts([\"<start> \" + i + \" <end>\" for i in YQA_train])\n",
        "\n",
        "input_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "max_output_length = max([len(i) for i in YQA_train])\n",
        "print(\"Max input output found: \" + str(max([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)])))\n",
        "#max_sequence_length = max(512, max_output_length)\n",
        "print(\"99° percentile of training set answer length:\" + str(np.quantile([len(i) for i in output_tokenizer.texts_to_sequences(YQA_train)], 0.99)))\n",
        "# actual percentile is 17, given that each string has the beginnning and ending token\n",
        "max_sequence_length = 20\n",
        "\n",
        "\n",
        "print(np.argmax([len(i) for i in YQA_train]))\n",
        "print(XQA_train[7529])\n",
        "print(YQA_train[7529])\n",
        "\n",
        "dataset_suffix = \"_hist\" if add_history else \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "a24a6e43a9114e6e99bef88e57e4d2e5",
            "24db20893a8c446b83bcae8e3cb840ac",
            "52051a6cfb27417a896fd3d29eafd801",
            "9d660321c123404580391a6f241ad084",
            "e85176d636c3449da63ecbaaedbc98c5",
            "af8fd820ecf640bb80bf17c86192b2b8",
            "7756b123000144ab92de2cbd4514174f",
            "d604fbfef4da4595b715e6f4b7cbaa68",
            "54729ba3bf1247a5931f3f26c74573bd",
            "16995bc4eac141c199cfd60f067c6ac2",
            "6772c8810e4d4d028cfa63aa4815a074",
            "030703dff4d046449ce9a6b18b6b3186",
            "310a95f8c888434db2e8ffbb8ba6a145",
            "103c31c9e2be43fda25f65b60212cf0c",
            "a23ec2dadeb441a285def238bb28c978",
            "2a111c91a7ca4beba3b47cc761d3787d",
            "0fd173fc150745019a27ebe4dbbf9250",
            "43e9fdec6cd1478fab2d0268dff58d15",
            "75ae81627a7340b49eabc8f957e43903",
            "66a190e7ace442049b4f7c7393fee6a2",
            "d228eaf764254b408118d1d9c5b4fcf9",
            "0e52dc717d154231957fc5bdcac8fb28",
            "f1fa011c4b584482851c53a3586918ab",
            "8fdde996f91843b4b1a74622a54e1ccb",
            "b1abb6c05899435cb565681dbde3052b",
            "a631d8ac18154d39a7270c58a66827b1",
            "a5141e3441454ec4ae47af79442bd668",
            "847a9bb923fd413ea64964785ee8710b",
            "c9abc8ffe4f547dea4d6f3e3bb4c999d",
            "caae70980eed48d4bffb784b4392a513",
            "51503b3a5f954cecb48acc9dc03e1266",
            "bb8b2f72fd5b46a7a72eccd0218d4db1",
            "37b3ee5365814ab1bb82722f5e433108",
            "95ca0808adfb4b6ea0fbf089c1cadd89",
            "f2eb55e0e3e84a5c93123a85c69f85ec",
            "b45bb8eff50a46e8b53bd48dfa647ee0",
            "d49c82e7d7d84280a5cceee2d0c4279a",
            "983229fc9e3f4d9ea06dbb637d243873",
            "198127d758f8493ab4b29dc3212e0c6a",
            "756687f9961043bb90b575f91939b23f",
            "9602487150aa4d7f99c4efbc01c528b0",
            "8c038ce14bca4ee7ae4402f27dccf90f",
            "abbf33ce2c47486691b4c470aa945b21",
            "e9f2671767e84ab19a2e7b81e830b77f"
          ]
        },
        "id": "bRzqq374GQOC",
        "outputId": "2c0691bb-dacc-49f1-c86e-7020955ff6c3"
      },
      "id": "bRzqq374GQOC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a24a6e43a9114e6e99bef88e57e4d2e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "030703dff4d046449ce9a6b18b6b3186"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1fa011c4b584482851c53a3586918ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95ca0808adfb4b6ea0fbf089c1cadd89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input output found: 106\n",
            "99° percentile of training set answer length:13.0\n",
            "61\n",
            "[\"What symptoms of addiction does Orzack's center list?\", 'Caught in the Web A few months ago, it wasn\\'t unusual for 47-year-old Carla Toebe to spend 15 hours per day online. She\\'d wake up early, turn on her laptop and chat on Internet dating sites and instant-messaging programs - leaving her bed for only brief intervals. Her household bills piled up, along with the dishes and dirty laundry, but it took near-constant complaints from her four daughters before she realized she had a problem. \"I was starting to feel like my whole world was falling apart - kind of slipping into a depression,\" said Carla. \"I knew that if I didn\\'t get off the dating sites, I\\'d just keep going,\" detaching herself further from the outside world. Toebe\\'s conclusion: She felt like she was \"addicted\" to the Internet. She\\'s not alone. Concern about excessive Internet use isn\\'t new. As far back as 1995, articles in medical journals and the establishment of a Pennsylvania treatment center for overusers generated interest in the subject. There\\'s still no consensus on how much time online constitutes too much or whether addiction is possible. But as reliance on the Web grows, there are signs that the question is getting more serious attention: Last month, a study published in CNS Spectrums claimed to be the first large-scale look at excessive Internet use. The American Psychiatric Association may consider listing Internet addiction in the next edition of its diagnostic manual. And scores of online discussion boards have popped up on which people discuss negative experiences tied to too much time on the Web. \"There\\'s no question that there\\'re people who\\'re seriously in trouble because they\\'re overdoing their Internet involvement,\" said psychiatrist Ivan Goldberg. Goldberg calls the problem a disorder rather than a true addiction. Jonathan Bishop, a researcher in Wales specializing in online communities, is more skeptical. \"The Internet is an environment,\" he said. \"You can\\'t be addicted to the environment.\" Bishop describes the problem as simply a matter of priorities, which can be solved by encouraging people to prioritize other life goals and plans in place of time spent online. The new CNS Spectrums study was based on results of a nationwide telephone survey of more than 2,500 adults. Like the 2005 survey, this one was conducted by Stanford University researchers.About 6% of respondents reported that \"their relationships suffered because of excessive Internet use.\" About 9% attempted to conceal \"nonessential Internet use,\" and nearly 4% reported feeling \"preoccupied by the Internet when offline.\" About 8% said they used the Internet as a way to escape problems, and almost 14% reported they \"found it hard to stay away from the Internet for several days at a time.\" \"The Internet problem is still in its infancy,\" said Elias Aboujaoude, a Stanford professor. No single online activity is to blame for excessive use, he said. \"They\\'re online in chat rooms, checking e-mail, or writing blogs. not limited to porn or gambling\" websites. Excessive Internet use should be defined not by the number of hours spent online but \"in terms of losses,\" said Maressa Orzack, a Harvard University professor. \"If it\\'s a loss you\\'re not getting to work, and family relationships are breaking down as a result, then it\\'s too much.\" Since the early 1990s, several clinics have been established in the U. S. to treat heavy Internet users. They include the Center for Internet Addiction Recovery and the Center for Internet Behavior. The website for Orzack\\'s center lists the following among the psychological symptoms of computer addiction: * Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders, Orzack said. When she discusses Internet habits with her patients, they often report that being online offers a \"sense of belonging, and escape, excitement fun,\" she said. \"Some people say relief...because they find themselves so relaxed.\" Some parts of the Internet seem to draw people in more than others. Internet gamers spend countless hours competing in games against people from all over the world. One such game, called World of Warcraft, is cited on many sites by posters complaining of a \"gaming addiction.\" Andrew Heidrich, an education network administrator from Sacramento, plays World of Warcraft for about two to four hours every other night, but that\\'s nothing compared with the 40 to 60 hours a week he spent playing online games when he was in college. He cut back only after a full-scale family intervention , in which s told him he\\'d gained weight. \"There\\'s this whole culture of competition that sucks people in\" with online gaming, said Heidrich, now a father of two. \"People do it at the expense of everything that was a constant in their lives.\" Heidrich now visits websites that discuss gaming addiction regularly \"to remind myself to keep my love for online games in check.\" Toebe also regularly visits a site where posters discuss Internet overuse. In August, when she first realized she had a problem, she posted a message on a Yahoo Internet addiction group with the subject line: \"I have an Internet Addiction.\" \"I\\'m self-employed and need the Internet for my work, but I\\'m failing to accomplish my work,to take care of my home, to give attention to my children,\" she wrote in a message sent to the group.\"I have no money or insurance to get professional help; I can\\'t even pay my mortgage and face losing everything.\" Since then, Toebe said, she has kept her promise to herself to cut back on her Internet use. \"I have a boyfriend now, and I\\'m not interested in online dating,\" she said by phone last week. \"It\\'s a lot better now.\"[SEP]What problems with addiction did Andrew have?[SEP]gained weight[SEP]What video game has been associated with addiction?[SEP]World of Warcraft[SEP]What problems did Carla have as a result of her addiction?[SEP]depression, bills piling up, household falling apart[SEP]How do you determine if someone is addicted to the internet?[SEP]There\\'s still no consensus[SEP]When did internet addiction first become known as a problem?[SEP]1995[SEP]Has the American Psychiatric Association listed Internet Addiction in its diagnostic manual?[SEP]No[SEP]Why was this a problem?[SEP]She was detached from daily life[SEP]What did Carla spend most of her day doing?[SEP]chat on Internet dating sites']\n",
            "Having a sense of well-being or excitement while at the computer. * Longing for more and more time at the computer. * Neglect of family and friends. * Feeling empty, depressed or irritable when not at the computer. * Lying to employers and family about activities. * Inability to stop the activity. * Problems with school or job. Physical symptoms listed include dry eyes, backaches, skipping meals, poor personal hygiene and sleep disturbances. People who struggle with excessive Internet use maybe depressed or have other mood disorders,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dataset\n",
        "train_ds = Dataset.from_dict({\"xqa\": XQA_train, \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_train]})\n",
        "train_ds = train_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_token\": output_tokenizer.texts_to_sequences(x[\"yqa\"])}, batched=True)\n",
        "train_ds = train_ds.map(lambda x: {\"y_padded\": tf.keras.preprocessing.sequence.pad_sequences(x[\"y_token\"],\n",
        "                                                                     padding='post',\n",
        "                                                                     maxlen=max_sequence_length)}, batched=True\n",
        ")\n",
        "train_ds = train_ds.remove_columns([\"xqa\", \"yqa\", \"y_token\"])\n",
        "train_ds = train_ds.with_format(type=\"tensorflow\")\n",
        "if model_name == 'prajjwal1/bert-tiny':\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds\" + dataset_suffix)\n",
        "else:\n",
        "  train_ds.save_to_disk(\"gdrive/MyDrive/ckpt/train_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "nErpyDpLhRV8"
      },
      "id": "nErpyDpLhRV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions are in lower case, so we consider the labels in lower case\n",
        "val_ds = Dataset.from_dict({\"xqa\": XQA_val, \"yqa\": [filter_string(i.lower()) for i in YQA_val], \"id_placeholder\": list(range(len(YQA_val)))})\n",
        "val_ds = val_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "val_ds = val_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "val_ds = val_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds\" + dataset_suffix)\n",
        "else:\n",
        "  val_ds = val_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  val_ds.save_to_disk(\"gdrive/MyDrive/ckpt/val_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "b9VyzKdnAuKz"
      },
      "id": "b9VyzKdnAuKz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions are in lower case, so we consider the labels in lower case\n",
        "test_ds = Dataset.from_dict({\"xqa\": XQA_test, \"yqa\": [filter_string(i.lower()) for i in YQA_test], \"id_placeholder\": list(range(len(YQA_test)))})\n",
        "test_ds = test_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "test_ds = test_ds.map(lambda x:{\"references\": {'answers':{'text':[x[\"yqa\"]], 'answer_start': [42]},\n",
        "    'id': str(x[\"id_placeholder\"]) } })\n",
        "\n",
        "test_ds = test_ds.remove_columns([\"xqa\",\"yqa\", \"id_placeholder\"])\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\",\"token_type_ids\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds\" + dataset_suffix)\n",
        "else:\n",
        "  test_ds = test_ds.with_format(type=\"tensorflow\", columns=[\"input_ids\", \"attention_mask\"], output_all_columns=True)\n",
        "  test_ds.save_to_disk(\"gdrive/MyDrive/ckpt/test_ds_rob\" + dataset_suffix)"
      ],
      "metadata": {
        "id": "83_mH8gTRY5z"
      },
      "id": "83_mH8gTRY5z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agumentation of the dataset by use of the best POS tagger obtained from Assignment 1 "
      ],
      "metadata": {
        "id": "EJ1JkP4iKeoP"
      },
      "id": "EJ1JkP4iKeoP"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "to_pos_tag_XQ = [XQA_train, XQA_val, XQA_test]\n",
        "to_pos_tag_YQ = [YQA_train, YQA_val, YQA_test]\n",
        "\n",
        "def from_sentence_to_token_list(sentence):\n",
        "  tokens_sentence = [word_tokenize(t) for t in sent_tokenize(sentence)]\n",
        "  tags_sentence = [nltk.pos_tag(token_list) for token_list in tokens_sentence]\n",
        "  to_return = []\n",
        "  for tagged_sentence in tags_sentence:\n",
        "    to_return.append([tagged_sentence[i][1] for i in range(0, len(tagged_sentence))])\n",
        "  return to_return\n",
        "\n",
        "def pos_tag_datasets(XQ, YQ):\n",
        "  pos_XQ = []\n",
        "  pos_YQ = []\n",
        "  i = 0\n",
        "  for elem in tqdm(XQ): \n",
        "    question = elem[0]\n",
        "    passage = elem[1]\n",
        "    answer = YQ[0]\n",
        "    question_tags = from_sentence_to_token_list(question)\n",
        "    passage_tags = from_sentence_to_token_list(passage)\n",
        "    answer_tags = from_sentence_to_token_list(answer)\n",
        "    i = i + 1\n",
        "    pos_XQ.append([question_tags, passage_tags])\n",
        "    pos_YQ.append(answer_tags)\n",
        "  return pos_XQ, pos_YQ\n",
        "\n",
        "XQA_train_pos, YQA_train_pos = pos_tag_datasets(XQA_train, YQA_train) \n",
        "XQA_val_pos, YQA_val_pos = pos_tag_datasets(XQA_val, YQA_val) \n",
        "XQA_test_pos, YQA_test_pos = pos_tag_datasets(XQA_val, YQA_val) \n",
        "\n"
      ],
      "metadata": {
        "id": "QvsiUHgRKdrw"
      },
      "id": "QvsiUHgRKdrw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(list_to_save, filename):\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(list_to_save, f)\n",
        "\n",
        "save_list(XQA_train_pos, \"drive/MyDrive/ckpt/pos/XQA_train_pos.pos\")\n",
        "save_list(YQA_train_pos, \"drive/MyDrive/ckpt/pos/YQA_train_pos.pos\")\n",
        "\n",
        "save_list(XQA_val_pos, \"drive/MyDrive/ckpt/pos/XQA_val_pos.pos\")\n",
        "save_list(YQA_val_pos, \"drive/MyDrive/ckpt/pos/YQA_val_pos.pos\")\n",
        "\n",
        "save_list(XQA_test_pos, \"drive/MyDrive/ckpt/pos/XQA_test_pos.pos\")\n",
        "save_list(YQA_test_pos, \"drive/MyDrive/ckpt/pos/YQA_test_pos.pos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RKg49rKWXGKy",
        "outputId": "b17467b5-e0cd-4536-c761-de04b6233877"
      },
      "id": "RKg49rKWXGKy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b09bc0dd744e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXQA_train_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drive/MyDrive/ckpt/pos/XQA_train_pos.pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msave_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYQA_train_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"drive/MyDrive/ckpt/pos/YQA_train_pos.pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'save_list' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_list(filename):\n",
        "  to_return = []\n",
        "  with open(filename, \"rb\") as f:\n",
        "    to_return = pickle.load(f)\n",
        "  return to_return\n",
        "  \n",
        "XQA_train_pos = load_list(r\"drive/MyDrive/ckpt/pos/XQA_train_pos.pos\")\n",
        "YQA_train_pos = load_list(r\"drive/MyDrive/ckpt/pos/YQA_train_pos.pos\")\n",
        "\n",
        "XQA_val_pos = load_list(r\"drive/MyDrive/ckpt/pos/XQA_val_pos.pos\")\n",
        "YQA_val_pos = load_list(r\"drive/MyDrive/ckpt/pos/YQA_val_pos.pos\")\n",
        "\n",
        "XQA_test_pos = load_list(r\"drive/MyDrive/ckpt/pos/XQA_test_pos.pos\")\n",
        "YQA_test_pos = load_list(r\"drive/MyDrive/ckpt/pos/YQA_test_pos.pos\")\n",
        "\n",
        "XQA_train_pos = np.asarray(XQA_train_pos)\n",
        "XQA_val_pos = np.asarray(XQA_val_pos)\n",
        "XQA_val_pos = np.asarray(XQA_val_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4neqL9ojzes",
        "outputId": "f038394f-c16c-4e79-a85c-2cd71603949a"
      },
      "id": "X4neqL9ojzes",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-e708ab2dd251>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  XQA_train_pos = np.asarray(XQA_train_pos)\n",
            "<ipython-input-33-e708ab2dd251>:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  XQA_val_pos = np.asarray(XQA_val_pos)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(XQA_train_pos[0][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJiAhrqcY0D_",
        "outputId": "94bbb1a4-f037-4808-86c4-3369b3d779c7"
      },
      "id": "DJiAhrqcY0D_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate dataset\n",
        "#train_ds = Dataset.from_dict({\"xqa\": XQA_train, \"yqa\": [\"<start> \" + i + \" <end>\" for i in YQA_train]})\n",
        "#train_ds = train_ds.map(lambda x: input_tokenizer(x[\"xqa\"], return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512), batched=True)\n",
        "#train_ds = train_ds.map(lambda x: {\"y_token\": output_tokenizer.texts_to_sequences(x[\"yqa\"])}, batched=True)\n",
        "#train_ds = train_ds.map(lambda x: {\"y_padded\": tf.keras.preprocessing.sequence.pad_sequences(x[\"y_token\"],\n",
        "#                                                                     padding='post',\n",
        "#       \n",
        "#                                                              maxlen=max_sequence_length)}, batched=True)\n",
        "#print(XQA_train_pos[0])\n",
        "#print(XQA_train_pos[1])\n",
        "#print(train_ds[0])\n",
        "quest_to_test = XQA_train_pos[0][0]\n",
        "pass_to_test = XQA_train_pos[0][1]\n",
        "#srt_to_test = input_tokenizer(str_to_test, return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512)\n",
        "#print(srt_to_test)\n",
        "\n",
        "import tensorflow as tf\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from datasets import concatenate_datasets\n",
        "from nltk.data import load\n",
        "import itertools\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download(\"tagsets\")\n",
        "\n",
        "def get_quantile_length_sentence_pos(XQA_train_pos, XQA_val_pos, XQA_test_pos):\n",
        "  train_sentences = [[len(XQA_train_pos[i][1][j]) for j in range(0, len(XQA_train_pos[i][1]))] for i in range(0, len(XQA_train_pos))]\n",
        "  train_sentence_length = list(itertools.chain.from_iterable(train_sentences))\n",
        "  val_sentences = [[len(XQA_val_pos[i][1][j]) for j in range(0, len(XQA_val_pos[i][1]))] for i in range(0, len(XQA_val_pos))]\n",
        "  val_sentence_length = list(itertools.chain.from_iterable(val_sentences))\n",
        "  test_sentences = [[len(XQA_test_pos[i][1][j]) for j in range(0, len(XQA_test_pos[i][1]))] for i in range(0, len(XQA_test_pos))]\n",
        "  test_sentence_length = list(itertools.chain.from_iterable(test_sentences))\n",
        "\n",
        "  quantile_sentences_length = np.quantile((train_sentence_length + val_sentence_length + test_sentence_length), 0.75)\n",
        "  return int(quantile_sentences_length)\n",
        "\n",
        "def get_quantile_numsentences_pos(XQA_train_pos, XQA_val_pos, XQA_test_pos):\n",
        "  train_num_sentences = [len(XQA_train_pos[i][0])+len(XQA_train_pos[i][1]) for i in range(0, len(XQA_train_pos))]\n",
        "  train_nums = train_num_sentences\n",
        "  val_num_sentences = [len(XQA_val_pos[i][0])+len(XQA_val_pos[i][1]) for i in range(0, len(XQA_val_pos))]\n",
        "  val_nums = val_num_sentences\n",
        "  test_num_sentences = [len(XQA_test_pos[i][0])+len(XQA_test_pos[i][1]) for i in range(0, len(XQA_test_pos))]\n",
        "  test_nums = test_num_sentences\n",
        "  quantile_numsentences_length = np.quantile((train_nums + val_nums + test_nums), 0.75)\n",
        "  return int(quantile_numsentences_length)\n",
        "\n",
        "\n",
        "def pos_tags_to_tensor(pos_tags_list, max_length_sentence_pos, max_numsentences_pos):\n",
        "  tag_to_idx = {}\n",
        "  tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
        "  for i, elem in enumerate(tagdict.keys()):\n",
        "    tag_to_idx.update({elem : float(i + 1)}) # no tag is represented as 0\n",
        "  tag_to_idx.update({\"#\": float(len(tag_to_idx.keys()) + 2)})\n",
        "\n",
        "  to_return = []\n",
        "  for i, pos_tags in enumerate(pos_tags_list):\n",
        "    pos_tags = [tag_to_idx[tag] for tag in pos_tags]\n",
        "    if i < max_numsentences_pos:\n",
        "      to_return.append(pos_tags)\n",
        "  to_return = tf.keras.preprocessing.sequence.pad_sequences(to_return, padding='post', maxlen=max_length_sentence_pos, dtype=\"float64\")\n",
        "  return to_return\n",
        "\n",
        "def append_zero_vecs(where_append, max_length_sentence_pos, max_numsentences_pos):\n",
        "  while len(where_append) < max_numsentences_pos:\n",
        "    where_append = np.concatenate((where_append, [np.zeros(max_length_sentence_pos)]), axis = 0)\n",
        "  return where_append\n",
        "\n",
        "def create_pos_tensor_from_pos_dataset_entry(pos_entry, max_length_sentence_pos, max_numsentences_pos):\n",
        "  #print(pos_tags_to_tensor(pos_entry[0], max_length_sentence_pos))\n",
        "  pos_entry_sentences = []\n",
        "  for sentence in pos_entry[0]:\n",
        "    pos_entry_sentences.append(sentence)\n",
        "  for sentence in pos_entry[1]:\n",
        "    pos_entry_sentences.append(sentence)\n",
        "  list_of_pos_vecs = pos_tags_to_tensor(pos_entry_sentences, max_length_sentence_pos, max_numsentences_pos)\n",
        "  pad_sentence_list = append_zero_vecs(list_of_pos_vecs, max_length_sentence_pos, max_numsentences_pos)\n",
        "  tensor_to_return = tf.convert_to_tensor(pad_sentence_list) \n",
        "  return tensor_to_return\n",
        "\n",
        "def convert_pos_df_to_tensors(XQA, max_length_sentence_pos, max_numsentences_pos):\n",
        "  first = create_pos_tensor_from_pos_dataset_entry(XQA[0], max_length_sentence_pos, max_numsentences_pos)\n",
        "  ds_to_return = np.array([first])\n",
        "  ds_to_return_2 = []\n",
        "  ds_to_return_3 = []\n",
        "  for elem in tqdm(range(1, len(XQA))):\n",
        "    to_append = create_pos_tensor_from_pos_dataset_entry(XQA[elem], max_length_sentence_pos, max_numsentences_pos)\n",
        "    to_append = np.array([to_append])\n",
        "    if (elem / len(XQA)) < 0.33:\n",
        "      ds_to_return = np.concatenate((ds_to_return, to_append))\n",
        "    if (elem / len(XQA)) > 0.33 and (elem / len(XQA)) < 0.66: \n",
        "      if ds_to_return_2 == []:\n",
        "        ds_to_return_2 = to_append\n",
        "      else:\n",
        "        ds_to_return_2 = np.concatenate((ds_to_return_2, to_append))\n",
        "    if (elem / len(XQA)) > 0.66:\n",
        "      if ds_to_return_3 == []:\n",
        "        ds_to_return_3 = to_append\n",
        "      else:\n",
        "        ds_to_return_3 = np.concatenate((ds_to_return_3, to_append))\n",
        "\n",
        "  ds_to_return = np.concatenate((ds_to_return, ds_to_return_2))\n",
        "  ds_to_return = np.concatenate((ds_to_return, ds_to_return_3))\n",
        "  return ds_to_return\n",
        "\n",
        "def serialize_obj(obj_to_save, filename):\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(obj_to_save, f)\n",
        "\n",
        "max_length_sentence_pos = get_quantile_length_sentence_pos(XQA_train_pos, XQA_val_pos, XQA_test_pos) # 303 is the maximum, it exceeded the ram so\n",
        "                                                                                                      # we consider the quantile\n",
        "print(max_length_sentence_pos)\n",
        "max_numsentences_pos = get_quantile_numsentences_pos(XQA_train_pos, XQA_val_pos, XQA_test_pos)        # 103 is the maximum, again we use the quantile\n",
        "print(max_numsentences_pos)\n",
        "\n",
        "\n",
        "XQA_train_pos_tensors = convert_pos_df_to_tensors(XQA_train_pos, max_length_sentence_pos, max_numsentences_pos)\n",
        "serialize_obj(XQA_train_pos_tensors, \"drive/MyDrive/ckpt/pos/XQA_train_pos_tensors.tens\")\n",
        "\n",
        "XQA_val_pos_tensors = convert_pos_df_to_tensors(XQA_val_pos, max_length_sentence_pos, max_numsentences_pos)\n",
        "serialize_obj(XQA_val_pos_tensors, \"drive/MyDrive/ckpt/pos/XQA_val_pos_tensors.tens\")\n",
        "\n",
        "XQA_test_pos_tensors = convert_pos_df_to_tensors(XQA_test_pos, max_length_sentence_pos, max_numsentences_pos)\n",
        "serialize_obj(XQA_test_pos_tensors, \"drive/MyDrive/ckpt/pos/XQA_test_pos_tensors.tens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "SARGpfJNNmrz",
        "outputId": "085043e1-4315-4239-a5cd-627ff016f25d"
      },
      "id": "SARGpfJNNmrz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-cda02f8dda82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#print(XQA_train_pos[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#print(train_ds[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mquest_to_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXQA_train_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpass_to_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXQA_train_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#srt_to_test = input_tokenizer(str_to_test, return_tensors=\"tf\", padding=\"max_length\", truncation=\"longest_first\", max_length=512)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'XQA_train_pos' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_list(filename):\n",
        "  to_return = []\n",
        "  with open(filename, \"rb\") as f:\n",
        "    to_return = pickle.load(f)\n",
        "  return to_return\n",
        "\n",
        "XQA_train_pos_tensors = load_list(\"drive/MyDrive/ckpt/pos/XQA_train_pos_tensors.tens\")\n",
        "XQA_val_pos_tensors = load_list(\"drive/MyDrive/ckpt/pos/XQA_val_pos_tensors.tens\")\n",
        "XQA_test_pos_tensors = load_list(\"drive/MyDrive/ckpt/pos/XQA_test_pos_tensors.tens\")"
      ],
      "metadata": {
        "id": "Dc8eCBQtiXb2"
      },
      "id": "Dc8eCBQtiXb2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"Indexed POS vector of the first (question, passage) \n",
        "pair of the training set:\"\"\")\n",
        "print(XQA_train_pos_tensors[0]) \n",
        "print(type(XQA_train_pos_tensors))"
      ],
      "metadata": {
        "id": "b7yPBMHVlp-R",
        "outputId": "d95f70c1-0da4-41b0-c7bf-8b3d690b11da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b7yPBMHVlp-R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexed POS vector of the first (question, passage) \n",
            "pair of the training set:\n",
            "[[38.  9. 13.  7. 12. 22.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [12. 30. 13.  8. 39. 12. 23. 43. 41. 36. 26. 37. 41. 30.  8. 41. 30. 39.\n",
            "  23. 41. 29. 22.]\n",
            " [ 7. 30. 41.  2. 37. 13. 12. 30. 13. 12. 45.  8.  8. 41. 30. 13. 12. 45.\n",
            "  12. 30. 44. 22.]\n",
            " [24. 14.  9. 13.  8. 12. 22.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [41. 23. 43.  5. 29. 32. 18.  8. 12. 39. 30. 14. 36. 24. 37.  3.  2. 37.\n",
            "  43. 12. 22.  4.]\n",
            " [39. 39. 39. 39. 43. 29. 13. 12. 30. 41. 15. 29.  2. 30. 13.  8. 12. 15.\n",
            "  30. 13. 12. 22.]\n",
            " [ 8. 39. 39. 23. 19. 36. 37.  3. 30.  7. 13.  8. 12. 43.  7. 13. 12. 30.\n",
            "  13. 12. 12. 22.]\n",
            " [41. 29. 12. 30. 39. 23.  7. 41. 30. 13.  8. 30.  7. 41. 23. 13.  7.  8.\n",
            "  41. 22.  0.  0.]\n",
            " [18. 12. 30. 13. 12. 30. 13.  8. 12. 30. 33. 30. 44. 41.  7. 30. 13.  8.\n",
            "  12. 30. 39. 22.]\n",
            " [24. 30. 14. 26. 26. 29. 13. 12.  2. 37. 41. 45. 43. 45. 22.  4.  4.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [26. 23. 12. 39. 39. 29. 14. 29. 26. 37. 13.  8. 12.  2. 37. 22.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "   0.  0.  0.  0.]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230a21de",
      "metadata": {
        "id": "230a21de"
      },
      "source": [
        "## [Task 3] Model definition\n",
        "\n",
        "Write your own script to define the following transformer-based models from [huggingface](https://HuggingFace.co/).\n",
        "\n",
        "* [M1] DistilRoBERTa (distilberta-base)\n",
        "* [M2] BERTTiny (bert-tiny)\n",
        "\n",
        "**Note**: Remember to install the ```transformers``` python package!\n",
        "\n",
        "**Note**: We consider small transformer models for computational reasons!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "xPPBaBkEa9N3",
        "outputId": "64c3ab97-759e-4d74-f79e-652654c3288e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "id": "xPPBaBkEa9N3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4996ee3d8d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not be a symlink'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not already contain files"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vClEMABsIsCd",
        "outputId": "4765fcf7-55bc-48a1-c5d9-40dace8e07aa"
      },
      "id": "vClEMABsIsCd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THIS IS A SEPARATOR ##########################################################\n",
        "\n",
        "\"\"\"\n",
        "This was tested with:\n",
        "tensorflow==2.6\n",
        "tensorflow-gpu==2.6\n",
        "tensorflow-addons==0.16.1\n",
        "transformers==4.18.0\n",
        "Keras==2.6.0\n",
        "\n",
        "Note 1: Simple adaptation of tf_seq2seq_lstm.py script\n",
        "Note 2: make sure Keras and Tensorflow versions match!\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm\n",
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "import time\n",
        "\n",
        "# check if training can be performed on GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "\n",
        "class MyTrainer(object):\n",
        "    \"\"\"\n",
        "    Simple wrapper class\n",
        "\n",
        "    train_op -> uses tf.GradientTape to compute the loss\n",
        "    batch_fit -> receives a batch and performs forward-backward passes (gradient included) \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, max_length):\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.max_length = max_length\n",
        "        self.ce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, \n",
        "                                                                reduction='none') # from logits means that it returns values after a \n",
        "                                                                                  # softmax application, thus it is useless to\n",
        "                                                                                  # add a softmax activation layer if this parameter is set to \n",
        "                                                                                  # true (or even dangerous because it squashes the values)\n",
        "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-03)            # here it is possible to tweak the learning rate\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, logits, target):\n",
        "        loss = self.ce(y_true=target, y_pred=logits)\n",
        "        mask = tf.logical_not(tf.math.equal(target, 0))\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask # pointwise product\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    @tf.function\n",
        "    def train_op(self, inputs):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # NOTABENE: it is necessary to add token_type_ids to see how it performs\n",
        "            if self.encoder.use_token_type_ids:\n",
        "              encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask'],\n",
        "                                                                  'token_type_ids': inputs['token_type_ids'],\n",
        "                                                                  \"pos_tags\": inputs[\"pos_tags\"]})\n",
        "            else:\n",
        "              encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs['input_ids'],\n",
        "                                                                  'attention_mask': inputs['attention_mask'],\n",
        "                                                                  \"pos_tags\": inputs[\"pos_tags\"]})\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "            decoder_input = inputs['y_padded'][:, :-1]  # ignore <end>\n",
        "            real_target = inputs['y_padded'][:, 1:]  # ignore <start>\n",
        "\n",
        "            # encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': inputs[0][0],\n",
        "            #                                                    'attention_mask': inputs[0][1]})\n",
        "            # decoder_input = inputs[1][:, :-1]\n",
        "            # real_target = inputs[1][:, 1:]\n",
        "\n",
        "            decoder.attention.setup_memory(encoder_output) # setup in order to perform attention queries over the \n",
        "                                                           # embedding space\n",
        "\n",
        "            # decoder initialization, check build_initial_state for additional insights\n",
        "            decoder_initial_state = self.decoder.build_initial_state(decoder.batch_size, [encoder_h, encoder_s])\n",
        "            # the input is then passed to the initialized decoder and we obtain predictions\n",
        "            # in rnn_output format because the model is BERT-emdedding-sequence-sequence, so the\n",
        "            # last layer is still a sequence of cells (a RNN)\n",
        "            predicted = self.decoder({'input_ids': decoder_input,\n",
        "                                      'initial_state': decoder_initial_state}).rnn_output\n",
        "            # we compute the losses over the computed predictions\n",
        "            loss = self.compute_loss(logits=predicted, target=real_target)\n",
        "        # gradients of the loss computed for this minibatch considering trainable\n",
        "        # parameters of encoder and decoder\n",
        "        grads = tape.gradient(loss, self.encoder.trainable_variables + self.decoder.trainable_variables)\n",
        "        return loss, grads\n",
        "\n",
        "    @tf.function\n",
        "    def batch_fit(self, inputs):\n",
        "        loss, grads = self.train_op(inputs=inputs)\n",
        "        # applies gradients to the trainable variables using Adam\n",
        "        self.optimizer.apply_gradients(zip(grads, self.encoder.trainable_variables + self.decoder.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    # @tf.function\n",
        "    def generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids, \n",
        "        })\n",
        "        if self.encoder.use_token_type_ids:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "        else:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "          \n",
        "\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "\n",
        "        # samples the possible answer with greedy technique, we could possibly\n",
        "        # use a variant here such as beam search at inference time \n",
        "        # We could not do this at training time, since the Sampler used at training\n",
        "        # is not designed to project the token in an embedding space before computing\n",
        "        # the next one. The aforementioned embedding space\n",
        "        # is changing at each backpropagation step anyways, thus we stick with\n",
        "        # the computation of the argmax of the logits using TrainingSampler.\n",
        "        # NOTABENE: we can still change this sampler, find a way to penalize repetitions\n",
        "        # and perform the beam search\n",
        "        greedy_sampler = tfa.seq2seq.GreedyEmbeddingSampler() \n",
        "        # we have a decoder for training and a decoder for test time, thus\n",
        "        # we need to re-define the training decoder each time we want to\n",
        "        # train a new batch\n",
        "        decoder_instance = tfa.seq2seq.BasicDecoder(cell=self.decoder.wrapped_decoder_cell,\n",
        "                                                    sampler=greedy_sampler,\n",
        "                                                    output_layer=self.decoder.generation_dense,\n",
        "                                                    maximum_iterations=self.max_length)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # decoder_initial_state is still an output of the encoder, we pass it to\n",
        "        # the decoder_instance in order to get the outputs\n",
        "        decoder_initial_state = self.decoder.build_initial_state(batch_size, [encoder_h, encoder_s])\n",
        "        decoder_embedding_matrix = self.decoder.embedding.variables[0]\n",
        "        outputs, _, _ = decoder_instance(decoder_embedding_matrix,\n",
        "                                         start_tokens=start_tokens,\n",
        "                                         end_token=end_token,\n",
        "                                         initial_state=decoder_initial_state)\n",
        "        return outputs\n",
        "\n",
        "    def translate(self, generated, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(generated.sample_id.numpy())\n",
        "\n",
        "    def beam_translate(self, results, output_tokenizer):\n",
        "        return output_tokenizer.sequences_to_texts(results[0][:,0,:])\n",
        "\n",
        "    def beam_generate(self, output_tokenizer, input_ids,token_type_ids, attention_mask=None, beam_width=3, length_penalty=0.5):\n",
        "        batch_size = input_ids.shape[0] # input_ids is the minibatch\n",
        "        encoder_output, encoder_h, encoder_s = self.encoder({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids, \n",
        "        })\n",
        "        if self.encoder.use_token_type_ids:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask,\n",
        "                                                                  'token_type_ids': token_type_ids})\n",
        "        else:\n",
        "          encoder_output, encoder_h, encoder_s = self.encoder({'input_ids': input_ids,\n",
        "                                                                  'attention_mask': attention_mask})\n",
        "        start_tokens = tf.fill([batch_size], output_tokenizer.word_index['<start>'])\n",
        "        end_token = output_tokenizer.word_index['<end>']\n",
        "        \n",
        "        # From official documentation\n",
        "        # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:\n",
        "        # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).\n",
        "        # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.\n",
        "        # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.\n",
        "\n",
        "        encoder_output = tfa.seq2seq.tile_batch(encoder_output, multiplier=beam_width)\n",
        "        self.decoder.attention.setup_memory(encoder_output)\n",
        "\n",
        "        # set decoder_inital_state which is an AttentionWrapperState considering beam_width\n",
        "        hidden_state = tfa.seq2seq.tile_batch([encoder_h, encoder_s], multiplier=beam_width)\n",
        "        decoder_initial_state = self.decoder.build_initial_state(beam_width*batch_size, hidden_state)\n",
        "\n",
        "        # Instantiate BeamSearchDecoder\n",
        "        decoder_instance = tfa.seq2seq.BeamSearchDecoder(self.decoder.wrapped_decoder_cell,\n",
        "                                                          beam_width=beam_width,\n",
        "                                                          output_layer=self.decoder.generation_dense,\n",
        "                                                          length_penalty_weight=length_penalty,\n",
        "                                                          maximum_iterations=self.max_length)\n",
        "        decoder_embedding_matrix = decoder.embedding.variables[0]\n",
        "\n",
        "        # The BeamSearchDecoder object's call() function takes care of everything.\n",
        "        outputs, final_state, sequence_lengths = decoder_instance(decoder_embedding_matrix, \n",
        "                                                                  start_tokens=start_tokens,\n",
        "                                                                  end_token=end_token,\n",
        "                                                                  initial_state=decoder_initial_state)\n",
        "        # outputs is tfa.seq2seq.FinalBeamSearchDecoderOutput object. \n",
        "        # The final beam predictions are stored in outputs.predicted_id\n",
        "        # outputs.beam_search_decoder_output is a tfa.seq2seq.BeamSearchDecoderOutput object which keep tracks of beam_scores and parent_ids while performing a beam decoding step\n",
        "        # final_state = tfa.seq2seq.BeamSearchDecoderState object.\n",
        "        # Sequence Length = [inference_batch_size, beam_width] details the maximum length of the beams that are generated\n",
        "\n",
        "\n",
        "        # outputs.predicted_id.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "        # outputs.beam_search_decoder_output.scores.shape = (inference_batch_size, time_step_outputs, beam_width)\n",
        "        # Convert the shape of outputs and beam_scores to (inference_batch_size, beam_width, time_step_outputs)\n",
        "        final_outputs = tf.transpose(outputs.predicted_ids, perm=(0,2,1))\n",
        "        beam_scores = tf.transpose(outputs.beam_search_decoder_output.scores, perm=(0,2,1))\n",
        "\n",
        "        return final_outputs.numpy(), beam_scores.numpy()\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, model_name, decoder_units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.model = TFAutoModel.from_pretrained(model_name, from_pt=True, trainable=False)\n",
        "        self.model.trainable=False\n",
        "        self.reducer = tf.keras.layers.Dense(decoder_units)\n",
        "        self.reducer2 = tf.keras.layers.Dense(decoder_units)\n",
        "        self.avg_pool = tf.keras.layers.AveragePooling1D(pool_size = 512)\n",
        "        self.use_token_type_ids = model_name=='prajjwal1/bert-tiny'\n",
        "        self.emb_layer_postags = tf.keras.layers.Embedding(682, 512)\n",
        "        self.conv_pos = tf.keras.layers.Conv1D(decoder_units, kernel_size = 682)\n",
        "        self.dense_pos_hidden = tf.keras.layers.Dense(512)\n",
        "        self.dense_pos_cell = tf.keras.layers.Dense(512)\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        inputs_no_pos = {\"input_ids\":inputs[\"input_ids\"], \"attention_mask\":inputs[\"attention_mask\"]}\n",
        "        model_output = self.model(inputs_no_pos)\n",
        "        \n",
        "        # all_outputs has shape (batch_size * 512 * 128)\n",
        "        all_outputs = model_output[0] # output of the last layer of the model\n",
        "        #pooled_output = model_output[1] # last layer but processed by a linear \n",
        "                                        # layer and a tanh\n",
        "        \n",
        "        \n",
        "        \n",
        "        # cls coding\n",
        "        hidden_pooled = all_outputs[:, 0, :]\n",
        "        cell_state = self.avg_pool(all_outputs)\n",
        "        cell_state = tf.reshape(cell_state, [all_outputs.shape[0], all_outputs.shape[2]])\n",
        "\n",
        "        # NOTABENE: it could be possible to add something to improve the encoding\n",
        "        \n",
        "        # pooled output has shape (batch_size * 128)\n",
        "        hidden_state = self.reducer(hidden_pooled)\n",
        "        cell_state = self.reducer2(cell_state)\n",
        "        #return all_outputs, self.reducer(model_output[1]), self.reducer(model_output[1])\n",
        "\n",
        "        to_concat = self.emb_layer_postags(inputs[\"pos_tags\"])\n",
        "        to_concat = self.conv_pos(to_concat)\n",
        "        to_concat = tf.reshape(to_concat, (14, 512))\n",
        "\n",
        "        #tf.print(to_concat.shape)\n",
        "        #tf.print(all_outputs.shape)\n",
        "        \n",
        "\n",
        "        pos_hidden = tf.concat([hidden_state, to_concat], axis = 1)\n",
        "        pos_cell = tf.concat([cell_state, to_concat], axis = 1)\n",
        "        \n",
        "        pos_hidden = self.dense_pos_hidden(pos_hidden)\n",
        "        pos_cell = self.dense_pos_cell(pos_cell)\n",
        "        #tf.print(pos_hidden.shape)\n",
        "        #tf.print(pos_cell.shape)\n",
        "\n",
        "        return all_outputs, pos_hidden, pos_cell\n",
        "\n",
        "\n",
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, max_sequence_length, embedding_dim, decoder_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.decoder_units = decoder_units\n",
        "        # NOTABENE: it is possible to change the embedding dimension and the number of LSTM cells\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                                   output_dim=embedding_dim)\n",
        "        # NOTABENE: It could be possible to swap LSTMCell with GRUCell\n",
        "        self.decoder_lstm_cell = tf.keras.layers.LSTMCell(self.decoder_units)\n",
        "        # NOTABENE: Just one type of attention, it could be changed to seek for different\n",
        "        # results\n",
        "        self.attention = tfa.seq2seq.BahdanauAttention(units=self.decoder_units,\n",
        "                                                       memory=None,\n",
        "                                                       memory_sequence_length=self.batch_size * [max_sequence_length])\n",
        "\n",
        "        self.wrapped_decoder_cell = tfa.seq2seq.AttentionWrapper(self.decoder_lstm_cell,\n",
        "                                                                 self.attention,\n",
        "                                                                 attention_layer_size=self.decoder_units) # adds the attention mechanism after a single\n",
        "                                                                                # LSTM cell, because we pass a word at the time\n",
        "        # dense layer needed to generate the distribution values over \n",
        "        # the size of the vocabulary (probability for each word)\n",
        "        self.generation_dense = tf.keras.layers.Dense(vocab_size)\n",
        "        # Above we describe why this cannot be changed and why it resambles\n",
        "        # the greedysampler\n",
        "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "        self.decoder = tfa.seq2seq.BasicDecoder(self.wrapped_decoder_cell,\n",
        "                                                sampler=self.sampler,\n",
        "                                                output_layer=self.generation_dense)\n",
        "\n",
        "    def build_initial_state(self, batch_size, encoder_state):\n",
        "        # after initializing the tensors within the attention layer to 0 we add\n",
        "        # the designated initialization that allow us to query the embedding space,\n",
        "        # which is passed as encoder_state.\n",
        "        # We load the embedding of a single batch and we actually don't freeze \n",
        "        # the parameters related to BERT, that are modified and can possibly \n",
        "        # overfit. \n",
        "        initial_state = self.wrapped_decoder_cell.get_initial_state(batch_size=batch_size, dtype=tf.float32)\n",
        "        initial_state = initial_state.clone(cell_state=encoder_state) \n",
        "        return initial_state\n",
        "\n",
        "    def call(self, inputs, training=False, **kwargs):\n",
        "        # as shown in calls, inputs is a dictionary with entries: \n",
        "        # \"input_ids\" : _encoder_output_\n",
        "        # \"initial_state\" : _result_of_build_initial_state_\n",
        "        input_ids = inputs['input_ids']\n",
        "        input_emb = self.embedding(input_ids)\n",
        "        decoder_output, _, _ = self.decoder(input_emb,\n",
        "                                            initial_state=inputs['initial_state'],\n",
        "                                            sequence_length=self.batch_size * [self.max_sequence_length - 1])\n",
        "        return decoder_output\n",
        "\n",
        "\n",
        "# THIS IS A SEPARATOR ##########################################################"
      ],
      "metadata": {
        "id": "tgypImQXgQhh"
      },
      "id": "tgypImQXgQhh",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "jqe4q0lTkzN6",
        "outputId": "0aef4c9f-a7c2-4041-cbff-5ec22ba1e9ac"
      },
      "id": "jqe4q0lTkzN6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "Successfully installed keras-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_addons.seq2seq import decoder\n",
        "import tensorflow as tf\n",
        "from tensorflow_addons.seq2seq import sampler as sampler_py\n",
        "import numpy as np\n",
        "from typing import Tuple, List, Mapping, Union, Optional\n",
        "import tempfile\n",
        "\n",
        "class POSLSTMCell(tf.keras.layers.LSTMCell):\n",
        "  def __init__(self, units, **kwargs):\n",
        "    super(POSLSTMCell, self).__init__(units, **kwargs)\n",
        "\n",
        "  def call(self, inputs, states, pos_tags):\n",
        "    # Unpack the inputs and states\n",
        "    inputs, h, c = inputs, states[0], states[1]\n",
        "\n",
        "    # Concatenate the POS tags to the inputs\n",
        "    inputs = tf.concat([inputs, pos_tags], axis=-1)\n",
        "\n",
        "    # Compute the new h and c states\n",
        "    h, c = super(POSLSTMCell, self).call(inputs, states=[h, c])\n",
        "\n",
        "    return h, c\n",
        "\n",
        "\n",
        "class NomoreBasicDecoder(decoder.BaseDecoder):\n",
        "  def __init__(\n",
        "    self,\n",
        "    cell: tf.keras.layers.Layer,\n",
        "    sampler: sampler_py.Sampler,\n",
        "    output_layer: Optional[tf.keras.layers.Layer] = None,\n",
        "    **kwargs,):\n",
        "    \"\"\"Initialize BasicDecoder.\n",
        "    Args:\n",
        "      cell: A layer that implements the `tf.keras.layers.AbstractRNNCell`\n",
        "        interface.\n",
        "      sampler: A `tfa.seq2seq.Sampler` instance.\n",
        "      output_layer: (Optional) An instance of `tf.keras.layers.Layer`, i.e.,\n",
        "        `tf.keras.layers.Dense`. Optional layer to apply to the RNN output\n",
        "          prior to storing the result or sampling.\n",
        "      **kwargs: Other keyword arguments of `tfa.seq2seq.BaseDecoder`.\n",
        "    \"\"\"\n",
        "    #keras_utils.assert_like_rnncell(\"cell\", cell) removing security checks about the cell layer because we want to use a custom one\n",
        "    self.cell = cell\n",
        "    self.sampler = sampler\n",
        "    self.output_layer = output_layer\n",
        "    super().__init__(**kwargs)\n",
        "\n",
        "  def initialize(self, inputs, initial_state=None, **kwargs):\n",
        "    \"\"\"Initialize the decoder.\"\"\"\n",
        "    # Assume the dtype of the cell is the output_size structure\n",
        "    # containing the input_state's first component's dtype.\n",
        "    #self._cell_dtype = tf.nest.flatten(initial_state)[0].dtype removing security checks about the cell layer because we want to use a custom one\n",
        "    return self.sampler.initialize(inputs, **kwargs) + (initial_state,)\n",
        "\n",
        "  @property\n",
        "  def batch_size(self):\n",
        "    return self.sampler.batch_size\n",
        "\n",
        "  def _rnn_output_size(self):\n",
        "    size = tf.TensorShape(self.cell.output_size)\n",
        "    if self.output_layer is None:\n",
        "        return size\n",
        "    else:\n",
        "        # To use layer's compute_output_shape, we need to convert the\n",
        "        # RNNCell's output_size entries into shapes with an unknown\n",
        "        # batch size.  We then pass this through the layer's\n",
        "        # compute_output_shape and read off all but the first (batch)\n",
        "        # dimensions to get the output size of the rnn with the layer\n",
        "        # applied to the top.\n",
        "        output_shape_with_unknown_batch = tf.nest.map_structure(\n",
        "            lambda s: tf.TensorShape([None]).concatenate(s), size\n",
        "        )\n",
        "        layer_output_shape = self.output_layer.compute_output_shape(\n",
        "            output_shape_with_unknown_batch\n",
        "        )\n",
        "        return tf.nest.map_structure(lambda s: s[1:], layer_output_shape)\n",
        "\n",
        "  @property\n",
        "  def output_size(self):\n",
        "    # Return the cell output and the id\n",
        "    return NomoreBasicDecoder(\n",
        "        rnn_output=self._rnn_output_size(), sample_id=self.sampler.sample_ids_shape\n",
        "    )\n",
        "\n",
        "  @property\n",
        "  def output_dtype(self):\n",
        "    # Assume the dtype of the cell is the output_size structure\n",
        "    # containing the input_state's first component's dtype.\n",
        "    # Return that structure and the sample_ids_dtype from the helper.\n",
        "    dtype = self._cell_dtype\n",
        "    return NomoreBasicDecoder(\n",
        "        tf.nest.map_structure(lambda _: dtype, self._rnn_output_size()),\n",
        "        self.sampler.sample_ids_dtype,\n",
        "    )\n",
        "  \n",
        "  def step(self, time, inputs, state, training=None, **kwargs):\n",
        "    \"\"\"Perform a decoding step.\n",
        "    Args:\n",
        "      time: scalar `int32` tensor.\n",
        "      inputs: A (structure of) input tensors.\n",
        "      state: A (structure of) state tensors and TensorArrays.\n",
        "      training: Python boolean.\n",
        "    Returns:\n",
        "      `(outputs, next_state, next_inputs, finished)`.\n",
        "    \"\"\"\n",
        "    pos_tags = kwargs[\"pos_tags\"]\n",
        "    cell_outputs, cell_state = self.cell(inputs, state, pos_tags, training=training)\n",
        "    cell_state = tf.nest.pack_sequence_as(state, tf.nest.flatten(cell_state))\n",
        "    if self.output_layer is not None:\n",
        "        cell_outputs = self.output_layer(cell_outputs)\n",
        "        sample_ids = self.sampler.sample(\n",
        "          time=time, outputs=cell_outputs, state=cell_state)\n",
        "        (finished, next_inputs, next_state) = self.sampler.next_inputs(time=time, \n",
        "                                                                        outputs=cell_outputs, \n",
        "                                                                        state=cell_state, \n",
        "                                                                        sample_ids=sample_ids)\n",
        "    outputs = tfa.seq2seq.BasicDecoderOutput(cell_outputs, sample_ids)\n",
        "    return (outputs, next_state, next_inputs, finished)"
      ],
      "metadata": {
        "id": "IRiGmF79QmzX"
      },
      "id": "IRiGmF79QmzX",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "max_sequence_length = 20\n",
        "if model_name == 'prajjwal1/bert-tiny':\n",
        "  train_ds = load_from_disk(\"drive/MyDrive/ckpt/train_ds\")\n",
        "  val_ds = load_from_disk(\"drive/MyDrive/ckpt/val_ds\")\n",
        "  test_ds = load_from_disk(\"drive/MyDrive/ckpt/test_ds\")\n",
        "else:\n",
        "  train_ds = load_from_disk(\"drive/MyDrive/ckpt/train_ds_rob\")\n",
        "  val_ds = load_from_disk(\"drive/MyDrive/ckpt/val_ds_rob\")\n",
        "  test_ds = load_from_disk(\"drive/MyDrive/ckpt/test_ds_rob\")"
      ],
      "metadata": {
        "id": "q5V3J1qzG3cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71adaead-ec69-4a9e-92fd-46eaa0adeed7"
      },
      "id": "q5V3J1qzG3cq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/datasets/arrow_dataset.py:1533: FutureWarning: 'fs' was is deprecated in favor of 'storage_options' in version 2.8.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'storage_options=fs.storage_options' instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(trainer, dataset, epochs, batch_size, checkpoint, checkpoint_prefix):\n",
        "  steps_per_epoch = len(dataset)//batch_size\n",
        "\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    batch_index = 0\n",
        "    cumulative_loss = 0\n",
        "\n",
        "    for batch_index in tqdm(range(steps_per_epoch), position=0, leave=True):\n",
        "      loss = trainer.batch_fit(dataset[batch_index*batch_size:batch_index*batch_size+batch_size])\n",
        "      cumulative_loss += loss\n",
        "\n",
        "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
        "    mean_loss = cumulative_loss / batch_index\n",
        "    print(f\"Current mean {mean_loss}\")\n",
        "\n",
        "\n",
        "def predict_loop(trainer, dataset, inference_batch_size,model_name,output_tokenizer, beam_search=False):\n",
        "  ttids=None\n",
        "  if beam_search:\n",
        "    generation_func = trainer.beam_generate\n",
        "    translation_func = trainer.beam_translate\n",
        "  else:\n",
        "    generation_func = trainer.generate\n",
        "    translation_func = trainer.translate\n",
        "  \n",
        "  inference_step = len(dataset) // inference_batch_size\n",
        "  predictions = []\n",
        "  for step_index in tqdm(range(inference_step)):\n",
        "    starting_index = step_index*inference_batch_size\n",
        "    ending_index = step_index*inference_batch_size + inference_batch_size\n",
        "    if model_name == 'prajjwal1/bert-tiny':  \n",
        "      ttids = dataset[\"token_type_ids\"][starting_index : ending_index]\n",
        "    generated = generation_func(output_tokenizer=output_tokenizer, \n",
        "                                  input_ids=dataset[\"input_ids\"][starting_index : ending_index],\n",
        "                                  token_type_ids=ttids,\n",
        "                                  attention_mask=dataset[\"attention_mask\"][starting_index : ending_index])\n",
        "    translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "  # all this mess with indexes is needed in order to have coherent ids in the field \"id\"\n",
        "    list_to_add = [{'prediction_text': translated[i - starting_index].split(\"<end>\")[0], 'id':str(i)} for i in range(starting_index, ending_index)]\n",
        "    predictions.extend(list_to_add)\n",
        "  if model_name == 'prajjwal1/bert-tiny':  \n",
        "    ttids = dataset[\"token_type_ids\"][(inference_step)*inference_batch_size :]\n",
        "  \n",
        "  generated = generation_func(output_tokenizer = output_tokenizer, \n",
        "                             input_ids=dataset[\"input_ids\"][(inference_step)*inference_batch_size :],\n",
        "                             token_type_ids=ttids,\n",
        "                             attention_mask=dataset[\"attention_mask\"][(inference_step)*inference_batch_size :])\n",
        "  translated = translation_func(generated, output_tokenizer=output_tokenizer)\n",
        "\n",
        "  predictions.extend([{'prediction_text': translated[i - (inference_step)*inference_batch_size].split(\"<end>\")[0], \n",
        "                    'id':str(i)} for i in range((inference_step)*inference_batch_size, \n",
        "                                                len(dataset))])\n",
        "  return predictions\n",
        "  \n",
        "def save_prediction(prediction, filename):\n",
        "  with open(filename, \"wb\") as f:\n",
        "    pickle.dump(prediction, f)"
      ],
      "metadata": {
        "id": "bIsHB5JGHGzE"
      },
      "id": "bIsHB5JGHGzE",
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load as lo\n",
        "\n",
        "BATCH_SIZE = 14\n",
        "EPOCHS = 3\n",
        "INF_BS = 64\n",
        "squad_metric = lo(\"squad\")\n",
        "\n",
        "if model_name == 'prajjwal1/bert-tiny':  \n",
        "  checkpoint_dir = './gdrive/MyDrive/ckpt/dom/tiny'\n",
        "  decoder_units = 128\n",
        "else: \n",
        "  checkpoint_dir = './gdrive/MyDrive/ckpt/dom/rob'\n",
        "  decoder_units = 512\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "print(checkpoint_prefix)"
      ],
      "metadata": {
        "id": "1yhop6aHPLr_",
        "outputId": "ae815fd5-9fc2-4327-d956-1caa9a7e46f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1yhop6aHPLr_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./gdrive/MyDrive/ckpt/dom/rob/ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "to_add_train = [np.asarray(elem).flatten() for elem in XQA_train_pos_tensors]\n",
        "to_add_val = [np.asarray(elem).flatten() for elem in XQA_val_pos_tensors]\n",
        "\n",
        "\n",
        "to_add_df = pd.DataFrame({\"pos_tags\":to_add})\n",
        "to_add_df_val = pd.DataFrame({\"pos_tags\":to_add_val})\n",
        "#train_ds = train_ds.remove_columns([\"pos_tags\"])\n",
        "\n",
        "#train_ds = train_ds.add_column(name=\"pos_tags\", column=to_add)\n",
        "val_ds = val_ds.add_column(name=\"pos_tags\", column=to_add_val)"
      ],
      "metadata": {
        "id": "HOAJMnq-5qQg"
      },
      "id": "HOAJMnq-5qQg",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_ds[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK_oXgT98O3c",
        "outputId": "136df0ef-6478-4662-9e71-12a14f9e591a"
      },
      "id": "hK_oXgT98O3c",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([    0, 12375,    21,   816,    11,     5,   177,   116,     2,\n",
            "           2,  1640, 16256,    43,   480,  5095,  9005,  1008,  2330,\n",
            "           6,    39,    78,  1175,    13,  3426,     6,     7,   244,\n",
            "          39,   950, 15995,  3002,  2361,   412,   155,    12,   288,\n",
            "          11,   302,    18,  2275,   815,  6376,    23, 18476,     4,\n",
            "        1437, 50118, 50118, 15075,     6,    54,   956,    10,  1124,\n",
            "           7,   517,  1065,  3098,    88,   371,   317,    11,     5,\n",
            "        2103,     6,    58, 12315,   409,    30,    10,  7360,    78,\n",
            "         457,   819,    31,  3426,     6,    54,    33, 14436,  2958,\n",
            "         737,    19,    42,   898,     4,  1437, 50118, 50118, 30760,\n",
            "         880, 28416,     8,   823,   362,    10,  3821,    12,  4530,\n",
            "         483,    77,  7866, 15612,    18,  2051,  2506,    21, 13402,\n",
            "        2500,     5,   618,    30,   412,    18,  1156,  7551,  2101,\n",
            "        4980,     4,  1437, 50118, 50118,  1708,     5,  3918,  1443,\n",
            "          21,  3306,     7, 10731,    19,  3426,    18,  4605,     9,\n",
            "        1912,     8,     5,  4452,   362,    10, 10973,   483,   411,\n",
            "         728,   423,    77,  9005,    18, 11415,   352,  2322,   314,\n",
            "          12, 26620,  2506,     6,    31,    95,   751,     5,   443,\n",
            "           6,  3514, 13539,   375,  4980,    13,    39,    78,   724,\n",
            "         187,  3736,     5,   950,    13,    10,  1089,   638,  2937,\n",
            "        4029,    11,   644,     4,  1437, 50118, 50118, 30760,  7113,\n",
            "          49,   483,    11,     5,  2631,   212,  2289,    77,   412,\n",
            "        1447,     7,   699,    10, 15436,     9, 20238,     8,  4953,\n",
            "        2347,     6,     5,  1011,  2140,  3064,     7,     5,  1730,\n",
            "           9, 30396,   229,  5781,    90,    54,  2277,   149,     5,\n",
            "        5856,     9,  5142,  4837,   229, 19231,  1417,     8,   375,\n",
            "        4980,     4,  1437, 50118, 50118, 30760,   156,    24,   155,\n",
            "          12,   288,    10,  2289,   423,    77,   248,  6695,  1464,\n",
            "        1885,  1634, 31247,    11,    41, 13869,  2116,    31,     5,\n",
            "         314,    13,  9005,     7,    66, 43750,   229, 19231,  1417,\n",
            "           8,   244,     5,  1011,    88,     5,   444,  2797,     9,\n",
            "           5,  1161,     4,  1437, 50118, 50118, 30760,    56,  3255,\n",
            "           7,   712,    49,   483,    71,     5,  1108,    53,  4980,\n",
            "         222,   157,     7,   489,    66,  1170,    31,  1464,  1885,\n",
            "        1634,     8,   229,  5781,    90,     6,   150, 15612,  2277,\n",
            "        1810,    31,    41, 13827, 11792,     8,  9005,  3475,    81,\n",
            "           5,  2116,  4901,    31,    10,   205,   737,     4,  1437,\n",
            "           2,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "           1,     1,     1,     1,     1,     1,     1,     1])>, 'attention_mask': <tf.Tensor: shape=(512,), dtype=int64, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0])>, 'pos_tags': <tf.Tensor: shape=(682,), dtype=float32, numpy=\n",
            "array([ 5., 29.,  7., 30., 13., 12., 22.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 41., 30., 39., 23.,\n",
            "        2., 37., 18., 12., 26.,  8., 39., 39., 44., 30., 39., 45., 39.,\n",
            "       39., 12., 30., 39., 22., 23., 29.,  3., 26., 30., 13.,  7.,  8.,\n",
            "        8., 12., 30., 39., 23.,  5., 11.,  3.,  8., 12., 30., 13., 12.,\n",
            "       22., 13.,  8., 12., 38., 39., 39., 45., 12., 12., 29.,  3., 30.,\n",
            "       13., 12., 30., 39., 45., 39., 12., 39., 39., 22., 12., 23., 29.,\n",
            "        8., 39., 30., 18.,  8., 12., 30.,  7., 13., 12., 30., 13.,  8.,\n",
            "       12., 12., 12., 30., 39., 22., 12., 26.,  7.,  2., 13., 41., 30.,\n",
            "       39., 39.,  5., 29., 30., 13., 41., 30., 12., 39., 39., 43.,  8.,\n",
            "       39., 22., 12., 12., 30., 13., 12., 30., 39.,  2., 37., 39., 43.,\n",
            "       37., 13., 12., 30., 13., 26., 12., 30., 13.,  8., 22., 43., 39.,\n",
            "       23., 30., 39., 29.,  8., 30., 13.,  8., 12., 43., 39., 29., 30.,\n",
            "       13., 12., 30., 13.,  8., 12., 22.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.], dtype=float32)>, 'source': 'cnn', 'references': {'answers': {'answer_start': [42], 'text': ['the team from liverpool']}, 'id': '0'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "results_beam = []\n",
        "for train_seed in [42,1337,2022]:\n",
        "  set_seed(train_seed)\n",
        "\n",
        "  encoder = Encoder(model_name=model_name,\n",
        "                        decoder_units=decoder_units)\n",
        "    \n",
        "  # Testing the decoder\n",
        "  decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                        embedding_dim=100,\n",
        "                        decoder_units=decoder_units,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        max_sequence_length=max_sequence_length)\n",
        "  # Training\n",
        "  trainer = MyTrainer(encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        max_length=max_sequence_length)\n",
        "  \n",
        "  checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "  \n",
        "\n",
        "\n",
        "  train_loop(trainer, train_ds, EPOCHS, BATCH_SIZE, checkpoint, checkpoint_prefix + str(train_seed))\n",
        "\n",
        "  prediction = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer)\n",
        "  save_prediction(prediction, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_pred.pickle\")\n",
        "\n",
        "  prediction_beam = predict_loop(trainer, val_ds, INF_BS, model_name,output_tokenizer, beam_search=True)\n",
        "  save_prediction(prediction_beam, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_beampred.pickle\")\n",
        "\n",
        "  results.append(squad_metric.compute(predictions=prediction, references=val_ds['references']))\n",
        "  results_beam.append(squad_metric.compute(predictions=prediction_beam, references=val_ds['references']))\n",
        "\n",
        "  del(checkpoint)\n",
        "  del(trainer)\n",
        "  del(encoder)\n",
        "  del(decoder) \n",
        "\n",
        "print(\"***VALIDATION RESULTS***\")\n",
        "print(results)\n",
        "print(results_beam)\n",
        "print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQK8ldAw9SIs",
        "outputId": "a17b2cc8-2075-44fc-e317-dee95c6ce697"
      },
      "id": "PQK8ldAw9SIs",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n",
            " 96%|█████████▌| 5874/6129 [1:36:12<04:09,  1.02it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(model_name=model_name,\n",
        "                        decoder_units=decoder_units)\n",
        "    \n",
        "# Testing the decoder\n",
        "decoder = Decoder(vocab_size=len(output_tokenizer.word_index) + 1,\n",
        "                        embedding_dim=100,\n",
        "                        decoder_units=decoder_units,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        max_sequence_length=max_sequence_length)\n",
        "# Training\n",
        "trainer = MyTrainer(encoder=encoder,\n",
        "                        decoder=decoder,\n",
        "                        max_length=max_sequence_length)\n",
        "  \n",
        "checkpoint = tf.train.Checkpoint(optimizer=trainer.optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)\n",
        "  \n",
        "results = []\n",
        "results_beam = []\n",
        "for train_seed in [42,1337,2022]:\n",
        "\n",
        "  checkpoint.restore(checkpoint_prefix + str(train_seed)+\"-3\")\n",
        "\n",
        "  prediction = predict_loop(trainer, test_ds, INF_BS, model_name, output_tokenizer)\n",
        "  save_prediction(prediction, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_testpred.pickle\")\n",
        "\n",
        "  prediction_beam = predict_loop(trainer, test_ds, INF_BS, model_name ,output_tokenizer, beam_search=True)\n",
        "  save_prediction(prediction_beam, checkpoint_dir + model_name[-4:] + \"_\" + str(train_seed) + \"_testbeampred.pickle\")\n",
        "\n",
        "  results.append(squad_metric.compute(predictions=prediction, references=test_ds['references']))\n",
        "  results_beam.append(squad_metric.compute(predictions=prediction_beam, references=test_ds['references']))\n",
        "\n",
        "print(\"***TEST RESULTS***\")\n",
        "print(results)\n",
        "print(results_beam)\n",
        "print(f\"greedy exact match:{sum([res['exact_match'] for res in results])/len(results)}\" )\n",
        "print(f\"greedy SQUAD-F1:{sum([res['f1'] for res in results])/len(results)}\" )\n",
        "print(f\"beam exact match:{sum([res['exact_match'] for res in results_beam])/len(results_beam)}\" )\n",
        "print(f\"beam SQUAD-F1:{sum([res['f1'] for res in results_beam])/len(results_beam)}\" )"
      ],
      "metadata": {
        "id": "1oNmAxBvSVuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aaf91c0-3e8a-499e-a2c4-1160b97264a0"
      },
      "id": "1oNmAxBvSVuH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f59090cd070>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predictions = [{'prediction_text': translated[i - 128].split(\"<end>\")[0], 'id':str(i)} for i in range(128, 256)]\n",
        "print(type(prediction[0]))\n",
        "for i in prediction[0:10]:\n",
        "  print(i[\"prediction_text\"])\n",
        "  print(YQA_val[int(i[\"id\"])])\n",
        "  print(XQA_val[int(i[\"id\"])])"
      ],
      "metadata": {
        "id": "g_Q4mJbLSuPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77cbcc40-7de2-47d5-ac01-d8fd5389f44d"
      },
      "id": "g_Q4mJbLSuPm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "4-2 \n",
            "the team from Liverpool\n",
            "['Who was playing in the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "real madrid \n",
            "Manchester City\n",
            "['who was playing against them?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "4-2 \n",
            "3-0\n",
            "['What was the score?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "sunday \n",
            "Monday\n",
            "['When was the game?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "the penalty penalty league \n",
            "Premier League\n",
            "['What league are they in?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "yes \n",
            "No\n",
            "['Is liverpool leading in the rankings?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "yes \n",
            "2 people scored\n",
            "['Were all the goals scored by different people?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "4-2 \n",
            "Andy Carroll\n",
            "['Who had the most goals?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "yes \n",
            "no\n",
            "['Had he scored for his team before?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n",
            "sunday \n",
            "34th minute\n",
            "['When did they double their score?', \"(CNN) -- Andy Carroll scored twice, his first goals for Liverpool, to help his club comfortably defeat Manchester City 3-0 in Monday's Premier League encounter at Anfield. \\n\\nCity, who needed a victory to move above Chelsea into third place in the table, were blown away by a devastating first half performance from Liverpool, who have consolidated sixth position with this result. \\n\\nLiverpool began brightly and nearly took a seventh-minute lead when Luis Suarez's fine strike was tipped onto the post by City's England goalkeeper Joe Hart. \\n\\nBut the visiting defense was struggling to cope with Liverpool's wave of attacks and the hosts took a deserved lead six minutes later when Carroll's superbly struck left-footed strike, from just outside the area, swerved past Hart for his first goal since joining the club for a British record transfer fee in January. \\n\\nLiverpool doubled their lead in the 34th minute when City failed to clear a succession of crosses and blocked shots, the ball eventually falling to the feet of Dirk Kuyt who fired through the legs of defender Alexander Kolarov and past Hart. \\n\\nLiverpool made it 3-0 a minute later when Raul Meireles curled in an inviting cross from the left for Carroll to outjump Kolarov and help the ball into the far corner of the net. \\n\\nLiverpool had chances to increase their lead after the break but Hart did well to keep out efforts from Meireles and Kuyt, while Suarez fired wide from an acute angle and Carroll headed over the crossbar from a good position. \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nnr1YfanbSIs"
      },
      "id": "Nnr1YfanbSIs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f1e83f28",
      "metadata": {
        "id": "f1e83f28"
      },
      "source": [
        "## [Task 4] Question generation with text passage $P$ and question $Q$\n",
        "\n",
        "We want to define $f_\\theta(P, Q)$. \n",
        "\n",
        "Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$ and $Q_i$ and generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7311ba86",
      "metadata": {
        "id": "7311ba86"
      },
      "source": [
        "## [Task 5] Question generation with text passage $P$, question $Q$ and dialogue history $H$\n",
        "\n",
        "We want to define $f_\\theta(P, Q, H)$. Write your own script to implement $f_\\theta$ for each model: M1 and M2.\n",
        "\n",
        "#### Formulation\n",
        "\n",
        "Consider a dialogue on text passage $P$. \n",
        "\n",
        "For each question $Q_i$ at dialogue turn $i$, your model should take $P$, $Q_i$, and $H = \\{ Q_0, A_0, \\dots, Q_{i-1}, A_{i-1} \\}$ to generate $A_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5ac768c",
      "metadata": {
        "id": "b5ac768c"
      },
      "source": [
        "## [Task 6] Train and evaluate $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$\n",
        "\n",
        "Write your own script to train and evaluate your $f_\\theta(P, Q)$ and $f_\\theta(P, Q, H)$ models.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "* Perform multiple train/evaluation seed runs: [42, 2022, 1337].$^1$\n",
        "* Evaluate your models with the following metrics: SQUAD F1-score.$^2$\n",
        "* Fine-tune each transformer-based models for **3 epochs**.\n",
        "* Report evaluation SQUAD F1-score computed on the validation and test sets.\n",
        "\n",
        "$^1$ Remember what we said about code reproducibility in Tutorial 2!\n",
        "\n",
        "$^2$ You can use ```allennlp``` python package for a quick implementation of SQUAD F1-score: ```from allennlp_models.rc.tools import squad```. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92c7e98f",
      "metadata": {
        "id": "92c7e98f"
      },
      "source": [
        "## [Task 7] Error Analysis\n",
        "\n",
        "Perform a simple and short error analysis as follows:\n",
        "* Group dialogues by ```source``` and report the worst 5 model errors for each source (w.r.t. SQUAD F1-score).\n",
        "* Inspect observed results and try to provide some comments (e.g., do the models make errors when faced with a particular question type?)$^1$\n",
        "\n",
        "$^1$ Check the [paper](https://arxiv.org/pdf/1808.07042.pdf) for some valuable information about question/answer types (e.g., Table 6, Table 8) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1814004",
      "metadata": {
        "id": "f1814004"
      },
      "source": [
        "# Assignment Evaluation\n",
        "\n",
        "The following assignment points will be awarded for each task as follows:\n",
        "\n",
        "* Task 1, Pre-processing $\\rightarrow$ 0.5 points.\n",
        "* Task 2, Dataset Splitting $\\rightarrow$ 0.5 points.\n",
        "* Task 3 and 4, Models Definition $\\rightarrow$ 1.0 points.\n",
        "* Task 5 and 6, Models Training and Evaluation $\\rightarrow$ 2.0 points.\n",
        "* Task 7, Analysis $\\rightarrow$ 1.0 points.\n",
        "* Report $\\rightarrow$ 1.0 points.\n",
        "\n",
        "**Total** = 6 points <br>\n",
        "\n",
        "We may award an additional 0.5 points for outstanding submissions. \n",
        " \n",
        "**Speed Bonus** = 0.5 extra points <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20a1b2b9",
      "metadata": {
        "id": "20a1b2b9"
      },
      "source": [
        "# Report\n",
        "\n",
        "We apply the rules described in Assignment 1 regarding the report.\n",
        "* Write a clear and concise report following the given overleaf template (**max 2 pages**).\n",
        "* Report validation and test results in a table.$^1$\n",
        "* **Avoid reporting** code snippets or copy-paste terminal outputs $\\rightarrow$ **Provide a clean schema** of what you want to show"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0967c209",
      "metadata": {
        "id": "0967c209"
      },
      "source": [
        "# Comments and Organization\n",
        "\n",
        "Remember to properly comment your code (it is not necessary to comment each single line) and don't forget to describe your work!\n",
        "\n",
        "Structure your code for readability and maintenance. If you work with Colab, use sections. \n",
        "\n",
        "This allows you to build clean and modular code, as well as easy to read and to debug (notebooks can be quite tricky time to time)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23929660",
      "metadata": {
        "id": "23929660"
      },
      "source": [
        "# FAQ (READ THIS!)\n",
        "\n",
        "---\n",
        "\n",
        "**Question**: Does Task 3 also include data tokenization and conversion step?\n",
        "\n",
        "**Answer:** Yes! These steps are usually straightforward since ```transformers``` also offers a specific tokenizer for each model.\n",
        "\n",
        "**Example**: \n",
        "\n",
        "```\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "encoded_text = tokenizer(text)\n",
        "%% Alternatively\n",
        "inputs = tokenizer.tokenize(text, add_special_tokens=True, max_length=min(max_length, 512))\n",
        "input_ids, attention_mask = inputs['input_ids'], inputs['attention_mask']\n",
        "```\n",
        "\n",
        "**Suggestion**: Hugginface's documentation is full of tutorials and user-friendly APIs.\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Question**: I'm hitting **out of memory error** when training my models, do you have any suggestions?\n",
        "\n",
        "**Answer**: Here are some common workarounds:\n",
        "\n",
        "1. Try decreasing the mini-batch size\n",
        "2. Try applying a different padding strategy (if you are applying padding): e.g. use quantiles instead of maximum sequence length\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c56a612",
      "metadata": {
        "id": "9c56a612"
      },
      "source": [
        "# Contact\n",
        "\n",
        "For any doubt, question, issue or help, you can always contact us at the following email addresses:\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54bac4b9",
      "metadata": {
        "id": "54bac4b9"
      },
      "source": [
        "# The End!\n",
        "\n",
        "Questions?"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a24a6e43a9114e6e99bef88e57e4d2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24db20893a8c446b83bcae8e3cb840ac",
              "IPY_MODEL_52051a6cfb27417a896fd3d29eafd801",
              "IPY_MODEL_9d660321c123404580391a6f241ad084"
            ],
            "layout": "IPY_MODEL_e85176d636c3449da63ecbaaedbc98c5"
          }
        },
        "24db20893a8c446b83bcae8e3cb840ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af8fd820ecf640bb80bf17c86192b2b8",
            "placeholder": "​",
            "style": "IPY_MODEL_7756b123000144ab92de2cbd4514174f",
            "value": "Downloading: 100%"
          }
        },
        "52051a6cfb27417a896fd3d29eafd801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d604fbfef4da4595b715e6f4b7cbaa68",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54729ba3bf1247a5931f3f26c74573bd",
            "value": 480
          }
        },
        "9d660321c123404580391a6f241ad084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16995bc4eac141c199cfd60f067c6ac2",
            "placeholder": "​",
            "style": "IPY_MODEL_6772c8810e4d4d028cfa63aa4815a074",
            "value": " 480/480 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "e85176d636c3449da63ecbaaedbc98c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8fd820ecf640bb80bf17c86192b2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7756b123000144ab92de2cbd4514174f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d604fbfef4da4595b715e6f4b7cbaa68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54729ba3bf1247a5931f3f26c74573bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "16995bc4eac141c199cfd60f067c6ac2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6772c8810e4d4d028cfa63aa4815a074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "030703dff4d046449ce9a6b18b6b3186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_310a95f8c888434db2e8ffbb8ba6a145",
              "IPY_MODEL_103c31c9e2be43fda25f65b60212cf0c",
              "IPY_MODEL_a23ec2dadeb441a285def238bb28c978"
            ],
            "layout": "IPY_MODEL_2a111c91a7ca4beba3b47cc761d3787d"
          }
        },
        "310a95f8c888434db2e8ffbb8ba6a145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fd173fc150745019a27ebe4dbbf9250",
            "placeholder": "​",
            "style": "IPY_MODEL_43e9fdec6cd1478fab2d0268dff58d15",
            "value": "Downloading: 100%"
          }
        },
        "103c31c9e2be43fda25f65b60212cf0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75ae81627a7340b49eabc8f957e43903",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66a190e7ace442049b4f7c7393fee6a2",
            "value": 898823
          }
        },
        "a23ec2dadeb441a285def238bb28c978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d228eaf764254b408118d1d9c5b4fcf9",
            "placeholder": "​",
            "style": "IPY_MODEL_0e52dc717d154231957fc5bdcac8fb28",
            "value": " 899k/899k [00:00&lt;00:00, 1.85MB/s]"
          }
        },
        "2a111c91a7ca4beba3b47cc761d3787d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fd173fc150745019a27ebe4dbbf9250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43e9fdec6cd1478fab2d0268dff58d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75ae81627a7340b49eabc8f957e43903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a190e7ace442049b4f7c7393fee6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d228eaf764254b408118d1d9c5b4fcf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e52dc717d154231957fc5bdcac8fb28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1fa011c4b584482851c53a3586918ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fdde996f91843b4b1a74622a54e1ccb",
              "IPY_MODEL_b1abb6c05899435cb565681dbde3052b",
              "IPY_MODEL_a631d8ac18154d39a7270c58a66827b1"
            ],
            "layout": "IPY_MODEL_a5141e3441454ec4ae47af79442bd668"
          }
        },
        "8fdde996f91843b4b1a74622a54e1ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_847a9bb923fd413ea64964785ee8710b",
            "placeholder": "​",
            "style": "IPY_MODEL_c9abc8ffe4f547dea4d6f3e3bb4c999d",
            "value": "Downloading: 100%"
          }
        },
        "b1abb6c05899435cb565681dbde3052b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caae70980eed48d4bffb784b4392a513",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51503b3a5f954cecb48acc9dc03e1266",
            "value": 456318
          }
        },
        "a631d8ac18154d39a7270c58a66827b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb8b2f72fd5b46a7a72eccd0218d4db1",
            "placeholder": "​",
            "style": "IPY_MODEL_37b3ee5365814ab1bb82722f5e433108",
            "value": " 456k/456k [00:00&lt;00:00, 1.23MB/s]"
          }
        },
        "a5141e3441454ec4ae47af79442bd668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "847a9bb923fd413ea64964785ee8710b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9abc8ffe4f547dea4d6f3e3bb4c999d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "caae70980eed48d4bffb784b4392a513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51503b3a5f954cecb48acc9dc03e1266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bb8b2f72fd5b46a7a72eccd0218d4db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b3ee5365814ab1bb82722f5e433108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95ca0808adfb4b6ea0fbf089c1cadd89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2eb55e0e3e84a5c93123a85c69f85ec",
              "IPY_MODEL_b45bb8eff50a46e8b53bd48dfa647ee0",
              "IPY_MODEL_d49c82e7d7d84280a5cceee2d0c4279a"
            ],
            "layout": "IPY_MODEL_983229fc9e3f4d9ea06dbb637d243873"
          }
        },
        "f2eb55e0e3e84a5c93123a85c69f85ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_198127d758f8493ab4b29dc3212e0c6a",
            "placeholder": "​",
            "style": "IPY_MODEL_756687f9961043bb90b575f91939b23f",
            "value": "Downloading: 100%"
          }
        },
        "b45bb8eff50a46e8b53bd48dfa647ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9602487150aa4d7f99c4efbc01c528b0",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c038ce14bca4ee7ae4402f27dccf90f",
            "value": 1355863
          }
        },
        "d49c82e7d7d84280a5cceee2d0c4279a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbf33ce2c47486691b4c470aa945b21",
            "placeholder": "​",
            "style": "IPY_MODEL_e9f2671767e84ab19a2e7b81e830b77f",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 2.81MB/s]"
          }
        },
        "983229fc9e3f4d9ea06dbb637d243873": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "198127d758f8493ab4b29dc3212e0c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756687f9961043bb90b575f91939b23f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9602487150aa4d7f99c4efbc01c528b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c038ce14bca4ee7ae4402f27dccf90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "abbf33ce2c47486691b4c470aa945b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9f2671767e84ab19a2e7b81e830b77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}