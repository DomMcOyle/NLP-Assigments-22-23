{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DomMcOyle/NLP-Assigments-22-23/blob/Assignment-1/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "**Due to**: 11/01/2022 (dd/mm/yyyy)\n",
        "\n",
        "If you deliver it by 11/12/2021 your assignment will be graded by 11/01/2022.\n",
        "\n",
        "\n",
        "**Credits**: Andrea Galassi, Federico Ruggeri, Paolo Torroni\n",
        "\n",
        "**Summary**: Part-of Speech (POS) tagging as Sequence Labelling using Recurrent Neural Architectures\n",
        "\n",
        "Please, read ALL the following instructions :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4_wqPdlBcKS"
      },
      "source": [
        "# Intro\n",
        "\n",
        "In this assignment  we will ask you to perform POS tagging using neural architectures\n",
        "\n",
        "You are asked to follow these steps:\n",
        "*   Download the corpora and split it in training and test sets, structuring a dataframe.\n",
        "*   Embed the words using GloVe embeddings\n",
        "*   Create a baseline model, using a simple neural architecture\n",
        "*   Experiment doing small modifications to the baseline model, choose hyperparameters using the validation set\n",
        "*   Evaluate your two best model\n",
        "*   Analyze the errors of your model\n",
        "\n",
        "\n",
        "**Task**: given a corpus of documents, predict the POS tag for each word\n",
        "\n",
        "**Corpus**:\n",
        "Ignore the numeric value in the third column, use only the words/symbols and its label. \n",
        "The corpus is available at:\n",
        "https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\n",
        "\n",
        "**Splits**: documents 1-100 are the train set, 101-150 validation set, 151-199 test set.\n",
        "\n",
        "\n",
        "**Features**: you MUST use GloVe embeddings as the only input features to the model.\n",
        "\n",
        "**Splitting**: you can decide to split documents into sentences or not, the choice is yours.\n",
        "\n",
        "**I/O structure**: The input data will have three dimensions: 1-documents/sentences, 2-token, 3-features; for the output there are 2 possibilities: if you use one-hot encoding it will be 1-documents/sentences, 2-token labels, 3-classes, if you use a single integer that indicates the number of the class it will be 1-documents/sentences, 2-token labels.\n",
        "\n",
        "**Baseline**: two layers architecture: a Bidirectional LSTM layer and a Dense/Fully-Connected layer on top; the choice of hyper-parameters is yours.\n",
        "\n",
        "**Architectures**: experiment using a GRU instead of the LSTM, adding an additional LSTM layer, and adding an additional dense layer; do not mix these variantions.\n",
        "\n",
        "\n",
        "**Training and Experiments**: all the experiments must involve only the training and validation sets.\n",
        "\n",
        "**Evaluation**: in the end, only the two best models of your choice (according to the validation set) must be evaluated on the test set. The main metric must be F1-Macro computed between the various part of speech. DO NOT CONSIDER THE PUNCTUATION CLASSES. [What is punctuation?]{https://en.wikipedia.org/wiki/English_punctuation}\n",
        "\n",
        "**Metrics**: the metric you must use to evaluate your final model is the F1-macro, WITHOUT considering punctuation/symbols classes; during the training process you can use accuracy because you can't use the F1 metric unless you use a single (gigantic) batch because there is no way to aggregate \"partial\" F1 scores computed on mini-batches.\n",
        "\n",
        "**Discussion and Error Analysis** : verify and discuss if the results on the test sets are coherent with those on the validation set; analyze the errors done by your model, try to understand which may be the causes and think about how to improve it.\n",
        "\n",
        "**Report**: you are asked to deliver the code of your experiments and a small pdf report of about 2 pages; the pdf must begin with the names of the people of your team and a small abstract (4-5 lines) that sums up your findings.\n",
        "\n",
        "# Out Of Vocabulary (OOV) terms\n",
        "\n",
        "How to handle words that are not in GloVe vocabulary?\n",
        "You can handle them as you want (random embedding, placeholder, whatever!), but they must be STATIC embeddings (you cannot train them).\n",
        "\n",
        "But there is a very important caveat! As usual, the element of the test set must not influence the elements of the other splits!\n",
        "If you use random embeddings or placeholder embeddings (e.g., everything is 0) this is automatically solved.\n",
        "\n",
        "If you want to use other techniques: when you compute new embeddings for train+validation, you must forget about test documents.\n",
        "The motivation is to emulate a real-world scenario, where you select and train a model in the first stage, without knowing nothing about the testing environment.\n",
        "\n",
        "For implementation convenience, you CAN use a single vocabulary file/matrix/whatever. The principle of the previous point is that the embeddings inside that file/matrix must be generated independently for train and test splits.\n",
        "\n",
        "Basically in a real-world scenario, this is what would happen:\n",
        "1. Starting vocabulary V1 (in this assignment, GloVe vocabulary)\n",
        "2. Compute embeddings for terms out of vocabulary V1 (OOV1) of the training split \n",
        "3. Add embeddings to the vocabulary, so to obtain vocabulary V2=V1+OOV1\n",
        "4. Training of the model(s)\n",
        "5. Compute embeddings for terms OOV2 of the validation split \n",
        "6. Add embeddings to the vocabulary, so to obtain vocabulary V3=V1+OOV1+OOV2\n",
        "7. Validation of the model(s)\n",
        "8. Compute embeddings for terms OOV3 of the test split \n",
        "9. Add embeddings to the vocabulary, so to obtain vocabulary V4=V1+OOV1+OOV2+OOV3\n",
        "10. Testing of the final model\n",
        "\n",
        "In this case, where we already have all the documents, we can simplify the process a bit, but the procedure must remain rigorous.\n",
        "\n",
        "1. Starting vocabulary V1 (in this assignment, GloVe vocabulary)\n",
        "2. Compute embeddings for terms out of vocabulary V1 (OOV1) of the training split \n",
        "3. Add embeddings to the vocabulary, so to obtain vocabulary V2=V1+OOV1\n",
        "4. Compute embeddings for terms OOV2 of the validation split \n",
        "5. Add embeddings to the vocabulary, so to obtain vocabulary V3=V1+OOV1+OOV2\n",
        "6. Compute embeddings for terms OOV3 of the test split \n",
        "7. Add embeddings to the vocabulary, so to obtain vocabulary V4=V1+OOV1+OOV2+OOV3\n",
        "8. Training of the model(s)\n",
        "9. Validation of the model(s)\n",
        "10. Testing of the final model\n",
        "\n",
        "Step 2 and step 6 must be completely independent of each other, for what concerns the method and the documents. But they can rely on the previous vocabulary (V1 for step 2 and V3 for step 6)\n",
        "THEREFORE if a word is present both in the training set and the test split and not in the starting vocabulary, its embedding is computed in step 2) and it is not considered OOV anymore in step 6).\n",
        "\n",
        "# Report\n",
        "The report must not be just a copy and paste of graphs and tables!\n",
        "\n",
        "The report must not be longer than 2 pages and must contain:\n",
        "* The names of the member of your team\n",
        "* A short abstract (4-5 lines) that sum ups everything\n",
        "* A general (brief!) description of the task you have addressed and how you have addressed it\n",
        "* A brief analysis of the data (class distribution, lenght, etc)\n",
        "* A short description of the models you have used\n",
        "* Some tables that sum up your findings in validation and test and a discussion of those results\n",
        "* The most relevant findings of your error analysis\n",
        "\n",
        "\n",
        "# Evaluation Criterion\n",
        "\n",
        "The goal of this assignment is not to prove you can find best model ever, but to face a common task, structure it correctly, and follow a correct and rigorous experimental procedure.\n",
        "In other words, we don't care if you final models are awful as long as you have followed the correct procedure and wrote a decent report.\n",
        "\n",
        "The score of the assignment will be computed roughly as follows\n",
        "* 1 point for the correctness of approach/methodology\n",
        "* 1 point for the handling of OOV terms\n",
        "* 1 point for the correct implementation of models (they must run and do the right thing)\n",
        "* 1 point for train-validation-test procedure\n",
        "* 2 point for the discussion of the results, error analysis, and report\n",
        "\n",
        "The evaluation will not be based on the performance of the models!\n",
        "\n",
        "We also reserve the right to assign a small bonus (0.5 points) to any assignment that is particularly worthy. \n",
        "\n",
        "# Deliver\n",
        "\n",
        "* Two files: a pdf file for the report, and a python notebook\n",
        "* Put the names of the member of the team at the beginning of both files\n",
        "* What about additional files, for example models or weights? You can upload them in a private cloud and insert the link in the report.\n",
        "* Please, submit a notebook with clear sections, text boxes, and comments and indications about what is going on in the code. When we do not understand what is going on we get annoyed, when we are annoyed we tend to be more severe in our evaluation.\n",
        "\n",
        "\n",
        "\n",
        "# Contacts\n",
        "\n",
        "In case of any doubt, question, issue, or help we highly recommend you to check the [course useful material](https://virtuale.unibo.it/pluginfile.php/1273064/mod_resource/content/2/NLP_Course_Useful_Material.pdf) for additional information, and to use the Virtuale forums to discuss with other students.\n",
        "\n",
        "You can always contact us at the following email addresses. To increase the probability of a prompt response, we reccomend you to write to both the teaching assistants.\n",
        "If we do not reply within 3-4 days, please send it again!\n",
        "\n",
        "Teaching Assistants:\n",
        "\n",
        "* Andrea Galassi -> a.galassi@unibo.it\n",
        "* Federico Ruggeri -> federico.ruggeri6@unibo.it\n",
        "\n",
        "Professor:\n",
        "\n",
        "* Paolo Torroni -> p.torroni@unibo.it\n",
        "\n",
        "\n",
        "# Additional notes and FAQ\n",
        "* You can use a non-trainable Embedding layer to load the glove embeddings\n",
        "* For the baseline, it must have only two trainable layers: the BiLSTM and the Dense/FC one. The Dense layer is the \"classification head\" with softmax activation. You must not add an additional dense layer on top of the baseline. You can use the embedding layer before the BiLSTM, but it must be not trainable.\n",
        "* You can use any library of your choice to implement the networks. Two options are tensorflow/keras or pythorch. Both these libraries have all the classes you need to implement these simple architectures and there are plenty of tutorials around, where you can learn how to use them.\n",
        "* For the application of the Dense Layer, it is recommended to use a Time-Distributed Dense. In any case, doing otherwise is NOT considered an error.\n",
        "* Some examples of things you can analyze in your discussion and error analysis are: the performances on the most frequent classes and the less frequent classes, precision and recall, the confusion tables, specific misclassified samples.\n",
        "* Punctuation: you must keep the punctuation in the documents, since it may be helpful for the model, you simply must ignore it when you perform the evaluation of the model, not considering the punctuation classes among the ones you use to compute F1 macro score. If you are curious, you can run ADDITIONAL experiments where you remove punctuation to see its impact."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 1"
      ],
      "metadata": {
        "id": "AP1iyYTTY3gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\n",
        "!unzip dependency_treebank.zip\n",
        "!rm dependency_treebank.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcrFcorDYzX1",
        "outputId": "cc979d9e-6c18-4ef0-bcaf-9a6278ef6c72"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-18 18:25:20--  https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 457429 (447K) [application/zip]\n",
            "Saving to: ‘dependency_treebank.zip’\n",
            "\n",
            "\rdependency_treebank   0%[                    ]       0  --.-KB/s               \rdependency_treebank 100%[===================>] 446.71K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2022-11-18 18:25:20 (98.8 MB/s) - ‘dependency_treebank.zip’ saved [457429/457429]\n",
            "\n",
            "Archive:  dependency_treebank.zip\n",
            "   creating: dependency_treebank/\n",
            "  inflating: dependency_treebank/wsj_0093.dp  \n",
            "  inflating: dependency_treebank/wsj_0065.dp  \n",
            "  inflating: dependency_treebank/wsj_0039.dp  \n",
            "  inflating: dependency_treebank/wsj_0182.dp  \n",
            "  inflating: dependency_treebank/wsj_0186.dp  \n",
            "  inflating: dependency_treebank/wsj_0041.dp  \n",
            "  inflating: dependency_treebank/wsj_0018.dp  \n",
            "  inflating: dependency_treebank/wsj_0105.dp  \n",
            "  inflating: dependency_treebank/wsj_0149.dp  \n",
            "  inflating: dependency_treebank/wsj_0194.dp  \n",
            "  inflating: dependency_treebank/wsj_0055.dp  \n",
            "  inflating: dependency_treebank/wsj_0187.dp  \n",
            "  inflating: dependency_treebank/wsj_0143.dp  \n",
            "  inflating: dependency_treebank/wsj_0052.dp  \n",
            "  inflating: dependency_treebank/wsj_0064.dp  \n",
            "  inflating: dependency_treebank/wsj_0179.dp  \n",
            "  inflating: dependency_treebank/wsj_0195.dp  \n",
            "  inflating: dependency_treebank/wsj_0051.dp  \n",
            "  inflating: dependency_treebank/wsj_0059.dp  \n",
            "  inflating: dependency_treebank/wsj_0109.dp  \n",
            "  inflating: dependency_treebank/wsj_0074.dp  \n",
            "  inflating: dependency_treebank/wsj_0089.dp  \n",
            "  inflating: dependency_treebank/wsj_0108.dp  \n",
            "  inflating: dependency_treebank/wsj_0104.dp  \n",
            "  inflating: dependency_treebank/wsj_0164.dp  \n",
            "  inflating: dependency_treebank/wsj_0024.dp  \n",
            "  inflating: dependency_treebank/wsj_0008.dp  \n",
            "  inflating: dependency_treebank/wsj_0101.dp  \n",
            "  inflating: dependency_treebank/wsj_0132.dp  \n",
            "  inflating: dependency_treebank/wsj_0028.dp  \n",
            "  inflating: dependency_treebank/wsj_0184.dp  \n",
            "  inflating: dependency_treebank/wsj_0082.dp  \n",
            "  inflating: dependency_treebank/wsj_0114.dp  \n",
            "  inflating: dependency_treebank/wsj_0061.dp  \n",
            "  inflating: dependency_treebank/wsj_0190.dp  \n",
            "  inflating: dependency_treebank/wsj_0034.dp  \n",
            "  inflating: dependency_treebank/wsj_0043.dp  \n",
            "  inflating: dependency_treebank/wsj_0044.dp  \n",
            "  inflating: dependency_treebank/wsj_0021.dp  \n",
            "  inflating: dependency_treebank/wsj_0005.dp  \n",
            "  inflating: dependency_treebank/wsj_0112.dp  \n",
            "  inflating: dependency_treebank/wsj_0167.dp  \n",
            "  inflating: dependency_treebank/wsj_0042.dp  \n",
            "  inflating: dependency_treebank/wsj_0168.dp  \n",
            "  inflating: dependency_treebank/wsj_0185.dp  \n",
            "  inflating: dependency_treebank/wsj_0057.dp  \n",
            "  inflating: dependency_treebank/wsj_0015.dp  \n",
            "  inflating: dependency_treebank/wsj_0116.dp  \n",
            "  inflating: dependency_treebank/wsj_0135.dp  \n",
            "  inflating: dependency_treebank/wsj_0175.dp  \n",
            "  inflating: dependency_treebank/wsj_0171.dp  \n",
            "  inflating: dependency_treebank/wsj_0068.dp  \n",
            "  inflating: dependency_treebank/wsj_0080.dp  \n",
            "  inflating: dependency_treebank/wsj_0035.dp  \n",
            "  inflating: dependency_treebank/wsj_0181.dp  \n",
            "  inflating: dependency_treebank/wsj_0177.dp  \n",
            "  inflating: dependency_treebank/wsj_0102.dp  \n",
            "  inflating: dependency_treebank/wsj_0137.dp  \n",
            "  inflating: dependency_treebank/wsj_0022.dp  \n",
            "  inflating: dependency_treebank/wsj_0176.dp  \n",
            "  inflating: dependency_treebank/wsj_0180.dp  \n",
            "  inflating: dependency_treebank/wsj_0121.dp  \n",
            "  inflating: dependency_treebank/wsj_0128.dp  \n",
            "  inflating: dependency_treebank/wsj_0036.dp  \n",
            "  inflating: dependency_treebank/wsj_0071.dp  \n",
            "  inflating: dependency_treebank/wsj_0091.dp  \n",
            "  inflating: dependency_treebank/wsj_0076.dp  \n",
            "  inflating: dependency_treebank/wsj_0123.dp  \n",
            "  inflating: dependency_treebank/wsj_0075.dp  \n",
            "  inflating: dependency_treebank/wsj_0131.dp  \n",
            "  inflating: dependency_treebank/wsj_0050.dp  \n",
            "  inflating: dependency_treebank/wsj_0136.dp  \n",
            "  inflating: dependency_treebank/wsj_0161.dp  \n",
            "  inflating: dependency_treebank/wsj_0033.dp  \n",
            "  inflating: dependency_treebank/wsj_0188.dp  \n",
            "  inflating: dependency_treebank/wsj_0085.dp  \n",
            "  inflating: dependency_treebank/wsj_0014.dp  \n",
            "  inflating: dependency_treebank/wsj_0073.dp  \n",
            "  inflating: dependency_treebank/wsj_0199.dp  \n",
            "  inflating: dependency_treebank/wsj_0120.dp  \n",
            "  inflating: dependency_treebank/wsj_0178.dp  \n",
            "  inflating: dependency_treebank/wsj_0122.dp  \n",
            "  inflating: dependency_treebank/wsj_0040.dp  \n",
            "  inflating: dependency_treebank/wsj_0020.dp  \n",
            "  inflating: dependency_treebank/wsj_0153.dp  \n",
            "  inflating: dependency_treebank/wsj_0107.dp  \n",
            "  inflating: dependency_treebank/wsj_0017.dp  \n",
            "  inflating: dependency_treebank/wsj_0140.dp  \n",
            "  inflating: dependency_treebank/wsj_0038.dp  \n",
            "  inflating: dependency_treebank/wsj_0031.dp  \n",
            "  inflating: dependency_treebank/wsj_0165.dp  \n",
            "  inflating: dependency_treebank/wsj_0146.dp  \n",
            "  inflating: dependency_treebank/wsj_0090.dp  \n",
            "  inflating: dependency_treebank/wsj_0001.dp  \n",
            "  inflating: dependency_treebank/wsj_0148.dp  \n",
            "  inflating: dependency_treebank/wsj_0097.dp  \n",
            "  inflating: dependency_treebank/wsj_0009.dp  \n",
            "  inflating: dependency_treebank/wsj_0173.dp  \n",
            "  inflating: dependency_treebank/wsj_0111.dp  \n",
            "  inflating: dependency_treebank/wsj_0129.dp  \n",
            "  inflating: dependency_treebank/wsj_0130.dp  \n",
            "  inflating: dependency_treebank/wsj_0047.dp  \n",
            "  inflating: dependency_treebank/wsj_0110.dp  \n",
            "  inflating: dependency_treebank/wsj_0113.dp  \n",
            "  inflating: dependency_treebank/wsj_0147.dp  \n",
            "  inflating: dependency_treebank/wsj_0160.dp  \n",
            "  inflating: dependency_treebank/wsj_0099.dp  \n",
            "  inflating: dependency_treebank/wsj_0003.dp  \n",
            "  inflating: dependency_treebank/wsj_0011.dp  \n",
            "  inflating: dependency_treebank/wsj_0056.dp  \n",
            "  inflating: dependency_treebank/wsj_0069.dp  \n",
            "  inflating: dependency_treebank/wsj_0026.dp  \n",
            "  inflating: dependency_treebank/wsj_0138.dp  \n",
            "  inflating: dependency_treebank/wsj_0029.dp  \n",
            "  inflating: dependency_treebank/wsj_0115.dp  \n",
            "  inflating: dependency_treebank/wsj_0037.dp  \n",
            "  inflating: dependency_treebank/wsj_0019.dp  \n",
            "  inflating: dependency_treebank/wsj_0002.dp  \n",
            "  inflating: dependency_treebank/wsj_0007.dp  \n",
            "  inflating: dependency_treebank/wsj_0158.dp  \n",
            "  inflating: dependency_treebank/wsj_0087.dp  \n",
            "  inflating: dependency_treebank/wsj_0157.dp  \n",
            "  inflating: dependency_treebank/wsj_0083.dp  \n",
            "  inflating: dependency_treebank/wsj_0103.dp  \n",
            "  inflating: dependency_treebank/wsj_0058.dp  \n",
            "  inflating: dependency_treebank/wsj_0054.dp  \n",
            "  inflating: dependency_treebank/wsj_0016.dp  \n",
            "  inflating: dependency_treebank/wsj_0126.dp  \n",
            "  inflating: dependency_treebank/wsj_0198.dp  \n",
            "  inflating: dependency_treebank/wsj_0144.dp  \n",
            "  inflating: dependency_treebank/wsj_0096.dp  \n",
            "  inflating: dependency_treebank/wsj_0086.dp  \n",
            "  inflating: dependency_treebank/wsj_0197.dp  \n",
            "  inflating: dependency_treebank/wsj_0025.dp  \n",
            "  inflating: dependency_treebank/wsj_0100.dp  \n",
            "  inflating: dependency_treebank/wsj_0084.dp  \n",
            "  inflating: dependency_treebank/wsj_0098.dp  \n",
            "  inflating: dependency_treebank/wsj_0106.dp  \n",
            "  inflating: dependency_treebank/wsj_0119.dp  \n",
            "  inflating: dependency_treebank/wsj_0092.dp  \n",
            "  inflating: dependency_treebank/wsj_0134.dp  \n",
            "  inflating: dependency_treebank/wsj_0077.dp  \n",
            "  inflating: dependency_treebank/wsj_0060.dp  \n",
            "  inflating: dependency_treebank/wsj_0172.dp  \n",
            "  inflating: dependency_treebank/wsj_0048.dp  \n",
            "  inflating: dependency_treebank/wsj_0030.dp  \n",
            "  inflating: dependency_treebank/wsj_0192.dp  \n",
            "  inflating: dependency_treebank/wsj_0066.dp  \n",
            "  inflating: dependency_treebank/wsj_0045.dp  \n",
            "  inflating: dependency_treebank/wsj_0155.dp  \n",
            "  inflating: dependency_treebank/wsj_0118.dp  \n",
            "  inflating: dependency_treebank/wsj_0152.dp  \n",
            "  inflating: dependency_treebank/wsj_0012.dp  \n",
            "  inflating: dependency_treebank/wsj_0006.dp  \n",
            "  inflating: dependency_treebank/wsj_0159.dp  \n",
            "  inflating: dependency_treebank/wsj_0163.dp  \n",
            "  inflating: dependency_treebank/wsj_0170.dp  \n",
            "  inflating: dependency_treebank/wsj_0141.dp  \n",
            "  inflating: dependency_treebank/wsj_0117.dp  \n",
            "  inflating: dependency_treebank/wsj_0125.dp  \n",
            "  inflating: dependency_treebank/wsj_0094.dp  \n",
            "  inflating: dependency_treebank/wsj_0169.dp  \n",
            "  inflating: dependency_treebank/wsj_0027.dp  \n",
            "  inflating: dependency_treebank/wsj_0010.dp  \n",
            "  inflating: dependency_treebank/wsj_0162.dp  \n",
            "  inflating: dependency_treebank/wsj_0127.dp  \n",
            "  inflating: dependency_treebank/wsj_0142.dp  \n",
            "  inflating: dependency_treebank/wsj_0046.dp  \n",
            "  inflating: dependency_treebank/wsj_0088.dp  \n",
            "  inflating: dependency_treebank/wsj_0079.dp  \n",
            "  inflating: dependency_treebank/wsj_0174.dp  \n",
            "  inflating: dependency_treebank/wsj_0063.dp  \n",
            "  inflating: dependency_treebank/wsj_0023.dp  \n",
            "  inflating: dependency_treebank/wsj_0004.dp  \n",
            "  inflating: dependency_treebank/wsj_0156.dp  \n",
            "  inflating: dependency_treebank/wsj_0133.dp  \n",
            "  inflating: dependency_treebank/wsj_0032.dp  \n",
            "  inflating: dependency_treebank/wsj_0070.dp  \n",
            "  inflating: dependency_treebank/wsj_0154.dp  \n",
            "  inflating: dependency_treebank/wsj_0095.dp  \n",
            "  inflating: dependency_treebank/wsj_0072.dp  \n",
            "  inflating: dependency_treebank/wsj_0183.dp  \n",
            "  inflating: dependency_treebank/wsj_0081.dp  \n",
            "  inflating: dependency_treebank/wsj_0196.dp  \n",
            "  inflating: dependency_treebank/wsj_0062.dp  \n",
            "  inflating: dependency_treebank/wsj_0124.dp  \n",
            "  inflating: dependency_treebank/wsj_0191.dp  \n",
            "  inflating: dependency_treebank/wsj_0013.dp  \n",
            "  inflating: dependency_treebank/wsj_0078.dp  \n",
            "  inflating: dependency_treebank/wsj_0150.dp  \n",
            "  inflating: dependency_treebank/wsj_0049.dp  \n",
            "  inflating: dependency_treebank/wsj_0189.dp  \n",
            "  inflating: dependency_treebank/wsj_0151.dp  \n",
            "  inflating: dependency_treebank/wsj_0193.dp  \n",
            "  inflating: dependency_treebank/wsj_0067.dp  \n",
            "  inflating: dependency_treebank/wsj_0145.dp  \n",
            "  inflating: dependency_treebank/wsj_0139.dp  \n",
            "  inflating: dependency_treebank/wsj_0166.dp  \n",
            "  inflating: dependency_treebank/wsj_0053.dp  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim is a Python library for topic modelling, document indexing and similarity retrieval with large corpora\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2r6z__jpAPq",
        "outputId": "73135f9f-19e8-4515-f333-17ae9259ad7c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from keras_preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "vnAjuwg4kSgi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir train_set\n",
        "!mkdir val_set\n",
        "!mkdir test_set"
      ],
      "metadata": {
        "id": "ggavZHbcTUas"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ],
      "metadata": {
        "id": "tFUSc77sYi6T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move first 100 text file to train\n",
        "for i in range(1, 101):\n",
        "  file_name = \"wsj_\" + (\"0\" * (4 - len(str(i)))) + str(i) + \".dp\"\n",
        "  src_name = os.path.join('/content/dependency_treebank/' + file_name)\n",
        "  trg_name = os.path.join('/content/train_set/' + file_name)\n",
        "  shutil.move(src_name, trg_name)\n",
        "\n",
        "# Move 101-150 text file to val\n",
        "for i in range(101, 151):\n",
        "  file_name = \"wsj_\" + (\"0\" * (4 - len(str(i)))) + str(i) + \".dp\"\n",
        "  src_name = os.path.join('/content/dependency_treebank/' + file_name)\n",
        "  trg_name = os.path.join('/content/val_set/' + file_name)\n",
        "  shutil.move(src_name, trg_name)\n",
        "\n",
        "# Move 151-199 text file to test\n",
        "for i in range(151, 200):\n",
        "  file_name = \"wsj_\" + (\"0\" * (4 - len(str(i)))) + str(i) + \".dp\"\n",
        "  src_name = os.path.join('/content/dependency_treebank/' + file_name)\n",
        "  trg_name = os.path.join('/content/test_set/' + file_name)\n",
        "  shutil.move(src_name, trg_name)\n",
        "\n",
        "!rm -rf \"/content/dependency_treebank\""
      ],
      "metadata": {
        "id": "OAdm2Wechnfg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataframe(dataset_path):\n",
        "  dataframe_x_rows =  []\n",
        "  dataframe_y_rows = []\n",
        "\n",
        "  sentence_x_row = []\n",
        "  sentence_y_row = []\n",
        "\n",
        "  words = set([])\n",
        "  tags = set([])\n",
        "\n",
        "  for file_name in os.listdir(dataset_path):\n",
        "    file_path = dataset_path + \"/\" + file_name\n",
        "    file_number = file_name.split(\".\")[0].split(\"_\")[1]\n",
        "\n",
        "    with open(file_path, mode='r', encoding='utf-8') as file_text:\n",
        "      lines = file_text.readlines()\n",
        "\n",
        "      for line in lines:\n",
        "        split_line = line.split(\"\\t\")\n",
        "        if len(split_line) > 1:\n",
        "          word = split_line[0].lower()\n",
        "          pos_tag = split_line[1]\n",
        "\n",
        "          words.add(word)\n",
        "          tags.add(pos_tag)\n",
        "\n",
        "          sentence_x_row.append(word)\n",
        "          sentence_y_row.append(pos_tag)\n",
        "\n",
        "          if word == '.' or word == ';':\n",
        "            dataframe_x_rows.append(sentence_x_row)\n",
        "            dataframe_y_rows.append(sentence_y_row)\n",
        "            sentence_x_row = []\n",
        "            sentence_y_row = []\n",
        "\n",
        "  return dataframe_x_rows, dataframe_y_rows, words, tags"
      ],
      "metadata": {
        "id": "VWiOBcY_bsNc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_x, df_train_y, train_words, train_tags = create_dataframe(\"/content/train_set\")"
      ],
      "metadata": {
        "id": "23_GbPw6cBsb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val_x, df_val_y, _, _ = create_dataframe(\"/content/val_set\")"
      ],
      "metadata": {
        "id": "A7NQ3-kJ3QBX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_x, df_test_y, _, _ = create_dataframe(\"/content/test_set\")"
      ],
      "metadata": {
        "id": "wQDqjYB_PlrT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the current choice is to give an id to each word\n",
        "word2index =  {w: i + 2 for i, w in enumerate(list(train_words))}\n",
        "word2index['<PAD>'] = 0\n",
        "word2index['<OOV>'] = 1\n",
        "\n",
        "# same things applies here it is exploited the possibility to assign an id to\n",
        "# tags, but one hot encoding could be performed instead\n",
        "tag2index = {t: i for i, t in enumerate(list(train_tags))}"
      ],
      "metadata": {
        "id": "SRQKdlcQ8sPq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences_X, val_sentences_X, train_tags_y, val_tags_y = [], [], [], []\n",
        "\n",
        "# function needed in order to convert each word of each sentence to an index \n",
        "def convert_all_sentences_to_indexes(df_x):\n",
        "  sentences_X = []\n",
        "  for sentence in df_x:\n",
        "    converted_sentence = []\n",
        "    for word in sentence:\n",
        "      try:\n",
        "        converted_sentence.append(word2index[word])\n",
        "      except KeyError:\n",
        "        converted_sentence.append(word2index[\"<OOV>\"])\n",
        "    sentences_X.append(converted_sentence)\n",
        "  return sentences_X\n",
        "\n",
        "train_sentences_X = convert_all_sentences_to_indexes(df_train_x)\n",
        "val_sentences_X = convert_all_sentences_to_indexes(df_val_x)\n",
        "\n",
        "print(f\"shape of train_sentences_X: {(len(train_sentences_X), len(train_sentences_X[0]))}\")\n",
        "print(f\"shape of val_sentences_X: {(len(val_sentences_X), len(val_sentences_X[0]))}\")"
      ],
      "metadata": {
        "id": "APguw-xF6h0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06147db1-de91-484b-8a8b-d9aa25334efd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_sentences_X: (2023, 46)\n",
            "shape of val_sentences_X: (1323, 41)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting a OneHotEncoder over tags\n",
        "encoder = OneHotEncoder(sparse = False)\n",
        "encoder.fit(np.array(list(train_tags)).reshape(-1, 1))\n",
        "n_classes = len(train_tags)"
      ],
      "metadata": {
        "id": "GYk2JV0-slTL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = len(max(train_sentences_X, key=len))\n",
        "\n",
        "print(\"The maximum length of a sentence in the training set is: \" + str(MAX_LENGTH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Z6CFe2Ad3w",
        "outputId": "d28c5727-2b23-4a54-e1f5-78e307a5d45a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The maximum length of a sentence in the training set is: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting tags to the associated indexes (we must OneHotEncode even these \n",
        "# tags, if we chose to change method)\n",
        "\n",
        "\"\"\"\n",
        "train_tags_y = [np.array([tag2index[t] for t in s] + [tag2index[s[-1]] for i in range(0,MAX_LENGTH-len(s))]) for s in df_train_y]\n",
        "val_tags_y =[np.array([tag2index[t] for t in s[:MAX_LENGTH]] + [tag2index[s[-1]] for i in range(0,MAX_LENGTH-len(s))]) for s in df_val_y]\n",
        "test_tags_y =[np.array([tag2index[t] for t in s[:MAX_LENGTH]] + [tag2index[s[-1]] for i in range(0,MAX_LENGTH-len(s))]) for s in df_test_y]\n",
        "\"\"\"\n",
        "\n",
        "def convert_to_one_hot(df_y):\n",
        "  converted_one_hot_y = []\n",
        "  for sentence in df_y:\n",
        "    container = np.zeros((MAX_LENGTH, 45))\n",
        "    single_encoded_sentence = encoder.transform(np.array(sentence).reshape(-1, 1))\n",
        "    len_sentence = single_encoded_sentence.shape[0]\n",
        "    if len_sentence >= MAX_LENGTH:\n",
        "      container[:, :] = single_encoded_sentence[:MAX_LENGTH, :]\n",
        "    else:\n",
        "      container[:len_sentence, :] = single_encoded_sentence\n",
        "      container[len_sentence:, :] = single_encoded_sentence[-1, :]\n",
        "    converted_one_hot_y.append(container)\n",
        "  return converted_one_hot_y\n",
        "\n",
        "train_tags_y = convert_to_one_hot(df_train_y)\n",
        "val_tags_y = convert_to_one_hot(df_val_y)\n",
        "test_tags_y = convert_to_one_hot(df_test_y)"
      ],
      "metadata": {
        "id": "4u6LICx2IZBt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a padding to each sentence, since they must have a fixed dimension \n",
        "train_sentences_X = pad_sequences(train_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "val_sentences_X = pad_sequences(val_sentences_X, maxlen=MAX_LENGTH, padding='post')\n",
        "\n",
        "train_tags_y = np.asarray(train_tags_y)\n",
        "val_tags_y = np.asarray(val_tags_y)\n",
        "test_tags_y = np.asarray(test_tags_y)\n",
        "\n",
        "print(f\"shape of train_tags_y: {train_tags_y.shape}\")\n",
        "print(f\"shape of val_tags_y: {val_tags_y.shape}\")\n",
        "print(f\"shape of test_tags_y: {test_tags_y.shape}\")"
      ],
      "metadata": {
        "id": "A2me5GaZAwC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ce3baf-3bd0-4b68-d4bf-fb5d56930a47"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of train_tags_y: (2023, 67, 45)\n",
            "shape of val_tags_y: (1323, 67, 45)\n",
            "shape of test_tags_y: (653, 67, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting up the embedding model, in our case it is GloVe\n",
        "embedding_dimension = 100\n",
        "embedding_model = gloader.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "id": "FQSplRwWImUc",
        "outputId": "64a47073-3fe9-452f-e87a-272b068ddc4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unclear why we have the number of tokens equal to train words + 2,\n",
        "# one special character should be for the OOV terms, the other one could \n",
        "# be a refuse coming from the fact that we had a PAD term, whose function\n",
        "# was to imitate the behaviour of the masks in the layers of the NN\n",
        "num_tokens = len(train_words) + 2\n",
        "\n",
        "# construction of the embedding matrix, it is a matrix N_token x E_dim\n",
        "# whose entries are the vectors corresponding to each word in the \n",
        "# embedding space, identified by idx\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dimension))\n",
        "for word, idx in word2index.items():\n",
        "  try:\n",
        "    embedding_vector = embedding_model[word]\n",
        "  except (KeyError, TypeError):\n",
        "    embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
        "  embedding_matrix[idx] = embedding_vector"
      ],
      "metadata": {
        "id": "pUlRxvgPDyS6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing all the tags in order to recognize which of these are punctuation\n",
        "# marks\n",
        "for tag, tag_value in tag2index.items():\n",
        "  print(str(tag_value) + \" \" + tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9fvkdjaaQG",
        "outputId": "0eebc9da-3b94-462c-b555-d3aaba8c2a46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 TO\n",
            "1 JJS\n",
            "2 CC\n",
            "3 RB\n",
            "4 ''\n",
            "5 JJR\n",
            "6 RBR\n",
            "7 NN\n",
            "8 WP\n",
            "9 LS\n",
            "10 WP$\n",
            "11 VBG\n",
            "12 VBZ\n",
            "13 CD\n",
            "14 VBN\n",
            "15 UH\n",
            "16 NNPS\n",
            "17 :\n",
            "18 POS\n",
            "19 #\n",
            "20 $\n",
            "21 VB\n",
            "22 JJ\n",
            "23 -LRB-\n",
            "24 NNS\n",
            "25 PRP\n",
            "26 MD\n",
            "27 PDT\n",
            "28 IN\n",
            "29 .\n",
            "30 WRB\n",
            "31 VBD\n",
            "32 RBS\n",
            "33 SYM\n",
            "34 NNP\n",
            "35 RP\n",
            "36 -RRB-\n",
            "37 ``\n",
            "38 EX\n",
            "39 FW\n",
            "40 WDT\n",
            "41 PRP$\n",
            "42 ,\n",
            "43 DT\n",
            "44 VBP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model"
      ],
      "metadata": {
        "id": "p91SaJgsndpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function needed to extract the corresponding token from\n",
        "# logits (scores for tokens are predicted as probabilities,\n",
        "# we need to take the maximum and convert it to the corresponding\n",
        "# token label)\n",
        "def logits_to_tokens(sequences, index):\n",
        "    token_sequences = []\n",
        "    for categorical_sequence in sequences:\n",
        "        token_sequence = []\n",
        "        for categorical in categorical_sequence:\n",
        "            token_sequence.append(index[np.argmax(categorical)])\n",
        " \n",
        "        token_sequences.append(token_sequence)\n",
        " \n",
        "    return token_sequences\n",
        "\n",
        "# function needed to extract the categorical vector from a sequence\n",
        "def to_categorical(sequences, categories):\n",
        "    cat_sequences = []\n",
        "    for s in sequences:\n",
        "        cats = []\n",
        "        for item in s:\n",
        "            cats.append(np.zeros(categories))\n",
        "            cats[-1][item] = 1.0\n",
        "        cat_sequences.append(cats)\n",
        "    return np.array(cat_sequences)"
      ],
      "metadata": {
        "id": "Sdkn_G2Gbwhe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construction of the model, an attempt at modelling this as a class was\n",
        "# performed, but it presented problems, so it was modeled as the output of\n",
        "# a single function\n",
        "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Activation, GRU\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "# one lstm                              -> 71 f1-macro\n",
        "# two lstm                              -> 68 f1-macro\n",
        "# two dense (first td 100), lr at 1e-4  -> 01 f1-macro\n",
        "# two dense (first td 100), lr at 1e-2  -> 40 f1-macro\n",
        "# two dense (first td 200), lr at 1e-2  -> 40 f1-macro\n",
        "# one gru                              -> 73 f1-macro\n",
        "def build_model(num_tokens, embedding_dimension, embedding_matrix):\n",
        "    input = Input(shape=(None,), dtype=\"int32\")\n",
        "    x = Embedding(num_tokens,\n",
        "                  embedding_dimension,\n",
        "                  embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
        "                  trainable=False,\n",
        "                  mask_zero=True)(input)\n",
        "    x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "    # x = Bidirectional(GRU(100, return_sequences=True))(x)\n",
        "    # x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
        "    # x = TimeDistributed(Dense(200, activation=\"softmax\"))(x)\n",
        "    x = TimeDistributed(Dense(n_classes, activation=\"softmax\"))(x)\n",
        "    return Model(input, x)\n",
        "\n",
        " \n",
        "print(num_tokens)\n",
        "print(embedding_dimension)\n",
        "model = build_model(num_tokens, embedding_dimension, embedding_matrix)\n",
        "# learning rate scheduling could be a thing when we are satisfied with the\n",
        "# model performances\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVJdOa7DMJ6s",
        "outputId": "d5f9c286-4123-4de9-ec5c-d777d63d3ee1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7406\n",
            "100\n",
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, None, 100)         740600    \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, None, 200)        160800    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, None, 45)         9045      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 910,445\n",
            "Trainable params: 169,845\n",
            "Non-trainable params: 740,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting function needed to show bias and variance of the fitted network\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from functools import partial\n",
        "import random\n",
        "\n",
        "def show_history(history: tf.keras.callbacks.History):\n",
        "    \"\"\"\n",
        "    Shows training history data stored by the History Keras callback\n",
        "\n",
        "    :param history: History Keras callback\n",
        "    \"\"\"\n",
        "    history_data = history.history\n",
        "\n",
        "    for key, value in history_data.items():\n",
        "        if not key.startswith('val'):\n",
        "            fig, ax = plt.subplots(1, 1)\n",
        "            ax.set_title(key)\n",
        "            ax.plot(value)\n",
        "            if f'val_{key}' in history_data:\n",
        "                ax.plot(history_data[f'val_{key}'])\n",
        "            else:\n",
        "                print(f\"Couldn't find validation values for metric: {key}\")\n",
        "\n",
        "            ax.set_ylabel(key)\n",
        "            ax.set_xlabel('epoch')\n",
        "            ax.legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sWhy_MOd1eIr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for sentence in df_test_x:\n",
        "  converted_sentence = []\n",
        "  for word in sentence:\n",
        "    try:\n",
        "      converted_sentence.append(word2index[word])\n",
        "    except KeyError:\n",
        "      converted_sentence.append(word2index[\"<OOV>\"])\n",
        "  test_sentences_X.append(converted_sentence)\n",
        "\"\"\"\n",
        "\n",
        "# construction of a test sentence in the format accepted by the model\n",
        "test_sentences_X = []\n",
        "test_sentences_X = convert_all_sentences_to_indexes(df_test_x)\n",
        "test_sentences_X = pad_sequences(test_sentences_X, maxlen=MAX_LENGTH, padding='post')\n"
      ],
      "metadata": {
        "id": "D3V1so41PkHP"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sksk(epoch, lr):\n",
        "  if epoch>1 and epoch % 20 == 0:\n",
        "    return lr/2\n",
        "  else: \n",
        "    return lr\n",
        "    \n",
        "\n",
        "# training block, here we gotta tweak the parameters\n",
        "training_info = {\n",
        "    'verbose': 1,\n",
        "    'epochs': 100,\n",
        "    'batch_size': 64,\n",
        "}\n",
        "\n",
        "pat = 10 #setting the patience value\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=pat, min_delta=1e-4, restore_best_weights=True)\n",
        "scheduler = tf.keras.callbacks.LearningRateScheduler(sksk, 1)\n",
        "\n",
        "print(f\"Start training! \\nParameters: {training_info}\")\n",
        "history = model.fit(x=train_sentences_X,\n",
        "                    y=train_tags_y,\n",
        "                    validation_data=(val_sentences_X, \n",
        "                                     val_tags_y),\n",
        "                    callbacks=[scheduler,es],\n",
        "                    **training_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvumXGpSoQNd",
        "outputId": "c7b2b3b8-9d79-4fca-e6c7-dc392a73bb36"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training! \n",
            "Parameters: {'verbose': 1, 'epochs': 100, 'batch_size': 64}\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/100\n",
            "32/32 [==============================] - 12s 111ms/step - loss: 1.0074 - accuracy: 0.2698 - val_loss: 0.8265 - val_accuracy: 0.4276 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.6530 - accuracy: 0.5313 - val_loss: 0.5508 - val_accuracy: 0.5913 - lr: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.4217 - accuracy: 0.7064 - val_loss: 0.4063 - val_accuracy: 0.7073 - lr: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.3054 - accuracy: 0.7874 - val_loss: 0.3341 - val_accuracy: 0.7527 - lr: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.2445 - accuracy: 0.8272 - val_loss: 0.2934 - val_accuracy: 0.7806 - lr: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.2077 - accuracy: 0.8514 - val_loss: 0.2686 - val_accuracy: 0.7968 - lr: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.1827 - accuracy: 0.8661 - val_loss: 0.2501 - val_accuracy: 0.8097 - lr: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.1646 - accuracy: 0.8781 - val_loss: 0.2372 - val_accuracy: 0.8187 - lr: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.1507 - accuracy: 0.8864 - val_loss: 0.2271 - val_accuracy: 0.8264 - lr: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.1393 - accuracy: 0.8937 - val_loss: 0.2178 - val_accuracy: 0.8347 - lr: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.1301 - accuracy: 0.9008 - val_loss: 0.2140 - val_accuracy: 0.8377 - lr: 0.0010\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1221 - accuracy: 0.9062 - val_loss: 0.2121 - val_accuracy: 0.8376 - lr: 0.0010\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1155 - accuracy: 0.9109 - val_loss: 0.2048 - val_accuracy: 0.8458 - lr: 0.0010\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.1091 - accuracy: 0.9159 - val_loss: 0.2004 - val_accuracy: 0.8488 - lr: 0.0010\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.1033 - accuracy: 0.9207 - val_loss: 0.1977 - val_accuracy: 0.8514 - lr: 0.0010\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0981 - accuracy: 0.9241 - val_loss: 0.1943 - val_accuracy: 0.8542 - lr: 0.0010\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0938 - accuracy: 0.9271 - val_loss: 0.1923 - val_accuracy: 0.8547 - lr: 0.0010\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0891 - accuracy: 0.9315 - val_loss: 0.1910 - val_accuracy: 0.8562 - lr: 0.0010\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0853 - accuracy: 0.9344 - val_loss: 0.1879 - val_accuracy: 0.8582 - lr: 0.0010\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0816 - accuracy: 0.9376 - val_loss: 0.1880 - val_accuracy: 0.8578 - lr: 0.0010\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0777 - accuracy: 0.9407 - val_loss: 0.1867 - val_accuracy: 0.8597 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0759 - accuracy: 0.9422 - val_loss: 0.1858 - val_accuracy: 0.8600 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0741 - accuracy: 0.9432 - val_loss: 0.1873 - val_accuracy: 0.8588 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0726 - accuracy: 0.9453 - val_loss: 0.1856 - val_accuracy: 0.8600 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0707 - accuracy: 0.9468 - val_loss: 0.1850 - val_accuracy: 0.8607 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.0692 - accuracy: 0.9476 - val_loss: 0.1847 - val_accuracy: 0.8604 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0675 - accuracy: 0.9497 - val_loss: 0.1858 - val_accuracy: 0.8606 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0660 - accuracy: 0.9507 - val_loss: 0.1839 - val_accuracy: 0.8615 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0645 - accuracy: 0.9524 - val_loss: 0.1841 - val_accuracy: 0.8618 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0630 - accuracy: 0.9530 - val_loss: 0.1837 - val_accuracy: 0.8619 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0615 - accuracy: 0.9550 - val_loss: 0.1859 - val_accuracy: 0.8611 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0602 - accuracy: 0.9559 - val_loss: 0.1830 - val_accuracy: 0.8617 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0587 - accuracy: 0.9573 - val_loss: 0.1860 - val_accuracy: 0.8596 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0574 - accuracy: 0.9587 - val_loss: 0.1877 - val_accuracy: 0.8592 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0559 - accuracy: 0.9603 - val_loss: 0.1846 - val_accuracy: 0.8617 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0546 - accuracy: 0.9618 - val_loss: 0.1854 - val_accuracy: 0.8612 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0534 - accuracy: 0.9626 - val_loss: 0.1845 - val_accuracy: 0.8617 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0519 - accuracy: 0.9640 - val_loss: 0.1840 - val_accuracy: 0.8631 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0508 - accuracy: 0.9648 - val_loss: 0.1841 - val_accuracy: 0.8635 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0494 - accuracy: 0.9662 - val_loss: 0.1844 - val_accuracy: 0.8632 - lr: 5.0000e-04\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 1s 25ms/step - loss: 0.0478 - accuracy: 0.9685 - val_loss: 0.1843 - val_accuracy: 0.8636 - lr: 2.5000e-04\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 1s 26ms/step - loss: 0.0472 - accuracy: 0.9687 - val_loss: 0.1836 - val_accuracy: 0.8645 - lr: 2.5000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_history(history)"
      ],
      "metadata": {
        "id": "eBAho2GhoTzV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 869
        },
        "outputId": "59001843-141c-4270-8318-b438ed76f738"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Couldn't find validation values for metric: lr\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simple block to plot the distribution of the tags in the training dataset\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "flatten_y = [word for sentence in df_train_y for word in sentence]\n",
        "\n",
        "plt.figure(figsize=(30, 15))\n",
        "plt.hist(flatten_y, bins=\"auto\", log=True, rwidth=0.7);"
      ],
      "metadata": {
        "id": "zEyoja7Mhkb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "b9d994b0-e4aa-4143-acc2-1730248d1253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the following blocks are all needed in order to compute the classification\n",
        "# report and thus the F1-macro score, the punctuation classes must\n",
        "# be excluded in the computation of the scores\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "pred = model.predict(test_sentences_X)\n",
        "\n",
        "print(pred.shape)\n",
        "#y_test_decoded = encoder.inverse_transform([test_tags_y])\n",
        "#y_pred_decoded = encoder.inverse_transofrm(convert_labels(pred))\n",
        "\n",
        "#print(classification_report(y_test_decoded, y_pred_decoded))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9J8jKLWp3vJ",
        "outputId": "1536fc6f-eb9a-4e3e-a0d2-bfa44276b705"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 3s 7ms/step\n",
            "(653, 67, 45)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_labels(e):\n",
        "  # set the highest value to 1\n",
        "  e[np.argmax(e)]=1\n",
        "  # set the rest to 0\n",
        "  e[e!=1]=0\n",
        "  return e\n",
        "\n",
        "def reduce_results(test, y_true, y_pred):\n",
        "  to_suppress = np.array([\"\\'\\'\", \"-RRB-\", \".\", \n",
        "                          \":\", \",\", \"-LRB-\", \"``\", \n",
        "                          \"#\", \"$\"]).reshape(-1, 1)\n",
        "  #print(to_suppress)\n",
        "  encoded_punct = encoder.transform(to_suppress)\n",
        "  #print(encoded_punct)\n",
        "  verylonglist_pred = []\n",
        "  verylonglist_true = []\n",
        "  j = 0\n",
        "  for e in test:\n",
        "    maxlen = min(len(e), MAX_LENGTH)\n",
        "    for i in range(0,maxlen):\n",
        "      #print(y_true[j][i])\n",
        "      dec_y_true = encoder.inverse_transform(np.array(y_true[j][i]).reshape(1, -1))\n",
        "      #if dec_y_true not in to_suppress:\n",
        "      verylonglist_pred.append(convert_labels(y_pred[j][i]))\n",
        "      verylonglist_true.append(y_true[j][i])\n",
        "    j = j + 1 \n",
        "  #verylonglist_true = encoder.transform(verylonglist_true)\n",
        "  #verylonglist_pred = encoder.transform(verylonglist_pred)  \n",
        "  return verylonglist_true, verylonglist_pred\n",
        "\n",
        "\n",
        "true_y, pred_y = reduce_results(df_test_x, test_tags_y, pred)\n",
        "true_y = encoder.inverse_transform(true_y)\n",
        "pred_y = encoder.inverse_transform(pred_y)\n",
        "\n",
        "to_suppress = np.array([\"\\'\\'\", \"-RRB-\", \".\", \n",
        "                          \":\", \",\", \"-LRB-\", \"``\", \n",
        "                          \"#\", \"$\"])\n",
        "new_cat = [encoder.categories_[0][i] for i in range(0, len(encoder.categories_[0])) if encoder.categories_[0][i] not in to_suppress]\n",
        "# chiedere in che senso escludere la punteggiatura e i simboli dal classification report"
      ],
      "metadata": {
        "id": "EY3PKKF-xUFl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(true_y,pred_y, labels = new_cat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6StjUW8Op0h",
        "outputId": "88eb0340-d1f8-4e26-cfc1-93190d46df9e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          CC       0.99      0.99      0.99       366\n",
            "          CD       0.96      0.90      0.93       858\n",
            "          DT       0.98      0.99      0.99      1334\n",
            "          EX       1.00      1.00      1.00         5\n",
            "          FW       0.00      0.00      0.00         0\n",
            "          IN       0.97      0.95      0.96      1630\n",
            "          JJ       0.64      0.76      0.70       918\n",
            "         JJR       0.85      0.56      0.67        59\n",
            "         JJS       0.95      0.68      0.79        31\n",
            "          LS       0.00      0.00      0.00         0\n",
            "          MD       0.96      0.99      0.98       167\n",
            "          NN       0.84      0.80      0.82      2381\n",
            "         NNP       0.76      0.84      0.79      1504\n",
            "        NNPS       0.67      0.05      0.09        44\n",
            "         NNS       0.82      0.79      0.80       941\n",
            "         PDT       0.00      0.00      0.00         4\n",
            "         POS       0.99      1.00      1.00       152\n",
            "         PRP       0.97      0.97      0.97       192\n",
            "        PRP$       0.99      0.99      0.99        99\n",
            "          RB       0.79      0.78      0.79       381\n",
            "         RBR       0.44      0.47      0.45        15\n",
            "         RBS       0.67      0.67      0.67         3\n",
            "          RP       0.57      0.82      0.68        33\n",
            "         SYM       0.00      0.00      0.00         0\n",
            "          TO       0.99      0.99      0.99       386\n",
            "          UH       0.00      0.00      0.00         0\n",
            "          VB       0.91      0.93      0.92       402\n",
            "         VBD       0.87      0.85      0.86       634\n",
            "         VBG       0.77      0.60      0.68       221\n",
            "         VBN       0.81      0.67      0.73       366\n",
            "         VBP       0.87      0.78      0.82       134\n",
            "         VBZ       0.95      0.90      0.92       280\n",
            "         WDT       0.92      0.98      0.95        84\n",
            "          WP       0.95      1.00      0.98        20\n",
            "         WP$       1.00      0.25      0.40         4\n",
            "         WRB       1.00      0.88      0.93        24\n",
            "\n",
            "   micro avg       0.87      0.86      0.86     13672\n",
            "   macro avg       0.75      0.69      0.70     13672\n",
            "weighted avg       0.87      0.86      0.86     13672\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}